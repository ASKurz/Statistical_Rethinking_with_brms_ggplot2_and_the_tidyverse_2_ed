
@article{aczelDiscussionPointsBayesian2020,
  title = {Discussion Points for {{Bayesian}} Inference},
  author = {Aczel, Balazs and Hoekstra, Rink and Gelman, Andrew and Wagenmakers, Eric-Jan and Klugkist, Irene G. and Rouder, Jeffrey N. and Vandekerckhove, Joachim and Lee, Michael D. and Morey, Richard D. and Vanpaemel, Wolf and Dienes, Zoltan and {van Ravenzwaaij}, Don},
  year = {2020},
  month = jan,
  pages = {1--3},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-019-0807-z},
  url = {https://www.researchgate.net/publication/338849264_Discussion_points_for_Bayesian_inference},
  urldate = {2020-05-18},
  abstract = {Why is there no consensual way of conducting Bayesian analyses? We present a summary of agreements and disagreements of the authors on several discussion points regarding Bayesian inference. We also provide a thinking guideline to assist researchers in conducting Bayesian inference in the social and behavioural sciences.},
  copyright = {2020 Springer Nature Limited},
  file = {/Users/solomonkurz/Zotero/storage/LPH5KWXL/s41562-019-0807-z.html},
  journal = {Nature Human Behaviour},
  language = {en}
}

@book{agrestiFoundationsLinearGeneralized2015,
  title = {Foundations of Linear and Generalized Linear Models},
  author = {Agresti, Alan},
  year = {2015},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034},
  abstract = {A valuable overview of the most important ideas and results in statistical modeling Written by a highly-experienced author, Foundations of Linear and Generalized Linear Models is a clear and comprehensive guide to the key concepts and results of linearstatistical models. The book presents a broad, in-depth overview of the most commonly usedstatistical models by discussing the theory underlying the models, R software applications,and examples with crafted models to elucidate key ideas and promote practical modelbuilding. The book begins by illustrating the fundamentals of linear models, such as how the model-fitting projects the data onto a model vector subspace and how orthogonal decompositions of the data yield information about the effects of explanatory variables. Subsequently, the book covers the most popular generalized linear models, which include binomial and multinomial logistic regression for categorical data, and Poisson and negative binomial loglinear models for count data. Focusing on the theoretical underpinnings of these models, Foundations ofLinear and Generalized Linear Models also features:  An introduction to quasi-likelihood methods that require weaker distributional assumptions, such as generalized estimating equation methods An overview of linear mixed models and generalized linear mixed models with random effects for clustered correlated data, Bayesian modeling, and extensions to handle problematic cases such as high dimensional problems Numerous examples that use R software for all text data analyses More than 400 exercises for readers to practice and extend the theory, methods, and data analysis A supplementary website with datasets for the examples and exercises  An invaluable textbook for upper-undergraduate and graduate-level students in statistics and biostatistics courses, Foundations of Linear and Generalized Linear Models is also an excellent reference for practicing statisticians and biostatisticians, as well as anyone who is interested in learning about the most important statistical models for analyzing data.},
  googlebooks = {dgIzBgAAQBAJ},
  isbn = {978-1-118-73005-8},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {en}
}

@incollection{akaike1998information,
  title = {Information Theory and an Extension of the Maximum Likelihood Principle},
  booktitle = {Selected Papers of {{Hirotugu Akaike}}},
  author = {Akaike, Hirotogu},
  year = {1998},
  pages = {199--213},
  publisher = {{Springer}},
  url = {https://www.springer.com/gp/book/9780387983554}
}

@article{amrheinScientistsRiseStatistical2019,
  title = {Scientists Rise up against Statistical Significance},
  author = {Amrhein, Valentin and Greenland, Sander and McShane, Blake},
  year = {2019},
  month = mar,
  volume = {567},
  pages = {305--307},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-019-00857-9},
  url = {https://www.nature.com/articles/d41586-019-00857-9},
  urldate = {2020-05-21},
  abstract = {Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories call for an end to hyped claims and the dismissal of possibly crucial effects.},
  copyright = {2020 Nature},
  file = {/Users/solomonkurz/Zotero/storage/5JQ3EHZV/Amrhein et al. - 2019 - Scientists rise up against statistical significanc.pdf;/Users/solomonkurz/Zotero/storage/IWDNAU3J/d41586-019-00857-9.html},
  journal = {Nature},
  language = {en},
  number = {7748}
}

@article{angristDoesCompulsorySchool1991,
  title = {Does {{Compulsory School Attendance Affect Schooling}} and {{Earnings}}?},
  author = {Angrist, Joshua D. and Keueger, Alan B.},
  year = {1991},
  month = nov,
  volume = {106},
  pages = {979--1014},
  publisher = {{Oxford Academic}},
  issn = {0033-5533},
  doi = {10.2307/2937954},
  url = {https://academic.oup.com/qje/article/106/4/979/1873496},
  urldate = {2020-08-01},
  abstract = {Abstract.  We establish that season of birth is related to educational attainment because of school start age policy and compulsory school attendance laws. Indi},
  file = {/Users/solomonkurz/Zotero/storage/WG5T6RJ7/Angrist and Keueger - 1991 - Does Compulsory School Attendance Affect Schooling.pdf;/Users/solomonkurz/Zotero/storage/WGBTDCNB/1873496.html},
  journal = {The Quarterly Journal of Economics},
  language = {en},
  number = {4}
}

@article{ape2019,
  title = {Ape 5.0: An Environment for Modern Phylogenetics and Evolutionary Analyses in {{R}}},
  author = {Paradis, E. and Schliep, K.},
  year = {2019},
  volume = {35},
  pages = {526--528},
  doi = {10.1093/bioinformatics/bty633},
  url = {https://academic.oup.com/bioinformatics/article/35/3/526/5055127},
  journal = {Bioinformatics}
}

@article{atkinsTutorialCountRegression2013,
  title = {A Tutorial on Count Regression and Zero-Altered Count Models for Longitudinal Substance Use Data},
  author = {Atkins, David C. and Baldwin, Scott A. and Zheng, Cheng and Gallop, Robert J. and Neighbors, Clayton},
  year = {2013},
  month = mar,
  volume = {27},
  pages = {166--177},
  issn = {0893-164X},
  doi = {10.1037/a0029508},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/},
  urldate = {2020-06-30},
  abstract = {Critical research questions in the study of addictive behaviors concern how these behaviors change over time - either as the result of intervention or in naturalistic settings. The combination of count outcomes that are often strongly skewed with many zeroes (e.g., days using, number of total drinks, number of drinking consequences) with repeated assessments (e.g., longitudinal follow-up after intervention or daily diary data) present challenges for data analyses. The current article provides a tutorial on methods for analyzing longitudinal substance use data, focusing on Poisson, zero-inflated, and hurdle mixed models, which are types of hierarchical or multilevel models. Two example datasets are used throughout, focusing on drinking-related consequences following an intervention and daily drinking over the past 30 days, respectively. Both datasets as well as R, SAS, Mplus, Stata, and SPSS code showing how to fit the models are available on a .},
  file = {/Users/solomonkurz/Zotero/storage/3EXIKU7I/Atkins et al. - 2013 - A tutorial on count regression and zero-altered co.pdf},
  journal = {Psychology of addictive behaviors : journal of the Society of Psychologists in Addictive Behaviors},
  number = {1},
  pmcid = {PMC3513584},
  pmid = {22905895}
}

@article{barrettAnIntroduction2020,
  title = {An Introduction to Ggdag},
  author = {Barrett, Malcolm},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=ggdag/vignettes/intro-to-ggdag.html},
  urldate = {2020-05-31},
  language = {English}
}

@article{barrRandomEffectsStructure2013,
  title = {Random Effects Structure for Confirmatory Hypothesis Testing: {{Keep}} It Maximal},
  shorttitle = {Random Effects Structure for Confirmatory Hypothesis Testing},
  author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  year = {2013},
  month = apr,
  volume = {68},
  pages = {255--278},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2012.11.001},
  url = {http://www.sciencedirect.com/science/article/pii/S0749596X12001180},
  urldate = {2020-07-27},
  abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the `gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond.},
  file = {/Users/solomonkurz/Zotero/storage/FHRVR92C/Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf;/Users/solomonkurz/Zotero/storage/7SG2QQCA/S0749596X12001180.html},
  journal = {Journal of Memory and Language},
  keywords = {Generalization,Linear mixed-effects models,Monte Carlo simulation,Statistics},
  language = {en},
  number = {3}
}

@article{batesFittingLinearMixedeffects2015,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  volume = {67},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{bayesLIIEssaySolving1763,
  title = {{{LII}}. {{An}} Essay towards Solving a Problem in the Doctrine of Chances. {{By}} the Late {{Rev}}. {{Mr}}. {{Bayes}}, {{FRS}} Communicated by {{Mr}}. {{Price}}, in a Letter to {{John Canton}}, {{AMFR S}}},
  author = {Bayes, Thomas},
  year = {1763},
  pages = {370--418},
  publisher = {{The Royal Society London}},
  url = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstl.1763.0053},
  file = {/Users/solomonkurz/Zotero/storage/EMMHAP35/Bayes - 1763 - LII. An essay towards solving a problem in the doc.pdf;/Users/solomonkurz/Zotero/storage/JISQSW2F/rstl.1763.html},
  journal = {Philosophical transactions of the Royal Society of London},
  number = {53}
}

@article{betancourtBayesSparse2018,
  title = {Bayes Sparse Regression},
  author = {Betancourt, Michael},
  year = {2018},
  month = mar,
  url = {https://betanalpha.github.io/assets/case_studies/bayes_sparse_regression.html},
  language = {English}
}

@misc{BetterBibTeXZotero2020,
  title = {Better {{BibTeX}} for Zotero :: {{Better BibTeX}} for Zotero},
  year = {2020},
  url = {https://retorque.re/zotero-better-bibtex/},
  urldate = {2020-05-19},
  file = {/Users/solomonkurz/Zotero/storage/GGWUJFDH/zotero-better-bibtex.html}
}

@misc{BibTeX2020,
  title = {{{BibTeX}}},
  year = {2020},
  url = {http://www.bibtex.org/},
  urldate = {2020-05-19},
  file = {/Users/solomonkurz/Zotero/storage/PMDJYC3M/www.bibtex.org.html}
}

@article{bickelSexBiasGraduate1975,
  title = {Sex Bias in Graduate Admissions: {{Data}} from {{Berkeley}}},
  shorttitle = {Sex {{Bias}} in {{Graduate Admissions}}},
  author = {Bickel, P. J. and Hammel, E. A. and O'Connell, J. W.},
  year = {1975},
  month = feb,
  volume = {187},
  pages = {398--404},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.187.4175.398},
  url = {https://pdfs.semanticscholar.org/b704/3d57d399bd28b2d3e84fb9d342a307472458.pdf},
  urldate = {2020-06-17},
  abstract = {Examination of aggregate data on graduate admissions to the University of California, Berkeley, for fall 1973 shows a clear but misleading pattern of bias against female applicants. Examination of the disaggregated data reveals few decision-making units that show statistically significant departures from expected frequencies of female admissions, and about as many units appear to favor women as to favor men. If the data are properly pooled, taking into account the autonomy of departmental decision making, thus correcting for the tendency of women to apply to graduate departments that are more difficult for applicants of either sex to enter, there is a small but statistically significant bias in favor of women. The graduate departments that are easier to enter tend to be those that require more mathematics in the undergraduate preparatory curriculum. The bias in the aggregated data stems not from any pattern of discrimination on the part of admissions committees, which seem quite fair on the whole, but apparently from prior screening at earlier levels of the educational system. Women are shunted by their socialization and education toward fields of graduate study that are generally more crowded, less productive of completed degrees, and less well funded, and that frequently offer poorer professional employment prospects.},
  chapter = {Articles},
  copyright = {1975 by the American Association for the Advancement of Science},
  file = {/Users/solomonkurz/Zotero/storage/XW4GACMB/398.html},
  journal = {Science},
  language = {en},
  number = {4175},
  pmid = {17835295}
}

@article{bliss1934method,
  title = {The Method of Probits.},
  author = {Bliss, Chester I},
  year = {1934},
  publisher = {{American Assn for the Advancement of Science}},
  doi = {10.1126/science.79.2037.38},
  url = {https://science.sciencemag.org/content/79/2037/38},
  journal = {Science}
}

@article{bolgerCausalProcessesPsychology2019,
  title = {Causal Processes in Psychology Are Heterogeneous},
  author = {Bolger, Niall and Zee, Katherine S. and {Rossignac-Milon}, Maya and Hassin, Ran R.},
  year = {2019},
  volume = {148},
  pages = {601--618},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2222(Electronic),0096-3445(Print)},
  doi = {10.1037/xge0000558},
  url = {https://www.researchgate.net/profile/Niall_Bolger/publication/332358948_Causal_processes_in_psychology_are_heterogeneous/links/5cd9b471a6fdccc9ddaa7879/Causal-processes-in-psychology-are-heterogeneous.pdf},
  abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/CAWSDRIT/2019-19962-002.html},
  journal = {Journal of Experimental Psychology: General},
  keywords = {Experimental Methods,Experimental Psychology,Experimenters,Homogeneity of Variance,Models,Repeated Measures,Theory Formulation},
  number = {4}
}

@incollection{borgesjlJardinSenderosQue1941,
  title = {El Jardin de Senderos Que Se Bifurcan. {{Buenos Aires}}: {{Sur}}. {{Translated}} by {{D}}. {{A}}. {{Yates}} (1964)},
  booktitle = {Labyrinths: {{Selected Stories}} \& {{Other Writings}}},
  author = {{Borges, JL}},
  year = {1941},
  pages = {19--29},
  publisher = {{New Directions}},
  address = {{New York}}
}

@article{braumoellerHypothesisTestingMultiplicative2004,
  title = {Hypothesis Testing and Multiplicative Interaction Terms},
  author = {Braumoeller, Bear F.},
  year = {2004},
  month = oct,
  volume = {58},
  pages = {807--820},
  publisher = {{Cambridge University Press}},
  issn = {1531-5088, 0020-8183},
  doi = {10.1017/S0020818304040251},
  url = {https://www.cambridge.org/core/journals/international-organization/article/hypothesis-testing-and-multiplicative-interaction-terms/5AE39EABAA8F26582C65F0D3FAD153D8},
  urldate = {2020-05-16},
  abstract = {When a statistical equation incorporates a multiplicative term in an
attempt to model interaction effects, the statistical significance of
the lower-order coefficients is largely useless for the typical
purposes of hypothesis testing. This fact remains largely unappreciated
in political science, however. This brief article explains this point,
provides examples, and offers some suggestions for more meaningful
interpretation.I am grateful to Tim
McDaniel, Anne Sartori, and Beth Simmons for comments on a previous
draft.},
  file = {/Users/solomonkurz/Zotero/storage/BPTHF27L/Braumoeller - 2004 - Hypothesis Testing and Multiplicative Interaction .pdf;/Users/solomonkurz/Zotero/storage/FZWUA73C/5AE39EABAA8F26582C65F0D3FAD153D8.html},
  journal = {International Organization},
  language = {en},
  number = {4}
}

@book{brms2020RM,
  title = {{{brms}} Reference Manual, {{Version}} 2.12.0},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/brms.pdf}
}

@book{bryanHappyGitGitHub2020,
  title = {Happy {{Git}} and {{GitHub}} for the {{useR}}},
  author = {Bryan, Jenny and {the STAT 545 TAs} and Hester, Jim},
  year = {2020},
  url = {https://happygitwithr.com}
}

@book{bugs2003UM,
  title = {{{WinBUGS}} User Manual},
  author = {Spiegelhalter, David and Thomas, Andrew and Best, Nicky and Lunn, Dave},
  year = {2003},
  month = jan,
  url = {https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/manual14.pdf}
}

@article{Bürkner2020Define,
  title = {Define Custom Response Distributions with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_customfamilies.html}
}

@misc{Bürkner2020Distributional,
  title = {Estimating Distributional Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html}
}

@article{Bürkner2020Monotonic,
  title = {Estimating Monotonic Effects with  Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = may,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_monotonic.html}
}

@article{Bürkner2020Multivariate,
  title = {Estimating Multivariate Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html}
}

@article{Bürkner2020Non_linear,
  title = {Estimating Non-Linear Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html}
}

@article{Bürkner2020Parameterization,
  title = {Parameterization of Response Distributions in Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  journal = {The R Journal},
  number = {1}
}

@article{burknerBayesianItemResponse2020,
  title = {Bayesian Item Response Modeling in {{R}} with Brms and {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  url = {http://arxiv.org/abs/1905.09501},
  urldate = {2020-05-18},
  abstract = {Item Response Theory (IRT) is widely applied in the human sciences to model persons' responses on a set of items measuring one or more latent constructs. While several R packages have been developed that implement IRT models, they tend to be restricted to respective prespecified classes of models. Further, most implementations are frequentist while the availability of Bayesian methods remains comparably limited. We demonstrate how to use the R package brms together with the probabilistic programming language Stan to specify and fit a wide range of Bayesian IRT models using flexible and intuitive multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Various distributions for categorical, ordinal, and continuous responses are supported. Users may even define their own custom response distribution for use in the presented framework. Common IRT model classes that can be specified natively in the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and post-processed. Model fit can be evaluated and compared using Bayes factors and efficient cross-validation procedures.},
  archivePrefix = {arXiv},
  eprint = {1905.09501},
  eprinttype = {arxiv},
  file = {/Users/solomonkurz/Zotero/storage/T5WVXMPA/Bürkner - 2020 - Bayesian Item Response Modeling in R with brms and.pdf;/Users/solomonkurz/Zotero/storage/KYB42QN2/1905.html},
  journal = {arXiv:1905.09501 [stat]},
  keywords = {Statistics - Computation},
  primaryClass = {stat}
}

@article{burknerBrmsPackageBayesian2017,
  title = {{{brms}}: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{burknerModellingMonotonicEffects2020,
  title = {Modelling Monotonic Effects of Ordinal Predictors in {{Bayesian}} Regression Models},
  author = {B{\"u}rkner, Paul-Christian and Charpentier, Emmanuel},
  year = {2020},
  volume = {n/a},
  issn = {2044-8317},
  doi = {10.1111/bmsp.12195},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/bmsp.12195},
  urldate = {2020-06-28},
  abstract = {Ordinal predictors are commonly used in regression models. They are often incorrectly treated as either nominal or metric, thus under- or overestimating the information contained. Such practices may lead to worse inference and predictions compared to methods which are specifically designed for this purpose. We propose a new method for modelling ordinal predictors that applies in situations in which it is reasonable to assume their effects to be monotonic. The parameterization of such monotonic effects is realized in terms of a scale parameter b representing the direction and size of the effect and a simplex parameter modelling the normalized differences between categories. This ensures that predictions increase or decrease monotonically, while changes between adjacent categories may vary across categories. This formulation generalizes to interaction terms as well as multilevel structures. Monotonic effects may be applied not only to ordinal predictors, but also to other discrete variables for which a monotonic relationship is plausible. In simulation studies we show that the model is well calibrated and, if there is monotonicity present, exhibits predictive performance similar to or even better than other approaches designed to handle ordinal predictors. Using Stan, we developed a Bayesian estimation method for monotonic effects which allows us to incorporate prior information and to check the assumption of monotonicity. We have implemented this method in the R package brms, so that fitting monotonic effects in a fully Bayesian framework is now straightforward.},
  copyright = {\textcopyright{} 2020 The British Psychological Society},
  file = {/Users/solomonkurz/Zotero/storage/32MU9XU6/bmsp.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  keywords = {Bayesian statistics,brms,isotonic regression,ordinal variables,R,Stan},
  language = {en},
  number = {n/a}
}

@article{burknerOrdinalRegressionModels2019,
  title = {Ordinal Regression Models in Psychology: {{A}} Tutorial},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {B{\"u}rkner, Paul-Christian and Vuorre, Matti},
  year = {2019},
  month = mar,
  volume = {2},
  pages = {77--101},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245918823199},
  url = {https://doi.org/10.1177/2515245918823199},
  urldate = {2020-05-18},
  abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {1}
}

@article{carifio2007ten,
  title = {Ten Common Misunderstandings, Misconceptions, Persistent Myths and Urban Legends about {{Likert}} Scales and {{Likert}} Response Formats and Their Antidotes},
  author = {Carifio, James and Perla, Rocco J},
  year = {2007},
  volume = {3},
  pages = {106--116},
  url = {https://thescipub.com/pdf/10.3844/jssp.2007.106.116.pdf},
  journal = {Journal of Social Sciences},
  number = {3}
}

@article{carifioResolving50yearDebate2008,
  title = {Resolving the 50-Year Debate around Using and Misusing {{Likert}} Scales},
  author = {Carifio, James and Perla, Rocco},
  year = {2008},
  volume = {42},
  pages = {1150--1152},
  issn = {1365-2923},
  doi = {10.1111/j.1365-2923.2008.03172.x},
  url = {Resolving the 50-year debate around using and misusing Likert scales},
  urldate = {2020-05-18},
  copyright = {\textcopyright{} Blackwell Publishing Ltd 2008},
  file = {/Users/solomonkurz/Zotero/storage/L3VGQJRR/j.1365-2923.2008.03172.html},
  journal = {Medical Education},
  language = {en},
  number = {12}
}

@article{carpenterStanProbabilisticProgramming2017,
  title = {Stan: {{A}} Probabilistic Programming Language},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  volume = {76},
  publisher = {{Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA \ldots}},
  doi = {10.18637/jss.v076.i01},
  url = {https://www.osti.gov/servlets/purl/1430202},
  journal = {Journal of statistical software},
  number = {1}
}

@inproceedings{carvalho2009handling,
  title = {Handling Sparsity via the Horseshoe},
  booktitle = {Artificial Intelligence and Statistics},
  author = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
  year = {2009},
  pages = {73--80},
  url = {http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf}
}

@article{casellaExplainingGibbsSampler1992,
  title = {Explaining the {{Gibbs}} Sampler},
  author = {Casella, George and George, Edward I.},
  year = {1992},
  month = aug,
  volume = {46},
  pages = {167--174},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1992.10475878},
  url = {https://ecommons.cornell.edu/bitstream/handle/1813/31670/BU-1098-MA.Revised.pdf?sequence=1},
  urldate = {2020-06-11},
  abstract = {Computer-intensive algorithms, such as the Gibbs sampler, have become increasingly popular statistical tools, both in applied and theoretical work. The properties of such algorithms, however, may sometimes not be obvious. Here we give a simple explanation of how and why the Gibbs sampler works. We analytically establish its properties in a simple case and provide insight for more complicated cases. There are also a number of examples.},
  file = {/Users/solomonkurz/Zotero/storage/7G3SEDKK/Casella and George - 1992 - Explaining the Gibbs Sampler.pdf;/Users/solomonkurz/Zotero/storage/SFZUD4XZ/00031305.1992.html},
  journal = {The American Statistician},
  keywords = {Data augmentation,Markov chains,Monte Carlo methods,Resampling techniques},
  number = {3}
}

@article{chandramouliCommentaryGronauWagenmakers2019,
  title = {Commentary on {{Gronau}} and {{Wagenmakers}}},
  author = {Chandramouli, Suyog H and Shiffrin, Richard M},
  year = {2019},
  volume = {2},
  pages = {12--21},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0017-1},
  journal = {Computational Brain \& Behavior},
  number = {1}
}

@article{chenMonteCarloEstimation1999,
  title = {Monte {{Carlo}} Estimation of {{Bayesian}} Credible and {{HPD}} Intervals},
  author = {Chen, Ming-Hui and Shao, Qi-Man},
  year = {1999},
  month = mar,
  volume = {8},
  pages = {69--92},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.1999.10474802},
  url = {https://www.researchgate.net/publication/2442323_Monte_Carlo_Estimation_of_Bayesian_Credible_and_HPD_Intervals},
  urldate = {2020-05-18},
  abstract = {This article considers how to estimate Bayesian credible and highest probability density (HPD) intervals for parameters of interest and provides a simple Monte Carlo approach to approximate these Bayesian intervals when a sample of the relevant parameters can be generated from their respective marginal posterior distribution using a Markov chain Monte Carlo (MCMC) sampling algorithm. We also develop a Monte Carlo method to compute HPD intervals for the parameters of interest from the desired posterior distribution using a sample from an importance sampling distribution. We apply our methodology to a Bayesian hierarchical model that has a posterior density containing analytically intractable integrals that depend on the (hyper) parameters. We further show that our methods are useful not only for calculating the HPD intervals for the parameters of interest but also for computing the HPD intervals for functions of the parameters. Necessary theory is developed and illustrative examples\textemdash including a simulation study\textemdash are given.},
  file = {/Users/solomonkurz/Zotero/storage/A37BJW48/10618600.1999.html},
  journal = {Journal of Computational and Graphical Statistics},
  number = {1}
}

@incollection{chenMonteCarloGap2003,
  title = {A {{Monte Carlo}} Gap Test in Computing {{HPD}} Regions},
  booktitle = {Development of {{Modern Statistics}} and {{Related Topics}}},
  author = {Chen, Ming-Hui and He, Xuming and Shao, Qi-Man and Xu, Hai},
  year = {2003},
  month = jun,
  volume = {Volume 1},
  pages = {38--52},
  publisher = {{World Scientific}},
  doi = {10.1142/9789812796707_0004},
  url = {https://www.researchgate.net/publication/264969946_A_Monte_Carlo_gap_test_in_computing_HPD_regions},
  urldate = {2020-05-18},
  file = {/Users/solomonkurz/Zotero/storage/ZSZ4HUD3/9789812796707_0004.html},
  isbn = {978-981-238-395-2},
  series = {Series in {{Biostatistics}}}
}

@article{chungNondegeneratePenalizedLikelihood2013,
  title = {A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models},
  author = {Chung, Yeojin and {Rabe-Hesketh}, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
  year = {2013},
  month = oct,
  volume = {78},
  pages = {685--709},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-013-9328-2},
  url = {http://link.springer.com/10.1007/s11336-013-9328-2},
  urldate = {2020-05-17},
  journal = {Psychometrika},
  language = {en},
  number = {4}
}

@book{cohenStatisticalPowerAnalysis1988,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  year = {1988},
  edition = {2nd Edition},
  publisher = {{Routledge}},
  doi = {10.4324/9780203771587},
  url = {https://www.taylorfrancis.com/books/9780203771587},
  urldate = {2020-05-16},
  file = {/Users/solomonkurz/Zotero/storage/P6QDI9KH/Cohen - 2013 - Statistical Power Analysis for the Behavioral Scie.pdf;/Users/solomonkurz/Zotero/storage/CCGXJI5G/9780203771587.html},
  isbn = {978-0-203-77158-7},
  language = {en}
}

@book{cover2006elements,
  title = {Elements of Information Theory},
  author = {Cover, Thomas M and Thomas, Joy A},
  year = {2006},
  edition = {2nd Edition},
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Elements+of+Information+Theory\%2C+2nd+Edition-p-9780471241959},
  isbn = {978-0-471-24195-9}
}

@article{cummingNewStatisticsWhy2014,
  title = {The New Statistics: {{Why}} and How},
  shorttitle = {The {{New Statistics}}},
  author = {Cumming, Geoff},
  year = {2014},
  month = jan,
  volume = {25},
  pages = {7--29},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797613504966},
  url = {https://journals.sagepub.com/doi/pdf/10.1177/0956797613504966},
  urldate = {2020-05-21},
  abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.},
  file = {/Users/solomonkurz/Zotero/storage/UJMRBZGC/Cumming - 2014 - The New Statistics Why and How.pdf},
  journal = {Psychological Science},
  number = {1}
}

@article{cushmanRoleConsciousReasoning2006,
  title = {The Role of Conscious Reasoning and Intuition in Moral Judgment: {{Testing}} Three Principles of Harm},
  shorttitle = {The {{Role}} of {{Conscious Reasoning}} and {{Intuition}} in {{Moral Judgment}}},
  author = {Cushman, Fiery and Young, Liane and Hauser, Marc},
  year = {2006},
  month = dec,
  volume = {17},
  pages = {1082--1089},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2006.01834.x},
  url = {https://doi.org/10.1111/j.1467-9280.2006.01834.x},
  urldate = {2020-06-27},
  abstract = {Is moral judgment accomplished by intuition or conscious reasoning? An answer demands a detailed account of the moral principles in question. We investigated three principles that guide moral judgments: (a) Harm caused by action is worse than harm caused by omission, (b) harm intended as the means to a goal is worse than harm foreseen as the side effect of a goal, and (c) harm involving physical contact with the victim is worse than harm involving no physical contact. Asking whether these principles are invoked to explain moral judgments, we found that subjects generally appealed to the first and third principles in their justifications, but not to the second. This finding has significance for methods and theories of moral psychology: The moral principles used in judgment must be directly compared with those articulated in justification, and doing so shows that some moral principles are available to conscious reasoning whereas others are not.},
  journal = {Psychological Science},
  language = {en},
  number = {12}
}

@book{daleHistoryInverseProbability2012,
  title = {A History of Inverse Probability: {{From Thomas Bayes}} to {{Karl Pearson}}},
  author = {Dale, Andrew I},
  year = {2012},
  publisher = {{Springer Science \& Business Media}},
  url = {https://www.springer.com/gp/book/9780387988078}
}

@article{derooijCrossvalidationMethodEvery2020,
  title = {Cross-Validation: {{A}} Method Every Psychologist Should Know},
  shorttitle = {Cross-{{Validation}}},
  author = {{de Rooij}, Mark and Weeda, Wouter},
  year = {2020},
  month = may,
  pages = {2515245919898466},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245919898466},
  url = {https://doi.org/10.1177/2515245919898466},
  urldate = {2020-06-03},
  abstract = {Cross-validation is a statistical procedure that every psychologist should know. Most are possibly familiar with the procedure in a global way but have not used it for the analysis of their own data. We introduce cross-validation for the purpose of model selection in a general sense, as well as an R package we have developed for this kind of analysis, and we present examples illustrating the use of this package for types of research problems that are often encountered in the social sciences. Cross-validation can be an easy-to-use alternative to null-hypothesis testing, and it has the benefit that it does not make as many assumptions.},
  file = {/Users/solomonkurz/Zotero/storage/S7SBFDUC/de Rooij and Weeda - 2020 - Cross-Validation A Method Every Psychologist Shou.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en}
}

@article{duaneHybridMonteCarlo1987,
  title = {Hybrid {{Monte Carlo}}},
  author = {Duane, Simon and Kennedy, A. D. and Pendleton, Brian J. and Roweth, Duncan},
  year = {1987},
  month = sep,
  volume = {195},
  pages = {216--222},
  issn = {0370-2693},
  doi = {10.1016/0370-2693(87)91197-X},
  url = {http://www.sciencedirect.com/science/article/pii/037026938791197X},
  urldate = {2020-05-16},
  abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
  file = {/Users/solomonkurz/Zotero/storage/SUYZYUWV/037026938791197X.html},
  journal = {Physics Letters B},
  language = {en},
  number = {2}
}

@book{dunn2018generalized,
  title = {Generalized Linear Models with Examples in {{R}}},
  author = {Dunn, Peter K and Smyth, Gordon K},
  year = {2018},
  publisher = {{Springer}},
  url = {https://link.springer.com/book/10.1007/978-1-4419-0118-7}
}

@article{eckhardtStanUlamJohn1987,
  title = {Stan {{Ulam}}, {{John}} von {{Neumann}} and the {{Monte Carlo}} Method},
  author = {Eckhardt, Roger},
  year = {1987},
  url = {https://library.sciencemadness.org/lanl1_a/lib-www/pubs/00326867.pdf},
  journal = {Argonne, USA}
}

@article{efronSteinParadoxStatistics1977,
  title = {Stein's Paradox in Statistics},
  author = {Efron, Bradley and Morris, Carl},
  year = {1977},
  volume = {236},
  pages = {119--127},
  publisher = {{Scientific American, a division of Nature America, Inc.}},
  issn = {0036-8733},
  doi = {10.1038/scientificamerican0577-119},
  url = {https://www.jstor.org/stable/24954030},
  urldate = {2020-05-17},
  journal = {Scientific American},
  number = {5}
}

@article{enders2007centering,
  title = {Centering Predictor Variables in Cross-Sectional Multilevel Models: {{A}} New Look at an Old Issue.},
  author = {Enders, Craig K and Tofighi, Davood},
  year = {2007},
  volume = {12},
  pages = {121},
  publisher = {{American Psychological Association}},
  doi = {10.1037/1082-989X.12.2.121},
  url = {https://www.researchgate.net/publication/6274186_Centering_Predictor_Variables_in_Cross-Sectional_Multilevel_Models_A_New_Look_at_An_Old_Issue},
  journal = {Psychological methods},
  number = {2}
}

@incollection{endersCenteringPredictorsContextual2013,
  title = {Centering Predictors and Contextual Effects},
  booktitle = {The {{SAGE Handbook}} of {{Multilevel Modeling}}},
  author = {Enders, Craig},
  editor = {Scott, Marc and Simonoff, Jeffrey and Marx, Brian},
  year = {2013},
  pages = {89--108},
  publisher = {{SAGE Publications Ltd}},
  address = {{1 Oliver's Yard,~55 City Road,~London~EC1Y 1SP~United Kingdom}},
  doi = {10.4135/9781446247600.n6},
  url = {http://methods.sagepub.com/book/the-sage-handbook-of-multilevel-modeling/n6.xml},
  urldate = {2020-05-16},
  isbn = {978-0-85702-564-7 978-1-4462-4760-0}
}

@article{Fernandez2016ggmcmc,
  title = {{{ggmcmc}}: {{Analysis}} of {{MCMC}} Samples and {{Bayesian}} Inference},
  author = {{Fern{\'a}ndez i Mar{\'i}n}, Xavier},
  year = {2016},
  volume = {70},
  pages = {1--20},
  doi = {10.18637/jss.v070.i09},
  journal = {Journal of Statistical Software},
  number = {9}
}

@book{fisherStatisticalMethodsResearch1925,
  title = {Statistical Methods for Research Workers, 11th Ed. Rev},
  author = {Fisher, R.A.},
  year = {1925},
  publisher = {{Edinburgh}},
  address = {{Oliver and Boyd}},
  url = {https://psycnet.apa.org/record/1925-15003-000},
  abstract = {Contains revisions of probability formulas and treatment of correlations.  Harvard Book List (edited) 1955 \#94 (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/L7DDMNLC/1925-15003-000.html},
  series = {Statistical Methods for Research Workers, 11th Ed. Rev}
}

@article{gabry2019visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/rssa.12378},
  url = {https://arxiv.org/abs/1709.01449},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  number = {2}
}

@misc{gabryGraphicalPosteriorPredictive2019,
  title = {Graphical Posterior Predictive Checks Using the Bayesplot Package},
  author = {Gabry, Jonah},
  year = {2019},
  month = nov,
  url = {https://CRAN.R-project.org/package=bayesplot/vignettes/graphical-ppcs.html}
}

@article{gabryPlottingMCMCDraws2019,
  title = {Plotting {{MCMC}} Draws Using the Bayesplot Package},
  author = {Gabry, Jonah},
  year = {2019},
  month = nov,
  url = {https://CRAN.R-project.org/package=bayesplot/vignettes/plotting-mcmc-draws.html},
  urldate = {2020-05-26},
  language = {English}
}

@article{gabryVisualMCMCDiagnostics2020,
  title = {Visual {{MCMC}} Diagnostics Using the Bayesplot Package},
  author = {Gabry, Jonah and Modr{\'a}k, Martin},
  year = {2020},
  month = may,
  url = {https://CRAN.R-project.org/package=bayesplot/vignettes/plotting-mcmc-draws.html},
  urldate = {2020-06-11},
  language = {English}
}

@article{gelman2006difference,
  title = {The Difference between ``Significant'' and ``Not Significant'' Is Not Itself Statistically Significant},
  author = {Gelman, Andrew and Stern, Hal},
  year = {2006},
  volume = {60},
  pages = {328--331},
  publisher = {{Taylor \& Francis}},
  doi = {10.1198/000313006X152649},
  url = {https://www.tandfonline.com/doi/pdf/10.1198/000313006X152649?needAccess=true},
  journal = {The American Statistician},
  number = {4}
}

@article{gelman2012we,
  title = {Why We (Usually) Don't Have to Worry about Multiple Comparisons},
  author = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
  year = {2012},
  volume = {5},
  pages = {189--211},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/19345747.2011.618213},
  url = {https://arxiv.org/pdf/0907.2478.pdf},
  journal = {Journal of Research on Educational Effectiveness},
  number = {2}
}

@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2013},
  publisher = {{CRC press}},
  url = {https://stat.columbia.edu/~gelman/book/}
}

@article{gelmanAnalysisVarianceWhy2005,
  title = {Analysis of Variance--{{Why}} It Is More Important than Ever},
  author = {Gelman, Andrew},
  year = {2005},
  month = feb,
  volume = {33},
  pages = {1--53},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053604000001048},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.aos/1112967698},
  urldate = {2020-05-18},
  abstract = {Analysis of variance (ANOVA) is an extremely important method in exploratory and confirmatory data analysis. Unfortunately, in complex problems (e.g., split-plot designs), it is not always easy to set up an appropriate ANOVA. We propose a hierarchical analysis that automatically gives the correct ANOVA comparisons even in complex scenarios. The inferences for all means and variances are performed under a model with a separate batch of effects for each row of the ANOVA table. We connect to classical ANOVA by working with finite-sample variance components: fixed and random effects models are characterized by inferences about existing levels of a factor and new levels, respectively. We also introduce a new graphical display showing inferences about the standard deviations of each batch of effects. We illustrate with two examples from our applied data analysis, first illustrating the usefulness of our hierarchical computations and displays, and second showing how the ideas of ANOVA are helpful in understanding a previously fit hierarchical model.},
  file = {/Users/solomonkurz/Zotero/storage/2U3XQY5J/Gelman - 2005 - Analysis of variance—why it is more important than.pdf;/Users/solomonkurz/Zotero/storage/SQ6DDNZI/1112967698.html},
  journal = {Annals of Statistics},
  keywords = {ANOVA,Bayesian inference,fixed effects,hierarchical model,linear regression,multilevel model,random effects,variance components},
  language = {EN},
  mrnumber = {MR2157795},
  number = {1},
  zmnumber = {1064.62082}
}

@article{gelmanAreConfidenceIntervals2019,
  title = {Are Confidence Intervals Better Termed ``Uncertainty Intervals''?},
  author = {Gelman, Andrew and Greenland, Sander},
  year = {2019},
  month = sep,
  pages = {l5381},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.l5381},
  url = {https://stat.columbia.edu/~gelman/research/published/uncertainty_intervals.pdf},
  urldate = {2020-05-21},
  file = {/Users/solomonkurz/Zotero/storage/TVDUC9Z3/Gelman and Greenland - 2019 - Are confidence intervals better termed “uncertaint.pdf},
  journal = {BMJ},
  language = {en}
}

@article{gelmanGardenForkingPaths2013,
  title = {The Garden of Forking Paths: {{Why}} Multiple Comparisons Can Be a Problem, Even When There Is No ``Fishing Expedition'' or ``p-Hacking'' and the Research Hypothesis Was Posited Ahead of Time},
  author = {Gelman, Andrew and Loken, Eric},
  year = {2013},
  month = nov,
  pages = {17},
  url = {https://stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf},
  abstract = {Researcher degrees of freedom can lead to a multiple comparisons problem, even in settings where researchers perform only a single analysis on their data. The problem is there can be a large number of potential comparisons when the details of data analysis are highly contingent on data, without the researcher having to perform any conscious procedure of fishing or examining multiple p-values. We discuss in the context of several examples of published papers where data-analysis decisions were theoretically-motivated based on previous literature, but where the details of data selection and analysis were not pre-specified and, as a result, were contingent on data.},
  file = {/Users/solomonkurz/Zotero/storage/EA32DKC7/Gelman and Loken - The garden of forking paths Why multiple comparis.pdf},
  language = {en}
}

@article{gelmanPostratificationManyCategories1997,
  title = {Postratification into Many Categories Using Hierarchical Logistic Regression},
  author = {Gelman, Andrew and Little, Thomas C.},
  year = {1997},
  month = sep,
  volume = {23},
  pages = {127--135},
  url = {https://stat.columbia.edu/~gelman/research/published/poststrat3.pdf},
  journal = {Survey Methodology},
  language = {English}
}

@article{gelmanPriorCanOften2017,
  title = {The Prior Can Often Only Be Understood in the Context of the Likelihood},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  year = {2017},
  month = oct,
  volume = {19},
  pages = {555},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e19100555},
  url = {https://www.mdpi.com/1099-4300/19/10/555},
  urldate = {2020-06-12},
  abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/Users/solomonkurz/Zotero/storage/GITEJRKC/Gelman et al. - 2017 - The Prior Can Often Only Be Understood in the Cont.pdf;/Users/solomonkurz/Zotero/storage/FD2UD59C/555.html},
  journal = {Entropy},
  keywords = {Bayesian inference,default priors,prior distribution},
  language = {en},
  number = {10}
}

@article{gelmanPriorDistributionsVariance2006,
  title = {Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by {{Browne}} and {{Draper}})},
  author = {Gelman, Andrew},
  year = {2006},
  month = sep,
  volume = {1},
  pages = {515--534},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/06-BA117A},
  url = {https://projecteuclid.org/euclid.ba/1340371048},
  urldate = {2020-05-17},
  abstract = {Various noninformative prior distributions have been suggested for scale parameters in hierarchical models. We construct a new folded-noncentral-ttt family of conditionally conjugate priors for hierarchical standard deviation parameters, and then consider noninformative and weakly informative priors in this family. We use an example to illustrate serious problems with the inverse-gamma family of "noninformative" prior distributions. We suggest instead to use a uniform prior on the hierarchical standard deviation, using the half-ttt family when the number of groups is small and in other settings where a weakly informative prior is desired. We also illustrate the use of the half-ttt family for hierarchical modeling of multiple variance parameters such as arise in the analysis of variance.},
  file = {/Users/solomonkurz/Zotero/storage/LNB63KFA/Gelman - 2006 - Prior distributions for variance parameters in hie.pdf;/Users/solomonkurz/Zotero/storage/AJT3SYSS/1340371048.html},
  journal = {Bayesian Analysis},
  keywords = {Bayesian inference,conditional conjugacy,folded-noncentral-$t$ distribution,half-$t$ distribution,hierarchical model,multilevel model,noninformative prior distribution,weakly informative prior distribution},
  language = {EN},
  mrnumber = {MR2221284},
  number = {3},
  zmnumber = {1331.62139}
}

@article{gelmanRsquaredBayesianRegression2019,
  title = {R-Squared for {{Bayesian}} Regression Models},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  year = {2019},
  month = jul,
  volume = {73},
  pages = {307--309},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2018.1549100},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1549100},
  urldate = {2020-05-16},
  journal = {The American Statistician},
  language = {en},
  number = {3}
}

@article{gelmanWhyHighorderPolynomials2019,
  title = {Why High-Order Polynomials Should Not Be Used in Regression Discontinuity Designs},
  author = {Gelman, Andrew and Imbens, Guido},
  year = {2019},
  month = jul,
  volume = {37},
  pages = {447--456},
  publisher = {{Taylor \& Francis}},
  issn = {0735-0015},
  doi = {10.1080/07350015.2017.1366909},
  url = {https://amstat.tandfonline.com/doi/full/10.1080/07350015.2017.1366909},
  urldate = {2020-07-30},
  abstract = {It is common in regression discontinuity analysis to control for third, fourth, or higher-degree polynomials of the forcing variable. There appears to be a perception that such methods are theoretically justified, even though they can lead to evidently nonsensical results. We argue that controlling for global high-order polynomials in regression discontinuity analysis is a flawed approach with three major problems: it leads to noisy estimates, sensitivity to the degree of the polynomial, and poor coverage of confidence intervals. We recommend researchers instead use estimators based on local linear or quadratic polynomials or other smooth functions.},
  file = {/Users/solomonkurz/Zotero/storage/IZ6XLLYA/Gelman and Imbens - 2019 - Why High-Order Polynomials Should Not Be Used in R.pdf;/Users/solomonkurz/Zotero/storage/PK67RHKK/07350015.2017.html},
  journal = {Journal of Business \& Economic Statistics},
  number = {3}
}

@article{gemanStochasticRelaxationGibbs1984,
  title = {Stochastic Relaxation, {{Gibbs}} Distributions, and the {{Bayesian}} Restoration of Images},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  month = nov,
  volume = {PAMI-6},
  pages = {721--741},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.1984.4767596},
  url = {https://www.dam.brown.edu/people/documents/stochasticrelaxation.pdf},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  file = {/Users/solomonkurz/Zotero/storage/M4USX4TH/4767596.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution},
  number = {6}
}

@article{gerardLimitsRetrospectivePower1998,
  title = {Limits of Retrospective Power Analysis},
  author = {Gerard, Patrick and Smith, David and Weerakkody, Govinda},
  year = {1998},
  month = apr,
  volume = {62},
  pages = {801},
  doi = {10.2307/3802357},
  url = {https://www.researchgate.net/publication/273104134_Limits_of_Retrospective_Power_Analysis},
  abstract = {Power analysis after study completion has been suggested to interpret study results. We present 3 methods of estimating power and discuss their limitations. We use simulation studies to show that estimated power can be biased, extremely variable, and severely bounded. We endorse the practice of computing power to detect a biologically meaningful difference as a tool for study planning but suggest that calculation of confidence intervals on the parameter of interest is the appropriate way to gauge the strength and biological meaning of study results.},
  file = {/Users/solomonkurz/Zotero/storage/RLMXTUWI/Gerard et al. - 1998 - Limits of Retrospective Power Analysis.pdf},
  journal = {The Journal of Wildlife Management}
}

@book{grafenModernStatisticsLife2002,
  title = {Modern Statistics for the Life Sciences},
  author = {Grafen, Alan and Hails, Rosie},
  year = {2002},
  month = may,
  publisher = {{Oxford University Press}},
  address = {{Oxford, New York}},
  url = {https://global.oup.com/academic/product/modern-statistics-for-the-life-sciences-9780199252312?},
  abstract = {Model formulae represent a powerful methodology for describing, discussing, understanding, and performing the component of statistical tests known as linear statistics. It was developed for professional statisticians in the 1960s and has become increasingly available as the use of computers has grown and software has advanced. Modern Statistics for Life Scientists puts this methodology firmly within the grasp of undergraduates for the first time. The authors assume a basic knowledge of statistics--up to and including one and two sample t-tests and their non-parametric equivalents. They provide the conceptual framework needed to understand what the method does--but without mathematical proofs--and introduce the ideas in a simple and steady progression with worked examples and exercises at every stage.  This innovative text offers students a single conceptual framework for a wide range of tests-including t-tests, oneway and multiway analysis of variance, linear and polynomial regressions, and analysis of covariance-that are usually introduced separately. More importantly, it gives students a language in which they can frame questions and communicate with the computers that perform the analyses. A companion website, www.oup.com/grafenhails, provides a wealth of worked exercises in the three statistical languages; Minitab, SAS, and SPSS. Appropriate for use in statistics courses at undergraduate and graduate levels, Modern Statistics for the Life Sciences  is also a helpful resource for students in non-mathematics-based disciplines using statistics, such as geography, psychology, epidemiology, and ecology.},
  file = {/Users/solomonkurz/Zotero/storage/9CLZ5C5J/modern-statistics-for-the-life-sciences-9780199252312.html},
  isbn = {978-0-19-925231-2}
}

@book{grolemundDataScience2017,
  title = {R for Data Science},
  author = {Grolemund, Garrett and Wickham, Hadley},
  year = {2017},
  publisher = {{O'Reilly}},
  url = {https://r4ds.had.co.nz}
}

@article{gronauLimitationsBayesianLeaveoneout2019,
  title = {Limitations of {{Bayesian}} Leave-One-out Cross-Validation for Model Selection},
  author = {Gronau, Quentin F and Wagenmakers, Eric-Jan},
  year = {2019},
  volume = {2},
  pages = {1--11},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0011-7},
  journal = {Computational brain \& behavior},
  number = {1}
}

@article{gronauRejoinderMoreLimitations2019,
  title = {Rejoinder: {{More}} Limitations of {{Bayesian}} Leave-One-out Cross-Validation},
  author = {Gronau, Quentin F and Wagenmakers, Eric-Jan},
  year = {2019},
  volume = {2},
  pages = {35--47},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0022-4},
  journal = {Computational brain \& behavior},
  number = {1}
}

@article{guber1999getting,
  title = {Getting What You Pay for: {{The}} Debate over Equity in Public School Expenditures},
  author = {Guber, Deborah, L},
  year = {1999},
  volume = {7},
  url = {https://www.semanticscholar.org/paper/Getting-What-You-Pay-For-The-Debate-Over-Equity-in-Guber/29c30e9dc77b56340faa5e6ad35e0741a5a83d49},
  journal = {Journal of Statistics Education},
  number = {2}
}

@misc{HadleyPrecisSource,
  title = {Hadley/Precis Source: {{R}}/Histospark.{{R}}},
  shorttitle = {Hadley/Precis Source},
  url = {https://rdrr.io/github/hadley/precis/src/R/histospark.R},
  urldate = {2020-05-22},
  abstract = {R/histospark.R defines the following functions:},
  file = {/Users/solomonkurz/Zotero/storage/WDBQG93J/histospark.html},
  language = {en}
}

@incollection{hamakerWhyResearchersShould2012,
  title = {Why Researchers Should Think "within-Person": {{A}} Paradigmatic Rationale},
  shorttitle = {Why Researchers Should Think "within-Person"},
  booktitle = {Handbook of Research Methods for Studying Daily Life},
  author = {Hamaker, Ellen L.},
  year = {2012},
  pages = {43--61},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  url = {https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055},
  abstract = {This chapter presents reasoning for taking an alternative research approach to the study of processes that unfold within individuals over time as part of their daily lives. To this end I focus on three issues. First, I present a brief historical account that shows the large-sample approach is not necessarily the only appropriate research approach in psychology. Second, I discuss the limitations of this approach, specifically, if our interest is in studying psychological processes that take place within individuals. Finally, I discuss several alternatives to the standard large-sample approach that allow us to take a closer and more detailed look at the processes as they are occurring in daily life. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/7IAKF3TS/2012-05165-003.html},
  isbn = {978-1-60918-747-7 978-1-60918-749-1},
  keywords = {Cognitive Processes,Experiences (Events),Experimental Psychologists,Experimentation,History,Methodology,Personality Processes}
}

@article{hanleySexualActivityLifespan1994,
  title = {Sexual Activity and the Lifespan of Male Fruitflies: {{A}} Dataset That Gets Attention},
  shorttitle = {Sexual {{Activity}} and the {{Lifespan}} of {{Male Fruitflies}}},
  author = {Hanley, A, James and Shapiro, H, Stanley},
  year = {1994},
  month = jul,
  volume = {2},
  pages = {null},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/10691898.1994.11910467},
  url = {https://doi.org/10.1080/10691898.1994.11910467},
  urldate = {2020-05-19},
  abstract = {This dataset contains observations on five groups of male fruitflies \textendash\textendash{} 25 fruitflies in each group \textendash\textendash{} from an experiment designed to test if increased reproduction reduces longevity for male fruitflies. (Such a cost has already been established for females.) The five groups are: males forced to live alone, males assigned to live with one or eight interested females, and males assigned to live with one or eight non-receptive females. The observations on each fly were longevity, thorax length, and the percentage of each day spent sleeping. The structure of the experiment provokes lively discussion on experimental design and on contrasts, and gives students opportunities to understand and verbalize what we mean by the term ``statistical interaction.'' Because the variable thorax length has a strong effect on survival, it is important to take it into account to increase the precision of between-group contrasts, even though it is distributed similarly across groups. The dataset can also be used to illustrate techniques of survival analysis.},
  file = {/Users/solomonkurz/Zotero/storage/3XL9TZQK/A and H - 1994 - Sexual Activity and the Lifespan of Male Fruitflie.pdf;/Users/solomonkurz/Zotero/storage/5G6CU48Y/10691898.1994.html},
  journal = {Journal of Statistics Education},
  keywords = {Analysis of covariance,Experiment,Longevity,Precision,Regression,Survival analysis},
  number = {1}
}

@book{hastie2009elements,
  title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  publisher = {{Springer Science \& Business Media}},
  doi = {10.1007/978-0-387-84858-7},
  url = {https://link.springer.com/book/10.1007\%2F978-0-387-84858-7}
}

@article{hauerHarmDoneTests2004,
  title = {The Harm Done by Tests of Significance},
  author = {Hauer, Ezra},
  year = {2004},
  month = may,
  volume = {36},
  pages = {495--500},
  issn = {00014575},
  doi = {10.1016/S0001-4575(03)00036-8},
  url = {https://statmodeling.stat.columbia.edu/wp-content/uploads/2013/03/1154-Hauer-The-harm-done-by-tests-of-significance.pdf},
  urldate = {2020-05-21},
  abstract = {Three historical episodes in which the application of null hypothesis significance testing (NHST) led to the mis-interpretation of data are described. It is argued that the pervasive use of this statistical ritual impedes the accumulation of knowledge and is unfit for use.},
  file = {/Users/solomonkurz/Zotero/storage/Y8LYGNMT/Hauer - 2004 - The harm done by tests of significance.pdf},
  journal = {Accident Analysis \& Prevention},
  language = {en},
  number = {3}
}

@book{hayes2017introduction,
  title = {Introduction to Mediation, Moderation, and Conditional Process Analysis: {{A}} Regression-Based Approach},
  author = {Hayes, Andrew F},
  year = {2017},
  publisher = {{Guilford publications}},
  url = {https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654},
  isbn = {978-1-4625-3465-4}
}

@article{hedekerApplicationMixedeffectsLocation2008,
  title = {An Application of a Mixed-Effects Location Scale Model for Analysis of Ecological Momentary Assessment ({{EMA}}) Data},
  author = {Hedeker, Donald and Mermelstein, Robin J. and Demirtas, Hakan},
  year = {2008},
  month = jun,
  volume = {64},
  pages = {627--634},
  issn = {0006-341X},
  doi = {10.1111/j.1541-0420.2007.00924.x},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2424261/},
  urldate = {2020-08-05},
  abstract = {For longitudinal data, mixed models include random subject effects to indicate how subjects influence their responses over repeated assessments. The error variance and the variance of the random effects are usually considered to be homogeneous. These variance terms characterize the within-subjects (i.e., error variance) and between-subjects (i.e., random-effects variance) variation in the data. In studies using ecological momentary assessment (EMA), up to 30 or 40 observations are often obtained for each subject, and interest frequently centers around changes in the variances, both within and between subjects. In this article, we focus on an adolescent smoking study using EMA where interest is on characterizing changes in mood variation. We describe how covariates can influence the mood variances, and also extend the standard mixed model by adding a subject-level random effect to the within-subject variance specification. This permits subjects to have influence on the mean, or location, and variability, or (square of the) scale, of their mood responses. Additionally, we allow the location and scale random effects to be correlated. These mixed-effects location scale models have useful applications in many research areas where interest centers on the joint modeling of the mean and variance structure.},
  file = {/Users/solomonkurz/Zotero/storage/WV9YLG3T/Hedeker et al. - 2008 - An Application of a Mixed-Effects Location Scale M.pdf},
  journal = {Biometrics},
  number = {2},
  pmcid = {PMC2424261},
  pmid = {17970819}
}

@article{hedekerModelingWithinsubjectVariance2012,
  title = {Modeling Between- and within-Subject Variance in Ecological Momentary Assessment ({{EMA}}) Data Using Mixed-Effects Location Scale Models},
  author = {Hedeker, Donald and Mermelstein, Robin J. and Demirtas, Hakan},
  year = {2012},
  month = nov,
  volume = {31},
  issn = {0277-6715},
  doi = {10.1002/sim.5338},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3655706/},
  urldate = {2020-08-05},
  abstract = {Ecological Momentary Assessment (EMA) and/or Experience Sampling (ESM) methods are increasingly used in health studies to study subjective experiences within changing environmental contexts. In these studies, up to thirty or forty observations are often obtained for each subject. Because there are so many measurements per subject, one can characterize a subject's mean and variance, and specify models for both. In this article, we focus on an adolescent smoking study using EMA where interest is on characterizing changes in mood variation. We describe how covariates can influence the mood variances, and also extend the statistical model by adding a subject-level random effect to the within-subject variance specification. This permits subjects to have influence on the mean, or location, and variability, or (square of the) scale, of their mood responses. These mixed-effects location scale models have useful applications in many research areas where interest centers on the joint modeling of the mean and variance structure.},
  file = {/Users/solomonkurz/Zotero/storage/62M7KKN5/Hedeker et al. - 2012 - Modeling Between- and Within-Subject Variance in E.pdf},
  journal = {Statistics in medicine},
  number = {27},
  pmcid = {PMC3655706},
  pmid = {22419604}
}

@article{hindePrimateMilkProximate2011,
  title = {Primate Milk: {{Proximate}} Mechanisms and Ultimate Perspectives},
  shorttitle = {Primate Milk},
  author = {Hinde, Katie and Milligan, Lauren A.},
  year = {2011},
  volume = {20},
  pages = {9--23},
  issn = {1520-6505},
  doi = {10.1002/evan.20289},
  url = {https://www.researchgate.net/publication/51751742_Primate_milk_Proximate_mechanisms_and_ultimate_perspectives},
  urldate = {2020-05-26},
  abstract = {To understand the evolutionary forces that have shaped primate lactation strategies, it is important to understand the proximate mechanisms of milk synthesis and their ecological and phylogenetic contexts. The lactation strategy of a species has four interrelated dimensions: the frequency and duration of nursing bouts, the period of lactation until weaning, the number and sex ratio of infants that a mother rears simultaneously, and the composition and yield of the milk that mothers synthesize. Milk synthesis, arguably the most physiologically costly component of rearing infants, remains the least studied. Energy transfer becomes energetically less efficient, transitioning from placental support to milk synthesis1, 2 just as the energy requirements for infant growth, development, and behavioral activity substantially increase. Here we review primate lactation biology and milk synthesis, integrating studies from anthropology, biology, nutrition, animal science, immunology, and biochemistry, to identify the derived and ancestral features of primate milks and enhance our understanding of primate life history.},
  copyright = {Copyright \textcopyright{} 2011 Wiley Periodicals, Inc.},
  file = {/Users/solomonkurz/Zotero/storage/7YIU3Z5X/evan.html},
  journal = {Evolutionary Anthropology: Issues, News, and Reviews},
  keywords = {infant development,lactation,life history,maternal investment,reproductive ecology},
  language = {en},
  number = {1}
}

@book{hoffmanLongitudinalAnalysisModeling2015,
  title = {Longitudinal Analysis: {{Modeling}} within-Person Fluctuation and Change},
  author = {Hoffman, Lesa},
  year = {2015},
  edition = {1 edition},
  publisher = {{Routledge}},
  address = {{New York}},
  url = {https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025},
  abstract = {Longitudinal Analysis provides an accessible, application-oriented treatment of introductory and advanced linear models for within-person fluctuation and change. Organized by research design and data type, the text uses in-depth examples to provide a complete description of the model-building process. The core longitudinal models and their extensions are presented within a multilevel modeling framework, paying careful attention to the modeling concerns that are unique to longitudinal data. Written in a conversational style, the text provides verbal and visual interpretation of model equations to aid in their translation to empirical research results. Overviews and summaries, boldfaced key terms, and review questions will help readers synthesize the key concepts in each chapter.  Written for non-mathematically-oriented readers, this text features:   A description of the data manipulation steps required prior to model estimation so readers can more easily apply the steps to their own data   An emphasis on how the terminology, interpretation, and estimation of familiar general linear models relates to those of more complex models for longitudinal data    Integrated model comparisons, effect sizes, and statistical inference in each example to strengthen readers' understanding of the overall model-building process   Sample results sections for each example to provide useful templates for published reports   Examples using both real and simulated data in the text, along with syntax and output for SPSS, SAS, STATA, and Mplus at www.PilesOfVariance.com to help readers apply the models to their own data The book opens with the building blocks of longitudinal analysis\rule{1em}{1pt}general ideas, the general linear model for between-person analysis, and between- and within-person models for the variance and the options within repeated measures analysis of variance. Section 2 introduces unconditional longitudinal models including alternative covariance structure models to describe within-person fluctuation over time and random effects models for within-person change. Conditional longitudinal models are presented in section 3, including both time-invariant and time-varying predictors. Section 4 reviews advanced applications, including alternative metrics of time in accelerated longitudinal designs, three-level models for multiple dimensions of within-person time, the analysis of individuals in groups over time, and repeated measures designs not involving time. The book concludes with additional considerations and future directions, including an overview of sample size planning and other model extensions for non-normal outcomes and intensive longitudinal data.  Class-tested at the University of Nebraska-Lincoln and in intensive summer workshops, this is an ideal text for graduate-level courses on longitudinal analysis or general multilevel modeling taught in psychology, human development and family studies, education, business, and other behavioral, social, and health sciences. The book's accessible approach will also help those trying to learn on their own. Only familiarity with general linear models (regression, analysis of variance) is needed for this text.},
  isbn = {978-0-415-87602-5},
  language = {English}
}

@book{howell2001demography,
  title = {Demography of the Dobe! {{Kung}}},
  author = {Howell, Nancy},
  year = {2001},
  edition = {2nd Edition},
  publisher = {{Routledge}},
  url = {https://www.routledge.com/Demography-of-the-Dobe-Kung/Howell/p/book/9780202306490},
  isbn = {978-0-202-30649-0}
}

@book{howell2010life,
  title = {Life Histories of the {{Dobe}}! {{Kung}}: Food, Fatness, and Well-Being over the Life Span},
  author = {Howell, Nancy},
  year = {2010},
  volume = {4},
  publisher = {{Univ of California Press}},
  url = {https://www.ucpress.edu/book/9780520262348/life-histories-of-the-dobe-kung},
  isbn = {978-0-520-26234-8}
}

@article{hyndmanComputingGraphingHighest1996,
  title = {Computing and Graphing Highest Density Regions},
  author = {Hyndman, Rob J.},
  year = {1996},
  month = may,
  volume = {50},
  pages = {120--126},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1996.10474359},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1996.10474359},
  urldate = {2020-05-18},
  abstract = {Many statistical methods involve summarizing a probability distribution by a region of the sample space covering a specified probability. One method of selecting such a region is to require it to contain points of relatively high density. Highest density regions are particularly useful for displaying multimodal distributions and, in such cases, may consist of several disjoint subsets\textemdash one for each local mode. In this paper, I propose a simple method for computing a highest density region from any given (possibly multivariate) density f(x) that is bounded and continuous in x. Several examples of the use of highest density regions in statistical graphics are also given. A new form of boxplot is proposed based on highest density regions; versions in one and two dimensions are given. Highest density regions in higher dimensions are also discussed and plotted.},
  file = {/Users/solomonkurz/Zotero/storage/RTPEUENN/00031305.1996.html},
  journal = {The American Statistician},
  number = {2}
}

@book{jeffreysTheoryProbability1961,
  title = {Theory of Probability},
  author = {Jeffreys, Harold},
  year = {1961},
  publisher = {{Oxford University Press}},
  url = {https://global.oup.com/academic/product/theory-of-probability-9780198503682?cc=us\&lang=en\&}
}

@article{kassBayesFactors1995,
  title = {Bayes Factors},
  author = {Kass, Robert E and Raftery, Adrian E},
  year = {1995},
  volume = {90},
  pages = {773--795},
  publisher = {{Taylor \& Francis}},
  url = {https://www.stat.washington.edu/raftery/Research/PDF/kass1995.pdf},
  journal = {Journal of the American Statistical Association},
  number = {430}
}

@misc{kayExtractingVisualizingTidy2020,
  title = {Extracting and Visualizing Tidy Draws from Brms Models},
  author = {Kay, Matthew},
  year = {2020},
  month = apr,
  url = {https://mjskay.github.io/tidybayes/articles/tidy-brms.html},
  urldate = {2020-05-17},
  abstract = {tidybayes},
  file = {/Users/solomonkurz/Zotero/storage/NT83AM3T/tidy-brms.html},
  language = {en}
}

@misc{kayMarginalDistributionSingle2020,
  title = {Marginal Distribution of a Single Correlation from an {{LKJ}} Distribution \textemdash{} Lkjcorr\_marginal},
  author = {Kay, Matthew},
  year = {2020},
  url = {https://mjskay.github.io/ggdist/reference/lkjcorr_marginal.html},
  urldate = {2020-07-29},
  abstract = {Marginal distribution for the correlation in a single cell from a correlation
matrix distributed according to an LKJ distribution.},
  file = {/Users/solomonkurz/Zotero/storage/2TMG4ARE/lkjcorr_marginal.html},
  language = {en}
}

@misc{kaySlabIntervalStats2020,
  title = {Slab + Interval Stats and Geoms},
  author = {Kay, Matthew},
  year = {2020},
  month = apr,
  url = {https://mjskay.github.io/tidybayes/articles/slabinterval.html},
  urldate = {2020-05-15},
  abstract = {tidybayes},
  file = {/Users/solomonkurz/Zotero/storage/SDV77RJR/slabinterval.html},
  language = {en}
}

@article{kelley2012effect,
  title = {On Effect Size},
  author = {Kelley, Ken and Preacher, Kristopher J},
  year = {2012},
  volume = {17},
  pages = {137},
  publisher = {{American Psychological Association}},
  doi = {10.1037/a0028086},
  url = {https://www3.nd.edu/~kkelley/publications/articles/Kelley_and_Preacher_Psychological_Methods_2012.pdf},
  journal = {Psychological methods},
  number = {2}
}

@article{kennedyKnowYourPopulation2020,
  title = {Know Your Population and Know Your Model: {{Using}} Model-Based Regression and Poststratification to Generalize Findings beyond the Observed Sample},
  shorttitle = {Know Your Population and Know Your Model},
  author = {Kennedy, Lauren and Gelman, Andrew},
  year = {2020},
  month = apr,
  url = {http://arxiv.org/abs/1906.11323},
  urldate = {2020-07-28},
  abstract = {Psychology research focuses on interactions, and this has deep implications for inference from non-representative samples. For the goal of estimating average treatment effects, we propose to fit a model allowing treatment to interact with background variables and then average over the distribution of these variables in the population. This can be seen as an extension of multilevel regression and poststratification (MRP), a method used in political science and other areas of survey research, where researchers wish to generalize from a sparse and possibly non-representative sample to the general population. In this paper, we discuss areas where this method can be used in the psychological sciences. We use our method to estimate the norming distribution for the Big Five Personality Scale using open source data. We argue that large open data sources like this and other collaborative data sources can be combined with MRP to help resolve current challenges of generalizability and replication in psychology.},
  archivePrefix = {arXiv},
  eprint = {1906.11323},
  eprinttype = {arxiv},
  file = {/Users/solomonkurz/Zotero/storage/6HFKVVBX/Kennedy and Gelman - 2020 - Know your population and know your model Using mo.pdf;/Users/solomonkurz/Zotero/storage/8HSAKEKD/1906.html},
  journal = {arXiv:1906.11323 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@article{kievitSimpsonParadoxPsychological2013,
  title = {Simpson's Paradox in Psychological Science: A Practical Guide},
  shorttitle = {Simpson's Paradox in Psychological Science},
  author = {Kievit, Rogier and Frankenhuis, Willem Eduard and Waldorp, Lourens and Borsboom, Denny},
  year = {2013},
  volume = {4},
  publisher = {{Frontiers}},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00513},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00513/full},
  urldate = {2020-06-17},
  abstract = {The direction of an association at the population-level may be reversed within the subgroups comprising that population\textemdash a striking observation called Simpson's paradox. When facing this pattern, psychologists often view it as anomalous. Here, we argue that Simpson's paradox is more common than conventionally thought, and typically results in incorrect interpretations \textendash{} potentially with harmful consequences. We support this claim by drawing on empirical results from cognitive neuroscience, behavior genetics, psychopathology, personality psychology, educational psychology, intelligence research, and simulation studies. We show that Simpson's Paradox is most likely to occur when inferences are drawn across different levels of explanation (e.g., from populations to subgroups, or subgroups to individuals). We propose a set of statistical markers indicative of the paradox, and offer psychometric solutions for dealing with the paradox when encountered\textemdash including a toolbox in R for detecting Simpson's Paradox. We show that explicit modeling of situations in which the paradox might occur not only prevents incorrect interpretations of data, but also results in a deeper understanding of what data tell us about the world.},
  file = {/Users/solomonkurz/Zotero/storage/2DI5JTLT/Kievit et al. - 2013 - Simpson's paradox in psychological science a prac.pdf},
  journal = {Frontiers in Psychology},
  keywords = {ecological fallacy,Measurement,Paradox,Reductionism,simpson's paradox,statistical inference},
  language = {English}
}

@article{kleinPracticalGuideTransparency2018,
  title = {A Practical Guide for Transparency in Psychological Science.},
  author = {Klein, O. and Hardwicke, T. E. and Aust, F. and Breuer, J. and Danielsson, H. and Hofelich Mohr, A. and IJzerman, H. and Nilsonne, G. and Vanpaemel, W. and Frank, M. C.},
  year = {2018},
  month = jun,
  volume = {4},
  pages = {1--15},
  publisher = {{The Regents of the University of California}},
  issn = {2474-7394},
  doi = {10.1525/collabra.158},
  url = {https://lirias.kuleuven.be/1999530},
  urldate = {2020-05-18},
  abstract = {\textcopyright{} 2018 The Author(s). The credibility of scientific claims depends upon the transparency of the research products upon which they are based (e.g., study protocols, data, materials, and analysis scripts). As psychology navigates a period of unprecedented introspection, user-friendly tools and services that support open science have flourished. However, the plethora of decisions and choices involved can be bewildering. Here we provide a practical guide to help researchers navigate the process of preparing and sharing the products of their research (e.g., choosing a repository, preparing their research products for sharing, structuring folders, etc.). Being an open scientist means adopting a few straightforward research management practices, which lead to less error prone, reproducible research workflows. Further, this adoption can be piecemeal \textendash{} each incremental step towards complete transparency adds positive value. Transparent research practices not only improve the efficiency of individual researchers, they enhance the credibility of the knowledge generated by the scientific community.},
  file = {/Users/solomonkurz/Zotero/storage/439IHJWF/Klein et al. - 2018 - A practical guide for transparency in psychologica.pdf;/Users/solomonkurz/Zotero/storage/AKE5WGPW/1999530.html},
  journal = {Collabra: Psychology},
  language = {eng},
  number = {1}
}

@article{klinePopulationSizePredicts2010,
  title = {Population Size Predicts Technological Complexity in {{Oceania}}},
  author = {Kline, Michelle A. and Boyd, Robert},
  year = {2010},
  month = aug,
  volume = {277},
  pages = {2559--2564},
  publisher = {{Royal Society}},
  doi = {10.1098/rspb.2010.0452},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2010.0452},
  urldate = {2020-06-17},
  abstract = {Much human adaptation depends on the gradual accumulation of culturally transmitted knowledge and technology. Recent models of this process predict that large, well-connected populations will have more diverse and complex tool kits than small, isolated populations. While several examples of the loss of technology in small populations are consistent with this prediction, it found no support in two systematic quantitative tests. Both studies were based on data from continental populations in which contact rates were not available, and therefore these studies do not provide a test of the models. Here, we show that in Oceania, around the time of early European contact, islands with small populations had less complicated marine foraging technology. This finding suggests that explanations of existing cultural variation based on optimality models alone are incomplete because demography plays an important role in generating cumulative cultural adaptation. It also indicates that hominin populations with similar cognitive abilities may leave very different archaeological records, a conclusion that has important implications for our understanding of the origin of anatomically modern humans and their evolved psychology.},
  file = {/Users/solomonkurz/Zotero/storage/674ZLAYD/Kline and Boyd - 2010 - Population size predicts technological complexity .pdf;/Users/solomonkurz/Zotero/storage/XYKLTPSX/rspb.2010.html},
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  number = {1693}
}

@book{kolmogorovFoundationsTheoryProbability1956,
  title = {Foundations of the Theory of Probability: {{Second English Edition}}},
  author = {Kolmogorov, Andre{\textbackslash}u{\i} Nikolaevich and {Bharucha-Reid}, Albert T},
  year = {1956},
  publisher = {{Chelsea Publishing Company}},
  url = {https://www.york.ac.uk/depts/maths/histstat/kolmogorov_foundations.pdf}
}

@article{kosterFoodSharingNetworks2014,
  title = {Food Sharing Networks in Lowland {{Nicaragua}}: {{An}} Application of the Social Relations Model to Count Data},
  shorttitle = {Food Sharing Networks in Lowland {{Nicaragua}}},
  author = {Koster, Jeremy M. and Leckie, George},
  year = {2014},
  month = jul,
  volume = {38},
  pages = {100--110},
  issn = {0378-8733},
  doi = {10.1016/j.socnet.2014.02.002},
  url = {https://www.researchgate.net/profile/Jeremy_Koster/publication/261764179_Food_sharing_networks_in_lowland_Nicaragua_An_application_of_the_social_relations_model_to_count_data/links/5c413437299bf12be3d04539/Food-sharing-networks-in-lowland-Nicaragua-An-application-of-the-social-relations-model-to-count-data.pdf},
  urldate = {2020-08-01},
  abstract = {Previous research on food sharing in small-scale societies provides support for multiple evolutionary hypotheses, but evolutionary anthropologists have devoted relatively little attention to the broader relational context of inter-household transfers of food. The present research observes transfers of meat over a yearlong period among 25 households of indigenous Mayangna and Miskito horticulturalists in Nicaragua. To analyze these data, we extend the multilevel formulation of the social relations model to count data, namely the number of portions of meat exchanged between households. Along with other covariates, we examine the effect of an ``association index,'' which reflects the amount of time that households interact with one another. The association index exhibits a positive effect on sharing, and our overall results indicate that food sharing networks largely correspond to kin-based networks of social interaction, suggesting that food sharing is embedded in broader social relationships between households. We discuss possible extensions of our methodological approach, as appropriate for research on food sharing and social network analysis more broadly.},
  file = {/Users/solomonkurz/Zotero/storage/4KUGED2E/Koster and Leckie - 2014 - Food sharing networks in lowland Nicaragua An app.pdf;/Users/solomonkurz/Zotero/storage/H6X59WZN/S0378873314000148.html},
  journal = {Social Networks},
  keywords = {Association networks,Behavioral ecology,Cooperation,Count data,Multilevel model,Social relations model},
  language = {en}
}

@article{kruschkeBayesianNewStatistics2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  month = feb,
  volume = {25},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  url = {https://link.springer.com/content/pdf/10.3758/s13423-016-1221-4.pdf},
  urldate = {2020-05-18},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  file = {/Users/solomonkurz/Zotero/storage/SRKQT967/Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {1}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Academic Press}},
  url = {https://sites.google.com/site/doingbayesiandataanalysis/}
}

@article{kruschkePosteriorPredictiveChecks2013,
  title = {Posterior Predictive Checks Can and Should Be {{Bayesian}}: {{Comment}} on {{Gelman}} and {{Shalizi}}, `{{Philosophy}} and the Practice of {{Bayesian}} Statistics'},
  shorttitle = {Posterior Predictive Checks Can and Should Be {{Bayesian}}},
  author = {Kruschke, John K.},
  year = {2013},
  volume = {66},
  pages = {45--56},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.2012.02063.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.2012.02063.x},
  urldate = {2020-05-18},
  abstract = {Bayesian inference is conditional on the space of models assumed by the analyst. The posterior distribution indicates only which of the available parameter values are less bad than the others, without indicating whether the best available parameter values really fit the data well. A posterior predictive check is important to assess whether the posterior predictions of the least bad parameters are discrepant from the actual data in systematic ways. Gelman and Shalizi (2012a) assert that the posterior predictive check, whether done qualitatively or quantitatively, is non-Bayesian. I suggest that the qualitative posterior predictive check might be Bayesian, and the quantitative posterior predictive check should be Bayesian. In particular, I show that the `Bayesian p-value', from which an analyst attempts to reject a model without recourse to an alternative model, is ambiguous and inconclusive. Instead, the posterior predictive check, whether qualitative or quantitative, should be consummated with Bayesian estimation of an expanded model. The conclusion agrees with Gelman and Shalizi regarding the importance of the posterior predictive check for breaking out of an initially assumed space of models. Philosophically, the conclusion allows the liberation to be completely Bayesian instead of relying on a non-Bayesian deus ex machina. Practically, the conclusion cautions against use of the Bayesian p-value in favour of direct model expansion and Bayesian evaluation.},
  copyright = {\textcopyright{} 2012 The British Psychological Society},
  file = {/Users/solomonkurz/Zotero/storage/T32AK4DC/j.2044-8317.2012.02063.html},
  journal = {British Journal of Mathematical and Statistical Psychology},
  language = {en},
  number = {1}
}

@article{kullbackInformationSufficiency1951,
  title = {On Information and Sufficiency},
  author = {Kullback, S. and Leibler, R. A.},
  year = {1951},
  month = mar,
  volume = {22},
  pages = {79--86},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177729694},
  url = {https://projecteuclid.org/euclid.aoms/1177729694},
  urldate = {2020-06-01},
  abstract = {Project Euclid - mathematics and statistics online},
  file = {/Users/solomonkurz/Zotero/storage/ZRSE9FMG/Kullback and Leibler - 1951 - On Information and Sufficiency.pdf;/Users/solomonkurz/Zotero/storage/QVXJE6S9/1177729694.html},
  journal = {Annals of Mathematical Statistics},
  language = {EN},
  mrnumber = {MR39968},
  number = {1},
  zmnumber = {0042.38403}
}

@book{kurzDoingBayesianData2020,
  title = {Doing {{Bayesian}} Data Analysis in Brms and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = may,
  edition = {version 0.2.0},
  url = {https://bookdown.org/content/3686/},
  urldate = {2020-05-22},
  abstract = {This project is an attempt to re-express the code in Kruschke's (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/UKHWZ73Z/3686.html}
}

@book{kurzRecodingIntroductionMediation2019,
  title = {Recoding {{Introduction}} to Mediation, Moderation, and Conditional Process Analysis},
  author = {Kurz, A. Solomon},
  year = {2019},
  month = dec,
  edition = {version 1.1.0},
  doi = {10.5281/zenodo.3589999},
  url = {https://bookdown.org/ajkurz/recoding_Hayes_2018/},
  urldate = {2020-06-10},
  abstract = {This project is an effort to connect his Hayes's conditional process analysis work with the Bayesian paradigm. Herein I refit his models with my favorite R package for Bayesian regression, B\"urkner's brms, and use the tidyverse for data manipulation and plotting.},
  file = {/Users/solomonkurz/Zotero/storage/IKVQT47J/recoding_Hayes_2018.html}
}

@book{kurzStatisticalRethinkingBrms2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = mar,
  edition = {version 1.1.0},
  doi = {10.5281/zenodo.3693202},
  url = {https://bookdown.org/content/3890/},
  urldate = {2020-05-16},
  abstract = {This project is an attempt to re-express the code in McElreath's textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html}
}

@article{lakensEquivalenceTestingPsychological2018,
  title = {Equivalence Testing for Psychological Research: {{A}} Tutorial},
  shorttitle = {Equivalence Testing for Psychological Research},
  author = {Lakens, Dani{\"e}l and Scheel, Anne M. and Isager, Peder M.},
  year = {2018},
  volume = {1},
  pages = {259--269},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/2515245918770963},
  file = {/Users/solomonkurz/Zotero/storage/ARE8PRAA/Lakens et al. - 2018 - Equivalence testing for psychological research A .pdf;/Users/solomonkurz/Zotero/storage/X8WDV6SQ/2515245918770963.html},
  journal = {Advances in Methods and Practices in Psychological Science},
  number = {2}
}

@article{lakensEquivalenceTestingSecond2018,
  title = {Equivalence Testing and the Second Generation P-Value},
  author = {Lakens, Dani{\"e}l and Delacre, Marie},
  year = {2018},
  month = aug,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/7k6ay},
  url = {https://psyarxiv.com/7k6ay/},
  urldate = {2020-05-16},
  abstract = {To move beyond the limitations of null-hypothesis tests, statistical approaches have been developed where the observed data is compared against a range of values that are equivalent to the absence of a meaningful effect. Specifying a range of values around zero allows researchers to statistically reject the presence of effects large enough to matter, and prevents practically insignificant effects from being interpreted as a statistically significant difference. We compare the behavior of the recently proposed second generation p-value (Blume, D'Agostino McGowan, Dupont, \& Greevy, 2018) with the more established Two One-Sided Tests (TOST) equivalence testing procedure (Schuirmann, 1987). We show that the two approaches yield almost identical results under optimal conditions. Under suboptimal conditions (e.g., when the confidence interval is wider than the equivalence range, or when confidence intervals are asymmetric) the second generation p-value becomes difficult to interpret as a descriptive statistic. The second generation p-value is interpretable in a dichotomous manner (i.e., when the SGPV equals 0 or 1 because the confidence intervals lies completely within or outside of the equivalence range), but this dichotomous interpretation does not require calculations. We conclude that equivalence tests yield more consistent p-values, distinguish between datasets that yield the same second generation p-value, and allow for easier control of Type I and Type II error rates.},
  file = {/Users/solomonkurz/Zotero/storage/8NTJHU7N/Lakens and Delacre - 2018 - Equivalence Testing and the Second Generation P-Va.pdf;/Users/solomonkurz/Zotero/storage/UVGXMXC9/7k6ay.html}
}

@article{lakensImprovingInferencesNull2020,
  title = {Improving Inferences about Null Effects with {{Bayes}} Factors and Equivalence Tests},
  author = {Lakens, Dani{\"e}l and McLatchie, Neil and Isager, Peder M and Scheel, Anne M and Dienes, Zoltan},
  editor = {Isaacowitz, Derek},
  year = {2020},
  month = jan,
  volume = {75},
  pages = {45--57},
  issn = {1079-5014, 1758-5368},
  doi = {10.1093/geronb/gby065},
  url = {https://academic.oup.com/psychsocgerontology/article/75/1/45/5033832},
  urldate = {2020-05-16},
  abstract = {Abstract
            Researchers often conclude an effect is absent when a null-hypothesis significance test yields a nonsignificant p value. However, it is neither logically nor statistically correct to conclude an effect is absent when a hypothesis test is not significant. We present two methods to evaluate the presence or absence of effects: Equivalence testing (based on frequentist statistics) and Bayes factors (based on Bayesian statistics). In four examples from the gerontology literature, we illustrate different ways to specify alternative models that can be used to reject the presence of a meaningful or predicted effect in hypothesis tests. We provide detailed explanations of how to calculate, report, and interpret Bayes factors and equivalence tests. We also discuss how to design informative studies that can provide support for a null model or for the absence of a meaningful effect. The conceptual differences between Bayes factors and equivalence tests are discussed, and we also note when and why they might lead to similar or different inferences in practice. It is important that researchers are able to falsify predictions or can quantify the support for predicted null effects. Bayes factors and equivalence tests provide useful statistical tools to improve inferences about null effects.},
  file = {/Users/solomonkurz/Zotero/storage/RAXAMC8E/Lakens et al. - 2020 - Improving Inferences About Null Effects With Bayes.pdf},
  journal = {The Journals of Gerontology: Series B},
  language = {en},
  number = {1}
}

@article{leeModelingIndividualDifferences2005,
  title = {Modeling Individual Differences in Cognition},
  author = {Lee, Michael D. and Webb, Michael R.},
  year = {2005},
  month = aug,
  volume = {12},
  pages = {605--621},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03196751},
  url = {http://link.springer.com/10.3758/BF03196751},
  urldate = {2020-05-16},
  file = {/Users/solomonkurz/Zotero/storage/7GYW7HR7/Lee and Webb - 2005 - Modeling individual differences in cognition.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {4}
}

@book{leglerBroadeningYourStatistical2019,
  title = {Broadening Your Statistical Horizons: {{Generalized}} Linear Models and Multilevel Models},
  author = {Legler, Julie and Roback, Paul},
  year = {2019},
  url = {https://bookdown.org/roback/bookdown-bysh/}
}

@article{likertTechniqueMeasurementAttitudes1932,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, R.},
  year = {1932},
  volume = {22  140},
  pages = {55--55},
  url = {https://legacy.voteview.com/pdf/Likert_1932.pdf},
  abstract = {The project conceived in 1929 by Gardner Murphy and the writer aimed first to present a wide array of problems having to do with five major "attitude areas"\textemdash international relations, race relations, economic conflict, political conflict, and religion. The kind of questionnaire material falls into four classes: yes-no, multiple choice, propositions to be responded to by degrees of approval, and a series of brief newspaper narratives to be approved or disapproved in various degrees. The monograph aims to describe a technique rather than to give results. The appendix, covering ten pages, shows the method of constructing an attitude scale. A bibliography is also given. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/3VW2VGT5/1933-01885-001.html},
  journal = {Archives of Psychology}
}

@article{liuBayesFactorsPrior2008,
  title = {Bayes Factors: {{Prior}} Sensitivity and Model Generalizability},
  author = {Liu, Charles C and Aitkin, Murray},
  year = {2008},
  volume = {52},
  pages = {362--375},
  publisher = {{Elsevier}},
  url = {https://doi.org/10.1016/j.jmp.2008.03.002},
  journal = {Journal of Mathematical Psychology},
  number = {6}
}

@misc{LongitudinalAnalysisModeling,
  title = {Longitudinal {{Analysis}}: {{Modeling Within}}-{{Person Fluctuation}} and {{Change}}},
  shorttitle = {Longitudinal {{Analysis}}},
  url = {https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025},
  urldate = {2020-08-06},
  abstract = {Longitudinal Analysis provides an accessible, application-oriented treatment of introductory and advanced linear models for within-person fluctuation and change. Organized by research design and data type, the text uses in-depth examples to provide a complete description of the model-building process. The core longitudinal models and their extensions are presented within a multilevel modeling framework, paying careful attention to the modeling concerns that are unique to longitudinal data. Writt},
  journal = {Routledge \& CRC Press},
  language = {en}
}

@book{luceIndividualChoiceBehavior2012,
  title = {Individual Choice Behavior: {{A}} Theoretical Analysis},
  shorttitle = {Individual {{Choice Behavior}}},
  author = {Luce, R. Duncan},
  year = {2012},
  month = jun,
  publisher = {{Courier Corporation}},
  abstract = {This influential treatise presents upper-level undergraduates and graduate students with a mathematical analysis of choice behavior. It begins with the statement of a general axiom upon which the rest of the book rests; the following three chapters, which may be read independently of each other, are devoted to applications of the theory to substantive problems: psychophysics, utility, and learning.Applications to psychophysics include considerations of time- and space-order effects, the Fechnerian assumption, the power law and its relation to discrimination data, interaction of continua, discriminal processes, signal detectability theory, and ranking of stimuli. The next major theme, utility theory, features unusual results that suggest an experiment to test the theory. The final chapters explore learning-related topics, analyzing the stochastic theories of learning as the basic approach\textemdash with the exception that distributions of response strengths are assumed to be transformed rather than response probabilities. The author arrives at three classes of learning operators, both linear and nonlinear, and the text concludes with a useful series of appendixes.},
  googlebooks = {ERQsKkPiKkkC},
  isbn = {978-0-486-15339-1},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{luceLuceChoiceAxiom2008,
  title = {Luce's Choice Axiom},
  author = {Luce, R. Duncan},
  year = {2008},
  month = dec,
  volume = {3},
  pages = {8077},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.8077},
  url = {http://www.scholarpedia.org/article/Luce\%27s_choice_axiom},
  urldate = {2020-05-18},
  file = {/Users/solomonkurz/Zotero/storage/PMGIVY8Z/Luce's_choice_axiom.html},
  journal = {Scholarpedia},
  language = {en},
  number = {12}
}

@book{mackay2003information,
  title = {Information Theory, Inference and Learning Algorithms},
  author = {MacKay, David JC},
  year = {2003},
  publisher = {{Cambridge University Press}},
  url = {https://www.inference.org.uk/itprnn/book.pdf}
}

@article{marinGgmcmcAnalysisMCMC2016,
  title = {{{ggmcmc}}: {{Analysis}} of {{MCMC}} Samples and {{Bayesian}} Inference},
  author = {i Mar{\'i}n, Xavier Fern{\'a}ndez},
  year = {2016},
  volume = {70},
  pages = {1--20},
  doi = {10.18637/jss.v070.i09},
  journal = {Journal of Statistical Software},
  number = {9}
}

@article{martoneDataSharingPsychology2018,
  title = {Data Sharing in Psychology},
  author = {Martone, Maryann E. and {Garcia-Castro}, Alexander and VandenBos, Gary R.},
  year = {2018},
  volume = {73},
  pages = {111--125},
  issn = {0003-066X},
  doi = {10.1037/amp0000242},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5920518/pdf/nihms935471.pdf},
  urldate = {2020-05-18},
  abstract = {Routine data sharing, defined here as the publication of the primary data and any supporting materials required to interpret the data acquired as part of a research study, is still in its infancy in psychology, as in many domains. Nevertheless, with increased scrutiny on reproducibility and more funder mandates requiring sharing of data, the issues surrounding data sharing are moving beyond whether data sharing is a benefit or a bane to science, to what data should be shared and how. Here, we present an overview of these issues, specifically focusing on the sharing of so-called ``long tail'' data, that is, data generated by individual laboratories as part of largely hypothesis-driven research. We draw on experiences in other domains to discuss attitudes towards data sharing, cost-benefits, best practices and infrastructure. We argue that the publishing of data sets is an integral component of 21st century scholarship. Moreover, although not all issues around how and what to share have been resolved, a consensus on principles and best practices for effective data sharing and the infrastructure for sharing many types of data are largely in place.},
  file = {/Users/solomonkurz/Zotero/storage/JXPYAVVI/Martone et al. - 2018 - Data Sharing in Psychology.pdf},
  journal = {The American psychologist},
  number = {2},
  pmcid = {PMC5920518},
  pmid = {29481105}
}

@book{MASS2002,
  title = {Modern Applied Statistics with {{S}}},
  author = {Venables, W. N. and Ripley, B. D.},
  year = {2002},
  edition = {Fourth},
  publisher = {{Springer}},
  address = {{New York}},
  url = {http://www.stats.ox.ac.uk/pub/MASS4}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2015},
  publisher = {{CRC press}},
  url = {https://xcelab.net/rm/statistical-rethinking/}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {Second edition},
  publisher = {{CRC Press}},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-63914-2},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@book{mcgrayneTheoryThatWould2011,
  title = {The Theory That Would Not Die: How {{Bayes}}' Rule Cracked the Enigma Code, Hunted down {{Russian}} Submarines, \& Emerged Triumphant from Two Centuries of Controversy},
  author = {McGrayne, Sharon Bertsch},
  year = {2011},
  publisher = {{Yale University Press}},
  url = {https://yalebooks.yale.edu/book/9780300188226/theory-would-not-die}
}

@article{meehlWhySummariesResearch1990,
  title = {Why Summaries of Research on Psychological Theories Are Often Uninterpretable},
  author = {Meehl, Paul E.},
  year = {1990},
  month = feb,
  volume = {66},
  pages = {195--244},
  publisher = {{SAGE Publications Inc}},
  issn = {0033-2941},
  doi = {10.2466/pr0.1990.66.1.195},
  url = {http://meehl.umn.edu/sites/meehl.dl.umn.edu/files/144whysummaries.pdf},
  urldate = {2020-05-25},
  abstract = {Null hypothesis testing of correlational predictions from weak substantive theories in soft psychology is subject to the influence of ten obfuscating factors whose effects are usually (1) sizeable, (2) opposed, (3) variable, and (4) unknown. The net epistemic effect of these ten obfuscating influences is that the usual research literature review is well-nigh uninterpretable. Major changes in graduate education, conduct of research, and editorial policy are proposed.},
  file = {/Users/solomonkurz/Zotero/storage/AYF7PQVK/Meehl - 1990 - Why Summaries of Research on Psychological Theorie.pdf},
  journal = {Psychological Reports},
  language = {en},
  number = {1}
}

@article{Merkle2018blavaan,
  title = {{{blavaan}}: {{Bayesian}} Structural Equation Models via Parameter Expansion},
  author = {Merkle, Edgar C. and Rosseel, Yves},
  year = {2018},
  volume = {85},
  pages = {1--30},
  doi = {10.18637/jss.v085.i04},
  journal = {Journal of Statistical Software},
  number = {4}
}

@article{metropolisEquationStateCalculations1953,
  title = {Equation of State Calculations by Fast Computing Machines},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
  year = {1953},
  volume = {21},
  pages = {1087--1092},
  publisher = {{American Institute of Physics}},
  doi = {10.1063/1.1699114},
  url = {https://bayes.wustl.edu/Manual/EquationOfState.pdf},
  journal = {The journal of chemical physics},
  number = {6}
}

@article{mgcv2003,
  title = {Thin-Plate Regression Splines},
  author = {Wood, Simon N},
  year = {2003},
  volume = {65},
  pages = {95--114},
  doi = {10.1111/1467-9868.00374},
  url = {https://s3.amazonaws.com/academia.edu.documents/50461038/1467-9868.0037420161121-28486-yjewi1.pdf?response-content-disposition=inline\%3B\%20filename\%3DThin_plate_regression_splines.pdf\&X-Amz-Algorithm=AWS4-HMAC-SHA256\&X-Amz-Credential=ASIATUSBJ6BANKOPOZEO\%2F20200524\%2Fus-east-1\%2Fs3\%2Faws4_request\&X-Amz-Date=20200524T180240Z\&X-Amz-Expires=3600\&X-Amz-SignedHeaders=host\&X-Amz-Security-Token=IQoJb3JpZ2luX2VjECEaCXVzLWVhc3QtMSJIMEYCIQDOX\%2FwTEMlLub97I\%2FMAMW8be650dvGXcsUS\%2FFT7fRLTFAIhALm6fierGHEIpDpqKXIzaF7X4n0Vgz6oeQya42qaxCUbKrQDCHkQABoMMjUwMzE4ODExMjAwIgz0HouvSIxUl554eAEqkQMCsNlb\%2BQSuS55lUhyF7eBFSq665pRSMi4DyFt0hNfLRi6gKXYUyv0Cqgog7u9dhX1rpMWmmOcD9bIZCqWNHirMlqynxY7K5\%2F5\%2BCosSEzqlDE5DA2oOH4hqgemL24qvpdh\%2F7sB57yZu5O4zlmsFHotrhhSCkMzk5JR3kvuC4BRjaI055JWQR\%2F\%2Bofp\%2Fuc\%2FlD\%2FGnQ8gUHBcw847tQyUPEZvPg0\%2Frv68j3I0jWjy2kon7Jgq5GJqjpD15aIQlUcLicQ0adoxfirnV3wS14m7\%2FNr0fdddpmOpJ\%2BPDlwyqGY6PN3oo9XZYUShrRkhzaOC8aERDg0N5WbWrGIMr0nFmoM4xZqBuxob1iHyTfpmrtN14YBEbGgVRPbCjc9YxwrPe7sr\%2B\%2Ff5\%2F71aNZfNW22td0HLuUiijGW1gKyKqEE907O3oDim0QD\%2B38EmW7N0apRBqZyE4oQA440ypSXABqa7\%2FkwspRZnBQVisqdMETD4m7W9jqTYr2OONaPJMTg\%2F2951ZbnQB87aczCx6fbb7K3snnOsQmHRDDRuKr2BTrqATfPzy8Sxe79\%2BEP54Yvh\%2FVuK9bF8SxInrfmJ1nITVtm3mhhleH9\%2BmbumR0HxkiPVqEXAq2C6wI5Akj6I3zXVzBFFnNzgPA\%2BHvWcUWBH33yJ4nmhZ8dDNMruPQ0H9lmya2noeaOr0w\%2FWS3VgLpkC\%2F\%2FCAjaFQydz1WZp1onsbpi66aeLxgsIecPfqD\%2FocvtDACzZxw3JSM7G\%2BSgSpcGdRvouHivT93d8hYmjLVYTXPR2J6BqwMC\%2BNXy\%2F4jBQcvWl08pPA0FjGdoNcestAXGwNkhsWv6RvMYo7rCpR5iyTlBkk5dNRz\%2FSl7wT37hA\%3D\%3D\&X-Amz-Signature=92b8be88b62ae556465c7e485d1f99917e86dad15ccaf9b0a7def69a5c716173},
  journal = {Journal of the Royal Statistical Society (B)},
  number = {1}
}

@article{mgcv2004,
  title = {Stable and Efficient Multiple Smoothing Parameter Estimation for Generalized Additive Models},
  author = {Wood, Simon N},
  year = {2004},
  volume = {99},
  pages = {673--686},
  doi = {10.1198/016214504000000980},
  url = {https://purehost.bath.ac.uk/ws/portalfiles/portal/9228711/magic.pdf},
  journal = {Journal of the American Statistical Association},
  number = {467}
}

@article{mgcv2011,
  title = {Fast Stable Restricted Maximum Likelihood and Marginal Likelihood Estimation of Semiparametric Generalized Linear Models},
  author = {Wood, Simon N},
  year = {2011},
  volume = {73},
  pages = {3--36},
  doi = {10.1111/j.1467-9868.2010.00749.x},
  url = {https://people.bath.ac.uk/man54/SAMBa/ITTs/ITT2/EDF/REMLWood2009.pdf},
  journal = {Journal of the Royal Statistical Society (B)},
  number = {1}
}

@article{mgcv2016,
  title = {Smoothing Parameter and Model Selection for General Smooth Models (with Discussion)},
  author = {Wood, Simon N and Pya, Natalya and S{\"a}fken, Benjamin},
  year = {2016},
  volume = {111},
  pages = {1548--1575},
  doi = {10.1080/01621459.2016.1180986},
  url = {https://doi.org/10.1080/01621459.2016.1180986},
  journal = {Journal of the American Statistical Association}
}

@book{mgcv2017,
  title = {Generalized Additive Models: {{An}} Introduction with r},
  author = {Wood, Simon N},
  year = {2017},
  edition = {Second},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://www.routledge.com/Generalized-Additive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331?utm_source=crcpress.com\&utm_medium=referral},
  isbn = {978-1-4987-2833-1}
}

@article{millerWhatProbabilityReplicating2009,
  title = {What Is the Probability of Replicating a Statistically Significant Effect?},
  author = {Miller, Jeff},
  year = {2009},
  month = aug,
  volume = {16},
  pages = {617--640},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/PBR.16.4.617},
  url = {http://link.springer.com/10.3758/PBR.16.4.617},
  urldate = {2020-05-16},
  file = {/Users/solomonkurz/Zotero/storage/6JP49JDB/Miller - 2009 - What is the probability of replicating a statistic.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {4}
}

@article{nakagawaCaseRetrospectiveStatistical2004,
  title = {The Case against Retrospective Statistical Power Analyses with an Introduction to Power Analysis},
  author = {Nakagawa, Shinichi and Foster, T. Mary},
  year = {2004},
  volume = {7},
  pages = {103--108},
  publisher = {{Springer}},
  address = {{Germany}},
  issn = {1437-9546(Electronic),0873-9749(Print)},
  doi = {10.1007/s10211-004-0095-z},
  url = {https://www.researchgate.net/publication/226772798_The_case_against_retrospective_statistical_power_analyses_with_an_introduction_to_power_analysis},
  abstract = {Statistical power analysis is an important tool for planning an experiment because this type of analysis allows researchers to identify an appropriate sample size for a particular experimental design. In recent years, it seems many biology journals have been encouraging researchers to calculate statistical power after their experiments when they have obtained non-significant results (hereafter, termed "retrospective power calculation or analysis" as opposed to "prospective power analysis", which is conducted pre-experimentally). The logic for retrospective power analysis for data interpretation is as follows. When a non-significant result is obtained (especially with small samples), we should examine the statistical power of the significance test. If the test had low statistical power (or a high Type-II error rate), we should reserve "acceptance" (or more properly "nonrejection") of H{$_0$}. The argument is that we may refer to the result as inconclusive because an increase in power (e.g. through an increase in sample size) might have produced a statistically significant result. On the other hand, if a nonsignificant result is obtained, despite high power (i.e. a low Type-II error rate), we can be fairly confident about the non-rejection of H{$_0$} (note that with results from null hypothesis significance testing, we can only reject or not reject H{$_0$}, but we cannot "accept" H{$_0$}-although the previously quoted sentence from Animal Behavior's instructions for authors seems to confuse this fact). Many researchers have both not recognized the serious logical flaw in retrospective power analysis when it is used for interpreting nonsignificant results and that an accurate understanding of power analysis has yet to be established among some researchers, especially among students in the study of animal behavior. The purpose of this article is-using the independent f-test as an example-to: (1) outline statistical power analysis and its components; (2) describe three common ways used to make retrospective power calculations and their logical flaws and shortcomings; (3) discuss solutions to the current situation and make recommendations. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/SG5KXE2E/2005-06529-008.html},
  journal = {Acta Ethologica},
  keywords = {Experimental Design,Null Hypothesis Testing,Statistical Analysis,Statistical Power,Type II Errors},
  number = {2}
}

@article{navarroDevilDeepBlue2019,
  title = {Between the Devil and the Deep Blue Sea: {{Tensions}} between Scientific Judgement and Statistical Model Selection},
  shorttitle = {Between the {{Devil}} and the {{Deep Blue Sea}}},
  author = {Navarro, Danielle J.},
  year = {2019},
  month = mar,
  volume = {2},
  pages = {28--34},
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-018-0019-z},
  url = {http://link.springer.com/10.1007/s42113-018-0019-z},
  urldate = {2020-05-15},
  abstract = {Discussions of model selection in the psychological literature typically frame the issues as a question of statistical inference, with the goal being to determine which model makes the best predictions about data. Within this setting, advocates of leaveone-out cross-validation and Bayes factors disagree on precisely which prediction problem model selection questions should aim to answer. In this comment, I discuss some of these issues from a scientific perspective. What goal does model selection serve when all models are known to be systematically wrong? How might ``toy problems'' tell a misleading story? How does the scientific goal of explanation align with (or differ from) traditional statistical concerns? I do not offer answers to these questions, but hope to highlight the reasons why psychological researchers cannot avoid asking them.},
  file = {/Users/solomonkurz/Zotero/storage/3D6FMZVD/Navarro - 2019 - Between the Devil and the Deep Blue Sea Tensions .pdf},
  journal = {Computational Brain \& Behavior},
  language = {en},
  number = {1}
}

@book{navarroLearningStatistics2019,
  title = {Learning Statistics with {{R}}},
  author = {Navarro, Danielle},
  year = {2019},
  url = {https://learningstatisticswithr.com},
  language = {en}
}

@incollection{neal2011mcmc,
  title = {{{MCMC}} Using {{Hamiltonian}} Dynamics},
  booktitle = {Handbook of {{Markov}} Chain {{Monte Carlo}}},
  author = {Neal, R},
  editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year = {2011},
  pages = {116--162},
  publisher = {{London, United Kingdom: Chapman \& Hall/CRC Press}},
  url = {https://arxiv.org/pdf/1206.1901.pdf}
}

@article{nealImprovedAcceptanceProcedure1994,
  title = {An Improved Acceptance Procedure for the Hybrid {{Monte Carlo}} Algorithm},
  author = {Neal, Radford M.},
  year = {1994},
  month = mar,
  volume = {111},
  pages = {194--203},
  issn = {0021-9991},
  doi = {10.1006/jcph.1994.1054},
  url = {http://www.sciencedirect.com/science/article/pii/S0021999184710540},
  urldate = {2020-05-16},
  abstract = {The probability of accepting a candidate move in the hybrid Monte Carlo algorithm can be increased by considering a transition to be between windows of several states at the beginning and end of the trajectory, with a particular state within the selected window then being chosen according to the Boltzmann probabilities. The detailed balance condition used to justify the algorithm still holds with this procedure, provided the start state is randomly positioned within its window. The new procedure is shown empirically to significantly improve the acceptance rate for a test system of uncoupled oscillators. It also allows expectations to be estimated using data from all states in the windows, rather than just states that are accepted.},
  file = {/Users/solomonkurz/Zotero/storage/4G66CMT3/Neal - 1994 - An Improved Acceptance Procedure for the Hybrid Mo.pdf;/Users/solomonkurz/Zotero/storage/2RCV64ZH/S0021999184710540.html},
  journal = {Journal of Computational Physics},
  language = {en},
  number = {1}
}

@article{nelder1972generalized,
  title = {Generalized Linear Models},
  author = {Nelder, John Ashworth and Wedderburn, Robert WM},
  year = {1972},
  volume = {135},
  pages = {370--384},
  publisher = {{Wiley Online Library}},
  doi = {10.2307/2344614},
  url = {https://repository.rothamsted.ac.uk/download/25425465aa52d05e1a9e553b2daddeeffe15d0ba40f5f9b8937aaab5c3d29e1d/4410096/Nelder\%201972.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  number = {3}
}

@article{normanLikertScalesLevels2010,
  title = {Likert Scales, Levels of Measurement and the ``Laws'' of Statistics},
  author = {Norman, Geoff},
  year = {2010},
  month = dec,
  volume = {15},
  pages = {625--632},
  issn = {1573-1677},
  doi = {10.1007/s10459-010-9222-y},
  url = {https://www.researchgate.net/publication/41420484_LIkert_scales_levels_of_measurement_adn_the_laws_of_statistics},
  urldate = {2020-05-18},
  abstract = {Reviewers of research reports frequently criticize the choice of statistical methods. While some of these criticisms are well-founded, frequently the use of various parametric methods such as analysis of variance, regression, correlation are faulted because: (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. In this paper, I dissect these arguments, and show that many studies, dating back to the 1930s consistently show that parametric statistics are robust with respect to violations of these assumptions. Hence, challenges like those above are unfounded, and parametric methods can be utilized without concern for ``getting the wrong answer''.},
  journal = {Advances in Health Sciences Education},
  language = {en},
  number = {5}
}

@article{nunn2012ruggedness,
  title = {Ruggedness: {{The}} Blessing of Bad Geography in {{Africa}}},
  author = {Nunn, Nathan and Puga, Diego},
  year = {2012},
  volume = {94},
  pages = {20--36},
  publisher = {{MIT Press}},
  doi = {10.1162/REST_a_00161},
  url = {https://scholar.harvard.edu/files/nunn/files/ruggedness.pdf},
  journal = {Review of Economics and Statistics},
  number = {1}
}

@article{okeefeBriefReportPost2007,
  title = {Brief Report: {{Post}} Hoc Power, Observed Power, a Priori Power, Retrospective Power, Prospective Power, Achieved Power: {{Sorting}} out Appropriate Uses of Statistical Power Analyses},
  shorttitle = {Brief {{Report}}},
  author = {O'Keefe, Daniel J.},
  year = {2007},
  month = dec,
  volume = {1},
  pages = {291--299},
  issn = {1931-2458, 1931-2466},
  doi = {10.1080/19312450701641375},
  url = {http://www.dokeefe.net/pub/OKeefe07CMM-posthoc.pdf},
  urldate = {2020-05-16},
  file = {/Users/solomonkurz/Zotero/storage/5M3I5XMH/O'Keefe - 2007 - Brief Report Post Hoc Power, Observed Power, A Pr.pdf},
  journal = {Communication Methods and Measures},
  language = {en},
  number = {4}
}

@article{parkBayesianMultilevelEstimation2004,
  title = {Bayesian Multilevel Estimation with Poststratification: {{State}}-Level Estimates from National Polls},
  shorttitle = {Bayesian {{Multilevel Estimation}} with {{Poststratification}}},
  author = {Park, David K. and Gelman, Andrew and Bafumi, Joseph},
  year = {2004},
  volume = {12},
  pages = {375--385},
  publisher = {{[Oxford University Press, Society for Political Methodology]}},
  issn = {1047-1987},
  url = {https://www.jstor.org/stable/25791784},
  urldate = {2020-07-27},
  abstract = {We fit a multilevel logistic regression model for the mean of a binary response variable conditional on poststratification cells. This approach combines the modeling approach often used in small-area estimation with the population information used in poststratification (see Gelman and Little 1997, Survey Methodology 23:127\textendash 135). To validate the method, we apply it to U.S. preelection polls for 1988 and 1992, poststratified by state, region, and the usual demographic variables. We evaluate the model by comparing it to state-level election outcomes. The multilevel model outperforms more commonly used models in political science. We envision the most important usage of this method to be not forecasting elections but estimating public opinion on a variety of issues at the state level.},
  journal = {Political Analysis},
  number = {4}
}

@article{Pedersen2020AddingAnnotation,
  title = {Adding Annotation and Style},
  author = {Pedersen, Thomas L},
  year = {2020},
  url = {https://patchwork.data-imaginist.com/articles/guides/annotation.html}
}

@article{Pedersen2020PlotAssembly,
  title = {Plot Assembly},
  author = {Pedersen, Thomas L},
  year = {2020},
  url = {https://patchwork.data-imaginist.com/articles/guides/assembly.html}
}

@book{pengMasteringSoftwareDevelopment2017,
  title = {Mastering Software Development in \{\vphantom\}{{R}}\vphantom\{\}},
  author = {Peng, Roger D. and Kross, Sean and Anderson, Brooke},
  year = {2017},
  month = sep,
  url = {https://github.com/rdpeng/RProgDA},
  urldate = {2020-07-29},
  abstract = {The book covers R software development for building data science tools. As the field of data science evolves, it has become clear that software development skills are essential for producing useful data science results and products. You will obtain rigorous training in the R language, including the skills for handling complex data, building R packages and developing custom data visualizations. You will learn modern software development practices to build tools that are highly reusable, modular, and suitable for use in a team-based environment or a community of developers.},
  file = {/Users/solomonkurz/Zotero/storage/97WUVMRH/RProgDA.html}
}

@book{pengProgrammingDataScience2019,
  title = {R Programming for Data Science},
  author = {Peng, Roger D.},
  year = {2019},
  url = {https://bookdown.org/rdpeng/rprogdatascience/}
}

@article{piironenSparsityInformationRegularization2017,
  title = {Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors},
  author = {Piironen, Juho and Vehtari, Aki},
  year = {2017},
  volume = {11},
  pages = {5018--5051},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  issn = {1935-7524},
  doi = {10.1214/17-EJS1337SI},
  url = {https://projecteuclid.org/euclid.ejs/1513306866},
  urldate = {2020-05-16},
  abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
  file = {/Users/solomonkurz/Zotero/storage/3JJ5T858/Piironen and Vehtari - 2017 - Sparsity information and regularization in the hor.pdf;/Users/solomonkurz/Zotero/storage/SX6KLCX7/1513306866.html},
  journal = {Electronic Journal of Statistics},
  keywords = {Bayesian inference,horseshoe prior,shrinkage priors,sparse estimation},
  language = {EN},
  mrnumber = {MR3738204},
  number = {2},
  zmnumber = {06825039}
}

@misc{PivotDataWide2020,
  title = {Pivot Data from Wide to Long \textemdash{} Pivot\_longer},
  year = {2020},
  url = {https://tidyr.tidyverse.org/reference/pivot_longer.html},
  urldate = {2020-05-21},
  abstract = {pivot\_longer() "lengthens" data, increasing the number of rows and
decreasing the number of columns. The inverse transformation is
pivot\_wider()
Learn more in vignette("pivot").},
  file = {/Users/solomonkurz/Zotero/storage/D62EQVQQ/pivot_longer.html},
  language = {en}
}

@misc{Pivoting2020,
  title = {Pivoting},
  year = {2020},
  url = {https://tidyr.tidyverse.org/articles/pivot.html},
  urldate = {2020-05-21},
  abstract = {Learn how use the new `pivot\_longer()` and `pivot\_wider()` functions which change the representation of a dataset without changing the data it contains.},
  file = {/Users/solomonkurz/Zotero/storage/AAYYSFTP/pivot.html},
  language = {en}
}

@article{plummerJAGSProgramAnalysis2003,
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  author = {Plummer, Martyn},
  year = {2003},
  pages = {8},
  url = {http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/Plummer.pdf},
  abstract = {JAGS is a program for Bayesian Graphical modelling which aims for compatibility with Classic BUGS. The program could eventually be developed as an R package. This article explains the motivations for this program, briefly describes the architecture and then discusses some ideas for a vectorized form of the BUGS language.},
  file = {/Users/solomonkurz/Zotero/storage/UX2NECXA/Plummer - 2003 - JAGS A program for analysis of Bayesian graphical.pdf},
  journal = {Working Papers},
  language = {en}
}

@manual{R-ape,
  title = {Ape: {{Analyses}} of Phylogenetics and Evolution},
  author = {Paradis, Emmanuel and Blomberg, Simon and Bolker, Ben and Brown, Joseph and Claramunt, Santiago and Claude, Julien and Cuong, Hoa Sien and Desper, Richard and Didier, Gilles and Durand, Benoit and Dutheil, Julien and Ewing, RJ and Gascuel, Olivier and Guillerme, Thomas and Heibl, Christoph and Ives, Anthony and Jones, Bradley and Krah, Franz and Lawson, Daniel and Lefort, Vincent and Legendre, Pierre and Lemon, Jim and Louvel, Guillaume and Marcon, Eric and McCloskey, Rosemary and Nylander, Johan and {Opgen-Rhein}, Rainer and Popescu, Andrei-Alin and {Royer-Carenzi}, Manuela and Schliep, Klaus and Strimmer, Korbinian and {de Vienne}, Damien},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ape},
  type = {Manual}
}

@book{R-base,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@book{R-bayesplot,
  title = {{{bayesplot}}: {{Plotting}} for {{Bayesian}} Models},
  author = {Gabry, Jonah and Mahr, Tristan},
  year = {2019},
  url = {https://CRAN.R-project.org/package=bayesplot}
}

@book{R-blavaan,
  title = {{{blavaan}}: {{Bayesian}} Latent Variable Analysis},
  author = {Merkle, Edgar C. and Rosseel, Yves and Goodrich, Ben},
  year = {2020},
  url = {https://CRAN.R-project.org/package=blavaan}
}

@book{R-bookdown,
  title = {Bookdown: {{Authoring}} Books and Technical Documents with {{R Markdown}}},
  author = {Xie, Yihui},
  year = {2020},
  url = {https://CRAN.R-project.org/package=bookdown}
}

@book{R-brms,
  title = {{{brms}}: {{Bayesian}} Regression Models Using '{{Stan}}'},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms}
}

@book{R-dagitty,
  title = {{{dagitty}}: {{Graphical}} Analysis of Structural Causal Models},
  author = {Textor, Johannes and van {der Zander}, Benito},
  year = {2016},
  url = {https://CRAN.R-project.org/package=dagitty}
}

@book{R-dplyr,
  title = {{{dplyr}}: {{A}} Grammar of Data Manipulation},
  author = {Wickham, Hadley and Fran{\c c}ois, Romain and Henry, Lionel and M{\"u}ller, Kirill},
  year = {2020},
  url = {https://CRAN.R-project.org/package=dplyr}
}

@manual{R-dutchmasters,
  title = {{{dutchmasters}}},
  author = {Thoen, Edwin},
  year = {2019},
  url = {https://github.com/EdwinTh/dutchmasters},
  type = {Manual}
}

@book{R-forcats,
  title = {{{forcats}}: {{Tools}} for Working with Categorical Variables (Factors)},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=forcats}
}

@book{R-GGally,
  title = {{{GGally}}: {{Extension}} to 'Ggplot2'},
  author = {Schloerke, Barret and Crowley, Jason and {Di Cook} and Briatte, Francois and Marbach, Moritz and Thoen, Edwin and Elberg, Amos and Larmarange, Joseph},
  year = {2020},
  url = {https://CRAN.R-project.org/package=GGally}
}

@book{R-ggdag,
  title = {{{ggdag}}: {{Analyze}} and Create Elegant Directed Acyclic Graphs},
  author = {Barrett, Malcolm},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggdag}
}

@book{R-ggExtra,
  title = {{{ ggExtra}}: {{Add}} Marginal Histograms to 'Ggplot2', and More 'ggplot2' Enhancements},
  author = {Attali, Dean and Baker, Christopher},
  year = {2019},
  url = {https://CRAN.R-project.org/package=ggExtra}
}

@book{R-ggmcmc,
  title = {{{ggmcmc}}: {{Tools}} for Analyzing {{MCMC}} Simulations from {{Bayesian}} Inference},
  author = {i Mar{\'i}n, Xavier Fern{\'a}ndez},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggmcmc}
}

@book{R-ggmcmc,
  title = {{{ggmcmc}}: {{Tools}} for Analyzing {{MCMC}} Simulations from {{Bayesian}} Inference},
  author = {{Fern{\'a}ndez i Mar{\'i}n}, Xavier},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggmcmc}
}

@book{R-ggplot2,
  title = {{{ggplot2}}: {{Create}} Elegant Data Visualisations Using the Grammar of Graphics},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggplot2}
}

@manual{R-ggpomological,
  title = {{{ggpomological}}: {{Pomological}} Plot Theme for Ggplot2},
  author = {{Aden-Buie}, Garrick},
  year = {2020},
  url = {https://github.com/gadenbuie/ggpomological},
  type = {Manual}
}

@book{R-ggrepel,
  title = {{{ggrepel}}: {{Automatically}} Position Non-Overlapping Text Labels with 'Ggplot2'},
  author = {Slowikowski, Kamil},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggrepel}
}

@book{R-ggridges,
  title = {{{ggridges}}: {{Ridgeline Plots}} in 'Ggplot2'},
  author = {Wilke, Claus O.},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggridges}
}

@book{R-ggthemes,
  title = {{{ggthemes}}: {{Extra}} Themes, Scales and Geoms for 'Ggplot2'},
  author = {Arnold, Jeffrey B.},
  year = {2019},
  url = {https://CRAN.R-project.org/package=ggthemes}
}

@manual{R-ghibli,
  title = {Ghibli: {{Studio}} Ghibli Colour Palettes},
  author = {Henderson, Ewen},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ghibli},
  type = {Manual}
}

@book{R-gridExtra,
  title = {{{gridExtra}}: {{Miscellaneous}} Functions for "Grid" Graphics},
  author = {Auguie, Baptiste},
  year = {2017},
  url = {https://CRAN.R-project.org/package=gridExtra}
}

@book{R-janitor,
  title = {{{janitor}}: {{Simple}} Tools for Examining and Cleaning Dirty Data},
  author = {Firke, Sam},
  year = {2020},
  url = {https://CRAN.R-project.org/package=janitor}
}

@book{R-lme4,
  title = {{{lme4}}: {{Linear}} Mixed-Effects Models Using {{Eigen}}' and {{S4}}},
  author = {Bates, Douglas and Maechler, Martin and Bolker, Ben and Walker, Steven},
  year = {2020},
  url = {https://CRAN.R-project.org/package=lme4}
}

@book{R-loo,
  title = {{{loo}}: {{Efficient}} Leave-One-out Cross-Validation and {{WAIC}} for Bayesian Models},
  author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  url = {https://CRAN.R-project.org/package=loo}
}

@book{R-MASS,
  title = {{{MASS}}: {{Support}} Functions and Datasets for Venables and Ripley's {{MASS}}},
  author = {Ripley, Brian},
  year = {2019},
  url = {https://CRAN.R-project.org/package=MASS}
}

@book{R-metRology,
  title = {{{metRology}}: {{Support}} for Metrological Applications},
  author = {Ellison., Stephen L R},
  year = {2018},
  url = {https://CRAN.R-project.org/package=metRology}
}

@book{R-mgcv,
  title = {{{mgcv}}: {{Mixed GAM}} Computation Vehicle with Automatic Smoothness Estimation},
  author = {Wood, Simon N},
  year = {2019},
  url = {https://CRAN.R-project.org/package=mgcv}
}

@book{R-patchwork,
  title = {{{patchwork}}: {{The}} Composer of Plots},
  author = {Pedersen, Thomas Lin},
  year = {2019},
  url = {https://CRAN.R-project.org/package=patchwork}
}

@book{R-psych,
  title = {{{psych}}: {{Procedures}} for Psychological, Psychometric, and Personality Research},
  author = {Revelle, William},
  year = {2020},
  url = {https://CRAN.R-project.org/package=psych}
}

@book{R-purrr,
  title = {{{purrr}}: {{Functional}} Programming Tools},
  author = {Henry, Lionel and Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=purrr}
}

@book{R-rcartocolor,
  title = {{{rcartocolor}}: '{{CARTOColors}}' Palettes},
  author = {Nowosad, Jakub},
  year = {2019},
  url = {https://CRAN.R-project.org/package=rcartocolor}
}

@book{R-readr,
  title = {{{readr}}: {{Read}} Rectangular Text Data},
  author = {Wickham, Hadley and Hester, Jim and Francois, Romain},
  year = {2018},
  url = {https://CRAN.R-project.org/package=readr}
}

@book{R-reshape2,
  title = {{{reshape2}}: {{Flexibly}} Reshape Data: {{A}} Reboot of the Reshape Package},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=reshape2}
}

@book{R-rethinking,
  title = {{{rethinking}} {{R}} Package},
  author = {McElreath, Richard},
  year = {2020},
  url = {https://xcelab.net/rm/software/}
}

@book{R-rethinking,
  title = {{{rethinking}} {{R}} Package},
  author = {McElreath, Richard},
  year = {2020},
  url = {https://xcelab.net/rm/software/}
}

@manual{R-rstanarm,
  title = {{{rstanarm}}: {{Bayesian}} Applied Regression Modeling via Stan},
  author = {Gabry, Jonah and Goodrich, Ben},
  year = {2020},
  url = {https://CRAN.R-project.org/package=rstanarm},
  type = {Manual}
}

@book{R-santoku,
  title = {{{santoku}}: {{A}} Versatile Cutting Tool},
  author = {{Hugh-Jones}, David},
  year = {2020},
  url = {https://CRAN.R-project.org/package=santoku}
}

@manual{R-statebins,
  title = {{{statebins}}: {{Create}} United States Uniform Cartogram Heatmaps},
  author = {Rudis, Bob},
  year = {2020},
  url = {https://CRAN.R-project.org/package=statebins},
  type = {Manual}
}

@book{R-stringr,
  title = {{{stringr}}: {{Simple}}, Consistent Wrappers for Common String Operations},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=stringr}
}

@book{R-tibble,
  title = {{{tibble}}: {{Simple}} Data Frames},
  author = {M{\"u}ller, Kirill and Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=tibble}
}

@book{R-tidybayes,
  title = {{{tidybayes}}: {{Tidy}} Data and 'geoms' for {{Bayesian}} Models},
  author = {Kay, Matthew},
  year = {2020},
  url = {http://mjskay.github.io/tidybayes}
}

@book{R-tidyr,
  title = {{{tidyr}}: {{Tidy}} Messy Data},
  author = {Wickham, Hadley and Henry, Lionel},
  year = {2020},
  url = {https://CRAN.R-project.org/package=tidyr}
}

@book{R-tidyverse,
  title = {{{tidyverse}}: {{Easily}} Install and Load the 'Tidyverse'},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@book{R-urbnmapr,
  title = {{{urbnmapr}}: {{State}} and County Maps with {{Alaska}} and {{Hawaii}}},
  author = {{Urban Institute}},
  year = {2020},
  url = {https://github.com/UrbanInstitute/urbnmapr}
}

@manual{R-wesanderson,
  title = {Wesanderson: {{A}} Wes Anderson Palette Generator},
  author = {Ram, Karthik and Wickham, Hadley},
  year = {2018},
  url = {https://CRAN.R-project.org/package=wesanderson},
  type = {Manual}
}

@article{rastModelingIndividualDifferences2012,
  title = {Modeling Individual Differences in Within-Person Variation of Negative and Positive Affect in a Mixed Effects Location Scale Model Using {{BUGS}}/{{JAGS}}},
  author = {Rast, Philippe and Hofer, Scott M. and Sparks, Catharine},
  year = {2012},
  month = mar,
  volume = {47},
  pages = {177--200},
  publisher = {{Routledge}},
  issn = {0027-3171},
  doi = {10.1080/00273171.2012.658328},
  url = {https://doi.org/10.1080/00273171.2012.658328},
  urldate = {2020-08-05},
  abstract = {A mixed effects location scale model was used to model and explain individual differences in within-person variability of negative and positive affect across 7 days (N=178) within a measurement burst design. The data come from undergraduate university students and are pooled from a study that was repeated at two consecutive years. Individual differences in level and change in mood was modeled with a random intercept and random slope where the residual within-person variability was allowed to vary across participants. Additionally changes in within-person variability were explained by the inclusion of a time-varying predictor indicating the severity of daily stressors. This model accounted for 2 location and 2 scale effects and provided evidence that individuals who reported higher severity in daily stressors also exhibited greater variability in affect\textemdash but only for participants who showed low overall affect variability and who reported low average negative affect. Those who were more variable in their affect reports overall were less reactive to daily stressors in the sense that their high levels of affect variability remained high. We describe the utility of this model for further research on individual variation and change.},
  file = {/Users/solomonkurz/Zotero/storage/6C5DIABL/00273171.2012.html},
  journal = {Multivariate Behavioral Research},
  number = {2},
  pmid = {26734847}
}

@article{rosaCloseLookTherapeutic1998,
  title = {A Close Look at Therapeutic Touch},
  author = {Rosa, Linda and Rosa, Emily and Sarner, Larry and Barrett, Stephen},
  year = {1998},
  volume = {279},
  pages = {1005--1010},
  publisher = {{American Medical Association}},
  doi = {10.1001/jama.279.13.1005},
  journal = {JAMA},
  number = {13}
}

@article{rouderDefaultBayesFactors2012,
  title = {Default {{Bayes}} Factors for {{ANOVA}} Designs},
  author = {Rouder, Jeffrey N. and Morey, Richard D. and Speckman, Paul L. and Province, Jordan M.},
  year = {2012},
  month = oct,
  volume = {56},
  pages = {356--374},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2012.08.001},
  url = {http://pcl.missouri.edu/sites/default/files/Rouder.JMP_.2012.pdf},
  urldate = {2020-05-18},
  abstract = {Bayes factors have been advocated as superior to p-values for assessing statistical evidence in data. Despite the advantages of Bayes factors and the drawbacks of p-values, inference by p-values is still nearly ubiquitous. One impediment to the adoption of Bayes factors is a lack of practical development, particularly a lack of ready-to-use formulas and algorithms. In this paper, we discuss and expand a set of default Bayes factor tests for ANOVA designs. These tests are based on multivariate generalizations of Cauchy priors on standardized effects, and have the desirable properties of being invariant with respect to linear transformations of measurement units. Moreover, these Bayes factors are computationally convenient, and straightforward sampling algorithms are provided. We cover models with fixed, random, and mixed effects, including random interactions, and do so for within-subject, between-subject, and mixed designs. We extend the discussion to regression models with continuous covariates. We also discuss how these Bayes factors may be applied in nonlinear settings, and show how they are useful in differentiating between the power law and the exponential law of skill acquisition. In sum, the current development makes the computation of Bayes factors straightforward for the vast majority of designs in experimental psychology.},
  file = {/Users/solomonkurz/Zotero/storage/2MM7ERU8/S0022249612000806.html},
  journal = {Journal of Mathematical Psychology},
  keywords = {Bayes factor,Bayesian statistics,Linear models,Model selection},
  language = {en},
  number = {5}
}

@article{rouderWhatWhyHow2016,
  title = {The What, Why, and How of Born-Open Data},
  author = {Rouder, Jeffrey N.},
  year = {2016},
  month = sep,
  volume = {48},
  pages = {1062--1069},
  issn = {1554-3528},
  doi = {10.3758/s13428-015-0630-z},
  url = {https://link.springer.com/content/pdf/10.3758/s13428-015-0630-z.pdf},
  urldate = {2020-05-18},
  abstract = {Although many researchers agree that scientific data should be open to scrutiny to ferret out poor analyses and outright fraud, most raw data sets are not available on demand. There are many reasons researchers do not open their data, and one is technical. It is often time consuming to prepare and archive data. In response, my laboratory has automated the process such that our data are archived the night they are created without any human approval or action. All data are versioned, logged, time stamped, and uploaded including aborted runs and data from pilot subjects. The archive is GitHub, github.com, the world's largest collection of open-source materials. Data archived in this manner are called born open. In this paper, I discuss the benefits of born-open data and provide a brief technical overview of the process. I also address some of the common concerns about opening data before publication.},
  file = {/Users/solomonkurz/Zotero/storage/T89ALUJW/Rouder - 2016 - The what, why, and how of born-open data.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {3}
}

@article{rstanarm2018,
  title = {Joint Longitudinal and Time-to-Event Models via {{Stan}}.},
  author = {Brilleman, SL and Crowther, MJ and {Moreno-Betancur}, M and Buros Novik, J and Wolfe, R},
  year = {2018},
  url = {https://github.com/stan-dev/stancon_talks/}
}

@book{RStudio,
  title = {{{RStudio}}: {{Integrated}} Development Environment for {{R}}},
  author = {{RStudio Team}},
  year = {2020},
  publisher = {{RStudio, Inc.}},
  address = {{Boston, MA}},
  url = {http://www.rstudio.com/}
}

@article{shannonMathematicalTheoryCommunication1948,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, C. E.},
  year = {1948},
  volume = {27},
  pages = {379--423},
  issn = {1538-7305},
  doi = {10.1002/j.1538-7305.1948.tb01338.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1948.tb01338.x},
  urldate = {2020-06-06},
  copyright = {\textcopyright{} 1948 The Bell System Technical Journal},
  file = {/Users/solomonkurz/Zotero/storage/2ZYC5TAW/Shannon - 1948 - A Mathematical Theory of Communication.pdf;/Users/solomonkurz/Zotero/storage/GJ7QEDI3/j.1538-7305.1948.tb01338.html},
  journal = {Bell System Technical Journal},
  language = {en},
  number = {3}
}

@article{shapiroSexualActivityLifespan1994,
  title = {Sexual Activity and the Lifespan of Male Fruitflies: {{A}} Dataset That Gets Attention},
  shorttitle = {Sexual {{Activity}} and the {{Lifespan}} of {{Male Fruitflies}}},
  author = {Shapiro, H, Stanley},
  year = {1994},
  month = jul,
  volume = {2},
  pages = {null},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/10691898.1994.11910467},
  url = {https://doi.org/10.1080/10691898.1994.11910467},
  urldate = {2020-05-17},
  abstract = {This dataset contains observations on five groups of male fruitflies \textendash\textendash{} 25 fruitflies in each group \textendash\textendash{} from an experiment designed to test if increased reproduction reduces longevity for male fruitflies. (Such a cost has already been established for females.) The five groups are: males forced to live alone, males assigned to live with one or eight interested females, and males assigned to live with one or eight non-receptive females. The observations on each fly were longevity, thorax length, and the percentage of each day spent sleeping. The structure of the experiment provokes lively discussion on experimental design and on contrasts, and gives students opportunities to understand and verbalize what we mean by the term ``statistical interaction.'' Because the variable thorax length has a strong effect on survival, it is important to take it into account to increase the precision of between-group contrasts, even though it is distributed similarly across groups. The dataset can also be used to illustrate techniques of survival analysis.},
  file = {/Users/solomonkurz/Zotero/storage/9J3933SB/A and H - 1994 - Sexual Activity and the Lifespan of Male Fruitflie.pdf;/Users/solomonkurz/Zotero/storage/HIZI77AL/10691898.1994.html},
  journal = {Journal of Statistics Education},
  keywords = {Analysis of covariance,Experiment,Longevity,Precision,Regression,Survival analysis},
  number = {1}
}

@article{silkChimpanzeesAreIndifferent2005,
  title = {Chimpanzees Are Indifferent to the Welfare of Unrelated Group Members},
  author = {Silk, Joan B. and Brosnan, Sarah F. and Vonk, Jennifer and Henrich, Joseph and Povinelli, Daniel J. and Richardson, Amanda S. and Lambeth, Susan P. and Mascaro, Jenny and Schapiro, Steven J.},
  year = {2005},
  month = oct,
  volume = {437},
  pages = {1357--1359},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature04243},
  url = {https://www.nature.com/articles/nature04243},
  urldate = {2020-06-16},
  abstract = {There is plenty of evidence \textemdash{} some of it cited in this week's Review Article \textemdash{} that humans care about the welfare of others and will provide costly assistance even to strangers. Frans de Waal has argued that 'other-regarding sentiments' may be deep-rooted in primate evolutionary history. But a test for such behaviour in chimpanzees has drawn a blank. They spurn the chance to deliver benefits to unrelated but familiar individuals at no cost to themselves, cooperating only with their kin and partners.},
  copyright = {2005 Nature Publishing Group},
  file = {/Users/solomonkurz/Zotero/storage/36JBUZ32/nature04243.html},
  journal = {Nature},
  language = {en},
  number = {7063}
}

@article{simmonsFalsepositivePsychologyUndisclosed2011,
  title = {False-Positive Psychology: {{Undisclosed}} Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant},
  shorttitle = {False-{{Positive Psychology}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  year = {2011},
  month = nov,
  volume = {22},
  pages = {1359--1366},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797611417632},
  url = {https://journals.sagepub.com/doi/full/10.1177/0956797611417632},
  urldate = {2020-05-23},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings ({$\leq$} .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  file = {/Users/solomonkurz/Zotero/storage/N85FNDMV/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {11}
}

@book{singerAppliedLongitudinalData2003,
  title = {Applied Longitudinal Data Analysis: {{Modeling}} Change and Event Occurrence},
  shorttitle = {Applied Longitudinal Data Analysis},
  author = {Singer, Judith D. and Willett, John B.},
  year = {2003},
  month = mar,
  publisher = {{Oxford University Press, USA}},
  url = {https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968},
  abstract = {Change is constant in everyday life. Infants crawl and then walk, children learn to read and write, teenagers mature in myriad ways, the elderly become frail and forgetful. Beyond these natural processes and events, external forces and interventions instigate and disrupt change: test scores may rise after a coaching course, drug abusers may remain abstinent after residential treatment. By charting changes over time and investigating whether and when events occur, researchers reveal the temporal rhythms of our lives. Applied Longitudinal Data Analysis is a much-needed professional book for empirical researchers and graduate students in the behavioral, social, and biomedical sciences. It offers the first accessible in-depth presentation of two of today's most popular statistical methods: multilevel models for individual change and hazard/survival models for event occurrence (in both discrete- and continuous-time). Using clear, concise prose and real data sets from published studies, the authors take you step by step through complete analyses, from simple exploratory displays that reveal underlying patterns through sophisticated specifications of complex statistical models.Applied Longitudinal Data Analysis offers readers a private consultation session with internationally recognized experts and represents a unique contribution to the literature on quantitative empirical methods.Visit http://www.ats.ucla.edu/stat/examples/alda.htm for:DT Downloadable data setsDT Library of computer programs in SAS, SPSS, Stata, HLM, MLwiN, and moreDT Additional material for data analysis},
  googlebooks = {PpnA1M8VwR8C},
  isbn = {978-0-19-515296-8},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Epidemiology,Psychology / Statistics},
  language = {en}
}

@article{skinnerCaseHistoryScientific1956,
  title = {A Case History in Scientific Method},
  author = {Skinner, B. F.},
  year = {1956},
  volume = {11},
  pages = {221--233},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1935-990X(Electronic),0003-066X(Print)},
  doi = {10.1037/h0047662},
  url = {https://pdfs.semanticscholar.org/a113/55f49947e4c77659ec9fa5c6b69bd7798194.pdf},
  abstract = {The case history in scientific method cited is autobiographical; Skinner relates certain relevant experiences in the development of some of his scientific contributions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/BZJKX54K/1957-05288-001.html},
  journal = {American Psychologist},
  keywords = {Experimental Methods,Experimentation,Scientific Communication},
  number = {5}
}

@article{sneeGraphicalDisplayTwoway1974,
  title = {Graphical Display of Two-Way Contingency Tables},
  author = {Snee, Ronald D},
  year = {1974},
  volume = {28},
  pages = {9--12},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00031305.1974.10479053},
  url = {https://www.researchgate.net/profile/Ron_Snee/publication/243769696_Graphical_Display_of_Two-Way_Contingency_Tables/links/580b7ab908aecba93500ce16/Graphical-Display-of-Two-Way-Contingency-Tables.pdf},
  journal = {The American Statistician},
  number = {1}
}

@article{spiegelhalterBayesianMeasuresModel2002,
  title = {Bayesian Measures of Model Complexity and Fit},
  author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and Linde, Angelika Van Der},
  year = {2002},
  volume = {64},
  pages = {583--639},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00353},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00353},
  urldate = {2020-06-12},
  abstract = {Summary. We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pD for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pD approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the `hat' matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.},
  file = {/Users/solomonkurz/Zotero/storage/GGPTKT9M/Spiegelhalter et al. - 2002 - Bayesian measures of model complexity and fit.pdf;/Users/solomonkurz/Zotero/storage/SD8PUJGW/1467-9868.html},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Bayesian model comparison,Decision theory,Deviance information criterion,Effective number of parameters,Hierarchical models,Information theory,Leverage,Markov chain Monte Carlo methods,Model dimension},
  language = {en},
  number = {4}
}

@misc{standevelopmentteamAccessingContentsStanfit2020,
  title = {Accessing the Contents of a Stanfit Object},
  author = {{Stan Development Team}},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=rstan/vignettes/stanfit-objects.html},
  urldate = {2020-05-15},
  file = {/Users/solomonkurz/Zotero/storage/RKEPKHUF/stanfit-objects.html}
}

@misc{standevelopmentteamRStanInterfaceStan2020,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  year = {2020},
  month = feb,
  url = {https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html},
  urldate = {2020-05-22},
  file = {/Users/solomonkurz/Zotero/storage/UNLVDTJP/rstan.html}
}

@book{standevelopmentteamStanFunctionsReference2020,
  title = {Stan Functions Reference},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_23/functions-reference/index.html},
  urldate = {2020-06-21},
  abstract = {Reference for the functions defined in the Stan math library and available in the Stan programming language.},
  file = {/Users/solomonkurz/Zotero/storage/IGIXTGX4/index.html}
}

@book{standevelopmentteamStanReferenceManual2020,
  title = {Stan Reference Manual, {{Version}} 2.23},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_23/reference-manual/}
}

@book{standevelopmentteamStanUserGuide2020,
  title = {Stan User's Guide, {{Version}} 2.23},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_23/stan-users-guide/index.html}
}

@article{steidlStatisticalPowerAnalysis1997,
  title = {Statistical Power Analysis in Wildlife Research},
  author = {Steidl, Robert J. and Hayes, John P. and Schauber, Eric},
  year = {1997},
  month = apr,
  volume = {61},
  pages = {270},
  issn = {0022541X},
  doi = {10.2307/3802582},
  url = {https://cals.arizona.edu/~steidl/files/pdfs/Steidl\%20et\%20al.\%201997\%20JWM.pdf},
  urldate = {2020-05-16},
  abstract = {Statistical power analysis can be used to increase the efficiency of research efforts and to clarify research results. Power analysis is most valuable in the design or planning phases of research efforts. Such prospective (a priori) power analyses can be used to guide research design and to estimate the number of samples necessary to achieve a high probability of detecting biologically significant effects. Retrospective (a posteriori) power analysis has been advocated as a method to increase information about hypothesis tests that were not rejected. However, estimating power for tests of null hypotheses that were not rejected with the effect size observed in the study is incorrect; these power estimates will always be 50.50 when bias adjusted and have no relation to true power. Therefore, retrospective power estimates based on the observed effect size for hypothesis tests that were not rejected are misleading; retrospective power estimates are only meaningful when based on effect sizes other than the observed effect size, such as those effect sizes hypothesized to be biologcally significant. Retrospective power analysis can be used effectively to estimate the number of samples or effect size that would have been necessary for a completed study to have rejected a specific null hypothesis. Simply presenting confidence intervals can provide addtional information about null hypotheses that were not rejected, including information about the size of the true effect and whether or not there is adequate evidence to "accept" a null hypothesis as true. We suggest that (1)statistical power analyses be routinely incorporated into research planning efforts to increase their efficiency, (2) confidence intervals be used in lieu of retrospective power analyses for null hypotheses that were not rejected to assess the likely size of the true effect, (3) minimum biologically significant effect sizes be used for all power analyses, and (4) if retrospective power estimates are to be reported, then the a-level, effect sizes, and sample sizes used in calculations must also be reported.},
  file = {/Users/solomonkurz/Zotero/storage/IHA6SZFZ/Steidl et al. - 1997 - Statistical Power Analysis in Wildlife Research.pdf},
  journal = {The Journal of Wildlife Management},
  language = {en},
  number = {2}
}

@misc{SteinParadoxStatistics,
  title = {Stein's {{Paradox}} in {{Statistics}} on {{JSTOR}}},
  url = {https://www.jstor.org/preview-page/10.2307/24954030?seq=1},
  urldate = {2020-07-01},
  abstract = {Bradley Efron, Carl Morris, Stein's Paradox in Statistics, Scientific American, Vol. 236, No. 5 (May 1977), pp. 119-127},
  file = {/Users/solomonkurz/Zotero/storage/NVTSYVC3/24954030.html},
  language = {en}
}

@article{streetCoevolutionCulturalIntelligence2017,
  title = {Coevolution of Cultural Intelligence, Extended Life History, Sociality, and Brain Size in Primates},
  author = {Street, Sally E. and Navarrete, Ana F. and Reader, Simon M. and Laland, Kevin N.},
  year = {2017},
  month = jul,
  volume = {114},
  pages = {7908--7914},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1620734114},
  url = {https://www.pnas.org/content/114/30/7908},
  urldate = {2020-08-03},
  abstract = {Explanations for primate brain expansion and the evolution of human cognition and culture remain contentious despite extensive research. While multiple comparative analyses have investigated variation in brain size across primate species, very few have addressed why primates vary in how much they use social learning. Here, we evaluate the hypothesis that the enhanced reliance on socially transmitted behavior observed in some primates has coevolved with enlarged brains, complex sociality, and extended lifespans. Using recently developed phylogenetic comparative methods we show that, across primate species, a measure of social learning proclivity increases with absolute and relative brain volume, longevity (specifically reproductive lifespan), and social group size, correcting for research effort. We also confirm relationships of absolute and relative brain volume with longevity (both juvenile period and reproductive lifespan) and social group size, although longevity is generally the stronger predictor. Relationships between social learning, brain volume, and longevity remain when controlling for maternal investment and are therefore not simply explained as a by-product of the generally slower life history expected for larger brained species. Our findings suggest that both brain expansion and high reliance on culturally transmitted behavior coevolved with sociality and extended lifespan in primates. This coevolution is consistent with the hypothesis that the evolution of large brains, sociality, and long lifespans has promoted reliance on culture, with reliance on culture in turn driving further increases in brain volume, cognitive abilities, and lifespans in some primate lineages.},
  chapter = {Colloquium Paper},
  copyright = {\textcopyright{}  . http://www.pnas.org/site/misc/userlicense.xhtml},
  file = {/Users/solomonkurz/Zotero/storage/UKCMQ4BS/Street et al. - 2017 - Coevolution of cultural intelligence, extended lif.pdf;/Users/solomonkurz/Zotero/storage/QREEYJJF/7908.html},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {brain evolution,cultural evolution,phylogenetic comparative analysis,primates,social learning},
  language = {en},
  number = {30},
  pmid = {28739950}
}

@article{subramanianAverageTreatmentEffect2018,
  title = {The "Average" Treatment Effect: {{A}} Construct Ripe for Retirement. {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {The "Average" Treatment Effect},
  author = {Subramanian, S. V. and Kim, Rockli and Christakis, Nicholas A.},
  year = {2018},
  month = aug,
  volume = {210},
  pages = {77--82},
  issn = {1873-5347},
  doi = {10.1016/j.socscimed.2018.04.027},
  journal = {Social Science \& Medicine (1982)},
  keywords = {Randomized Controlled Trials as Topic,Retirement},
  language = {eng},
  pmid = {29724462}
}

@article{subramanianAverageTreatmentEffect2018a,
  title = {The ``Average'' Treatment Effect: {{A}} Construct Ripe for Retirement. {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {The ``Average'' Treatment Effect},
  author = {Subramanian, S. V. and Kim, Rockli and Christakis, Nicholas A.},
  year = {2018},
  month = aug,
  volume = {210},
  pages = {77--82},
  issn = {0277-9536},
  doi = {10.1016/j.socscimed.2018.04.027},
  url = {http://www.sciencedirect.com/science/article/pii/S0277953618301941},
  urldate = {2020-06-16},
  file = {/Users/solomonkurz/Zotero/storage/KB9NJ647/S0277953618301941.html},
  journal = {Social Science \& Medicine},
  language = {en},
  series = {Randomized {{Controlled Trials}} and {{Evidence}}-Based {{Policy}}: {{A Multidisciplinary Dialogue}}}
}

@article{sunRethinkingObservedPower2011,
  title = {Rethinking Observed Power: {{Concept}}, Practice, and Implications},
  shorttitle = {Rethinking {{Observed Power}}},
  author = {Sun, Shuyan and Pan, Wei and Wang, Lihshing Leigh},
  year = {2011},
  month = jan,
  volume = {7},
  pages = {81--87},
  issn = {1614-1881, 1614-2241},
  doi = {10.1027/1614-2241/a000025},
  url = {https://www.researchgate.net/profile/Shuyan_Sun2/publication/232499536_Rethinking_Observed_Power_Concept_Practice_and_Implications/links/5623f87708aea35f26868b78/Rethinking-Observed-Power-Concept-Practice-and-Implications.pdf},
  urldate = {2020-05-16},
  abstract = {Observed power analysis is recommended by many scholarly journal editors and reviewers, especially for studies with statistically nonsignificant test results. However, researchers may not fully realize that blind observance of this recommendation could lead to an unfruitful effort, despite the repeated warnings from methodologists. Through both a review of 14 published empirical studies and a Monte Carlo simulation study, the present study demonstrates that observed power is usually not as informative or helpful as we think because (a) observed power for a nonsignificant test is generally low and, therefore, does not provide additional information to the test; and (b) a low observed power does not always indicate that the test is underpowered. Implications and suggestions of statistical power analysis for quantitative researchers are discussed.},
  file = {/Users/solomonkurz/Zotero/storage/G35IZV26/Sun et al. - 2011 - Rethinking Observed Power Concept, Practice, and .pdf},
  journal = {Methodology},
  language = {en},
  number = {3}
}

@article{thomasRetrospectivePowerAnalysis1997,
  title = {Retrospective Power Analysis},
  author = {Thomas, Len},
  year = {1997},
  month = feb,
  volume = {11},
  pages = {276--280},
  issn = {0888-8892, 1523-1739},
  doi = {10.1046/j.1523-1739.1997.96102.x},
  url = {https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/679/Thomas-Retrospectivepoweranalysis-postprint.pdf?sequence=5},
  urldate = {2020-05-16},
  file = {/Users/solomonkurz/Zotero/storage/X4DNELP7/Thomas - 1997 - Retrospective Power Analysis.pdf},
  journal = {Conservation Biology},
  language = {en},
  number = {1}
}

@book{tufteVisualDisplayQuantitative2001,
  title = {The Visual Display of Quantitative Information},
  author = {Tufte, Edward R.},
  year = {2001},
  month = may,
  edition = {2nd edition edition},
  publisher = {{Graphics Press}},
  address = {{Cheshire, Conn}},
  url = {https://www.edwardtufte.com/tufte/books_vdqi},
  abstract = {The classic book on statistical graphics, charts, tables. Theory and practice in the design of data graphics, 250 illustrations of the best (and a few of the worst) statistical graphics, with detailed analysis of how to display data for precise, effective, quick analysis. Design of the high-resolution displays, small multiples. Editing and improving graphics. The data-ink ratio. Time-series, relational graphics, data maps, multivariate designs. Detection of graphical deception: design variation vs. data variation. Sources of deception. Aesthetics and data graphical displays. This is the second edition of The Visual Display of Quantitative Information. Recently published, this new edition provides excellent color reproductions of the many graphics of William Playfair, adds color to other images, and includes all the changes and corrections accumulated during 17 printings of the first edition.},
  isbn = {978-1-930824-13-3},
  language = {English}
}

@article{vanpaemelPriorSensitivityTheory2010,
  title = {Prior Sensitivity in Theory Testing: {{An}} Apologia for the {{Bayes}} Factor},
  author = {Vanpaemel, Wolf},
  year = {2010},
  volume = {54},
  pages = {491--498},
  publisher = {{Elsevier}},
  doi = {10.1016/j.jmp.2010.07.003},
  url = {https://ppw.kuleuven.be/okp/_pdf/Vanpaemel2010PSITT.pdf},
  journal = {Journal of Mathematical Psychology},
  number = {6}
}

@misc{vehtariBayesianStackingPseudoBMA,
  title = {Bayesian Stacking and Pseudo-{{BMA}} Weights Using the Loo Package},
  author = {Vehtari, Aki and Gabry, Jonah},
  year = {2019},
  month = dec,
  url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-weights.html}
}

@article{vehtariLimitationsLimitationsBayesian2019,
  title = {Limitations of ``{{Limitations}} of {{Bayesian}} Leave-One-out Cross-Validation for Model Selection''},
  author = {Vehtari, Aki and Simpson, Daniel P and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  volume = {2},
  pages = {22--27},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0020-6},
  journal = {Computational Brain \& Behavior},
  number = {1}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  url = {https://arxiv.org/pdf/1507.04544.pdf},
  urldate = {2020-06-03},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  file = {/Users/solomonkurz/Zotero/storage/I7HY567V/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {5}
}

@article{vehtariRanknormalizationFoldingLocalization2019,
  title = {Rank-Normalization, Folding, and Localization: {{An}} Improved \$\textbackslash widehat\{\vphantom\}{{R}}\vphantom\{\}\$ for Assessing Convergence of {{MCMC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year = {2019},
  url = {https://arxiv.org/abs/1903.08008?},
  journal = {arXiv preprint arXiv:1903.08008}
}

@artwork{vermeerGirlPearlEarring1665,
  title = {Girl with a Pearl Earring},
  author = {Vermeer, Johannes},
  year = {1665}
}

@article{voneshCompensatoryLarvalResponses2005,
  title = {Compensatory Larval Responses Shift Trade-Offs Associated with Predator-Induced Hatching Plasticity},
  author = {Vonesh, James R. and Bolker, Benjamin M.},
  year = {2005},
  volume = {86},
  pages = {1580--1591},
  issn = {1939-9170},
  doi = {10.1890/04-0535},
  url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/04-0535},
  urldate = {2020-07-01},
  abstract = {Many species with complex life histories can respond to risk by adaptively altering the timing of key life history switch points, including hatching. It is generally thought that such hatching plasticity involves a trade-off between embryonic and hatchling predation risk, e.g., hatching early to escape egg predation comes at the cost of increased vulnerability to hatchling predators. However, most empirical work has focused on simply detecting predator-induced hatching responses or on the short-term consequences of hatching plasticity. Short-term studies may not allow sufficient time for hatchlings to exhibit compensatory responses, which may extend to subsequent life stages and could alter the nature of the trade-offs associated with hatching plasticity. In this study, we examine the consequences of predator-induced hatching plasticity through the larval stage to metamorphosis in the East African reed frog, Hyperolius spinigularis. To do this we conducted an experiment in which we manipulated initial larval size and density (mimicking the effects of egg predators) and the presence of aquatic predators. We expected that predator-induced hatchlings (because they are less developed and smaller) would experience higher per capita predation rates and a longer larval period and thus would exhibit lower survival to metamorphosis in the presence of aquatic predators than larger, more developed, later hatched larvae. Surprisingly, we found that predator-induced hatchlings survived better, not worse, than hatchlings from undisturbed clutches. These results motivated us to develop a model parameterized from additional experiments to explore whether a combination of mechanisms, compensatory growth, and density- and size-specific predation, could give rise to this pattern. Predicted survival probabilities from the model with compensatory growth were consistent with those from the field experiment: early hatched larvae grew more rapidly through vulnerable size classes than later hatched larvae, resulting in higher survival at metamorphosis. Thus, in this system, there does not appear to be a trade-off in vulnerability between egg and larval predators. Instead, our results suggest that the cost that balances the survival benefit of hatching early to evade egg predators arises later in the life history, as a result of smaller size at metamorphosis.},
  copyright = {\textcopyright{} 2005 by the Ecological Society of America},
  file = {/Users/solomonkurz/Zotero/storage/HTIQ7YL3/04-0535.html},
  journal = {Ecology},
  keywords = {compensatory growth,density-mediated indirect interaction (DMII),functional response,hatching plasticity,Hyperolius spinigularis,multiple predators,phenotypic plasticity,size-selective predation,trait-mediated indirect interaction (TMII)},
  language = {en},
  number = {6}
}

@article{wagenmakers2007practical,
  title = {A Practical Solution to the Pervasive Problems of {\emph{p}} Values},
  author = {Wagenmakers, Eric-Jan},
  year = {2007},
  volume = {14},
  pages = {779--804},
  publisher = {{Springer}},
  url = {https://doi.org/10.3758/BF03194105},
  journal = {Psychonomic bulletin \& review},
  number = {5}
}

@article{wagenmakersBayesianHypothesisTesting2010,
  title = {Bayesian Hypothesis Testing for Psychologists: {{A}} Tutorial on the {{Savage}}\textendash{{Dickey}} Method},
  shorttitle = {Bayesian Hypothesis Testing for Psychologists},
  author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
  year = {2010},
  month = may,
  volume = {60},
  pages = {158--189},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2009.12.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028509000826},
  urldate = {2020-05-16},
  abstract = {In the field of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage\textendash Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method's validity, generality, and flexibility.},
  file = {/Users/solomonkurz/Zotero/storage/USW25SKW/Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf},
  journal = {Cognitive Psychology},
  language = {en},
  number = {3}
}

@article{watanabeAsymptoticEquivalenceBayes2010,
  title = {Asymptotic Equivalence of {{Bayes}} Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory},
  author = {Watanabe, Sumio},
  year = {2010},
  volume = {11},
  pages = {3571--3594},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v11/watanabe10a.html},
  urldate = {2020-06-12},
  file = {/Users/solomonkurz/Zotero/storage/4HA4VYLM/Watanabe - 2010 - Asymptotic Equivalence of Bayes Cross Validation a.pdf;/Users/solomonkurz/Zotero/storage/MSKBHX5F/watanabe10a.html},
  journal = {Journal of Machine Learning Research},
  number = {116}
}

@article{watsonPANASDevelopment1988,
  title = {Development and Validation of Brief Measures of Positive and Negative Affect: The {{PANAS}} Scales.},
  author = {Watson, David and Clark, Lee Anna and Tellegen, Auke},
  year = {1988},
  volume = {54},
  pages = {1063--1070},
  publisher = {{American Psychological Association}},
  doi = {10.1037/0022-3514.54.6.1063},
  url = {https://homepages.se.edu/cvonbergen/files/2013/01/Development-and-Validation-of-Brief-Measures-of-Positive-and-Negative-Affect_The-PANAS-Scales.pdf},
  journal = {Journal of personality and social psychology},
  number = {6}
}

@article{wetzelsDefaultBayesianHypothesis2012,
  title = {A Default {{Bayesian}} Hypothesis Test for {{ANOVA}} Designs},
  author = {Wetzels, Ruud and Grasman, Raoul P. P. P. and Wagenmakers, Eric-Jan},
  year = {2012},
  month = may,
  volume = {66},
  pages = {104--111},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2012.695956},
  url = {https://www.ejwagenmakers.com/2012/WetzelsEtAl2012AmStat.pdf},
  urldate = {2020-05-18},
  abstract = {This article presents a Bayesian hypothesis test for analysis of variance (ANOVA) designs. The test is an application of standard Bayesian methods for variable selection in regression models. We illustrate the effect of various g-priors on the ANOVA hypothesis test. The Bayesian test for ANOVA designs is useful for empirical researchers and for students; both groups will get a more acute appreciation of Bayesian inference when they can apply it to practical statistical problems such as ANOVA. We illustrate the use of the test with two examples, and we provide R code that makes the test easy to use.},
  file = {/Users/solomonkurz/Zotero/storage/K9KJAT77/00031305.2012.html},
  journal = {The American Statistician},
  keywords = {Bayes factor,Model selection,Teaching Bayesian statistics},
  number = {2}
}

@article{wetzelsStatisticalEvidenceExperimental2011,
  title = {Statistical Evidence in Experimental Psychology: {{An}} Empirical Comparison Using 855 {\emph{t}} Tests},
  author = {Wetzels, Ruud and Matzke, Dora and Lee, Michael D and Rouder, Jeffrey N and Iverson, Geoffrey J and Wagenmakers, Eric-Jan},
  year = {2011},
  volume = {6},
  pages = {291--298},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/1745691611406923},
  url = {https://pdfs.semanticscholar.org/1874/4e6c84087ccc20bc0f6db28020bc48c81b4a.pdf},
  journal = {Perspectives on Psychological Science},
  number = {3}
}

@book{wickhamGgplot2ElegantGraphics2016,
  title = {{{ggplot2}}: {{Elegant}} Graphics for Data Analysis},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  url = {https://ggplot2.tidyverse.org},
  isbn = {978-3-319-24277-4}
}

@article{wickhamReshapingDataReshape2007,
  title = {Reshaping Data with the Reshape Package},
  author = {Wickham, Hadley},
  year = {2007},
  volume = {21},
  pages = {1--20},
  url = {https://doi.org/10.18637/jss.v021.i12},
  journal = {Journal of Statistical Software},
  number = {12}
}

@article{wickhamTidyData2014,
  title = {Tidy Data},
  author = {Wickham, Hadley},
  year = {2014},
  volume = {59},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  url = {http://www.jstatsoft.org/v59/i10/},
  urldate = {2020-05-17},
  file = {/Users/solomonkurz/Zotero/storage/56ARBADN/Wickham - 2014 - Tidy Data.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {10}
}

@book{wickhamTidyverseStyleGuide2020,
  title = {The Tidyverse Style Guide},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://style.tidyverse.org/}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  volume = {4},
  pages = {1686},
  doi = {10.21105/joss.01686},
  journal = {Journal of Open Source Software},
  number = {43}
}

@article{wilksLargesampleDistributionLikelihood1938,
  title = {The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses},
  author = {Wilks, S. S.},
  year = {1938},
  volume = {9},
  pages = {60--62},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177732360},
  url = {https://www.jstor.org/stable/2957648},
  urldate = {2020-06-01},
  journal = {The Annals of Mathematical Statistics},
  number = {1}
}

@techreport{williamsBayesianMultivariateMixedeffects2019,
  title = {Bayesian Multivariate Mixed-Effects Location Scale Modeling of Longitudinal Relations among Affective Traits, States, and Physical Activity},
  author = {Williams, Donald R. and Liu, Siwei and Martin, Stephen Ross and Rast, Philippe},
  year = {2019},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/4kfjp},
  url = {https://osf.io/4kfjp},
  urldate = {2020-05-17},
  abstract = {Intensive longitudinal studies and experience sampling methods are becoming more common in psychology. While they provide a unique opportunity to ask novel questions about within-person processes relating to personality, there is a lack of methods specifically built to characterize the interplay between traits and states. We thus introduce a Bayesian multivariate mixed-effects location scale model (M-MELSM). The formulation can simultaneously model both personality traits (the location) and states (the scale) for multivariate data common to personality research. Variables can be included to predict either (or both) the traits and states, in addition to estimating random effects therein. This provides correlations between location and scale random effects, both across and within each outcome, which allows for characterizing relations between any number personality traits and the corresponding states. We take a \textbackslash textit\{fully\} Bayesian approach, not only to make estimation possible, but also because  it provides the necessary information for use in psychological applications such as hypothesis testing. To illustrate the model we use data from 194 individuals that provided daily ratings of negative and positive affect, as well as their psychical activity in the form of step counts over 100 consecutive days. We describe the fitted model, where we emphasize, with visualization, the richness of information provided by the M-MELSM. We demonstrate Bayesian hypothesis testing for the correlations between the random effects. We conclude by discussing limitations of the MELSM in general and extensions to the M-MELSM specifically for personality research.},
  type = {Preprint}
}

@article{williamsBayesianMultivariateMixedeffects2019a,
  title = {Bayesian Multivariate Mixed-Effects Location Scale Modeling of Longitudinal Relations among Affective Traits, States, and Physical Activity},
  author = {Williams, Donald R. and Liu, Siwei and Martin, Stephen R. and Rast, Philippe},
  year = {2019},
  month = mar,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/4kfjp},
  url = {https://psyarxiv.com/4kfjp/},
  urldate = {2020-08-05},
  abstract = {Intensive longitudinal studies and experience sampling methods are becoming more common in psychology. While they provide a unique opportunity to ask novel questions about within-person processes relating to personality, there is a lack of methods specifically built to characterize the interplay between traits and states. We thus introduce a Bayesian multivariate mixed-effects location scale model (M-MELSM). The formulation can simultaneously model both personality traits (the location) and states (the scale) for multivariate data common to personality research. Variables can be included to predict either (or both) the traits and states, in addition to estimating random effects therein. This provides correlations between location and scale random effects, both across and within each outcome, which allows for characterizing relations between any number personality traits and the corresponding states. We take a \textbackslash textit\{fully\} Bayesian approach, not only to make estimation possible, but also because  it provides the necessary information for use in psychological applications such as hypothesis testing. To illustrate the model we use data from 194 individuals that provided daily ratings of negative and positive affect, as well as their psychical activity in the form of step counts over 100 consecutive days. We describe the fitted model, where we emphasize, with visualization, the richness of information provided by the M-MELSM. We demonstrate Bayesian hypothesis testing for the correlations between the random effects. We conclude by discussing limitations of the MELSM in general and extensions to the M-MELSM specifically for personality research.},
  file = {/Users/solomonkurz/Zotero/storage/6ZTN3QZI/Williams et al. - 2019 - Bayesian Multivariate Mixed-Effects Location Scale.pdf;/Users/solomonkurz/Zotero/storage/AZQVGTM4/4kfjp.html}
}

@article{williamsBayesianNonlinearMixedeffects2019,
  title = {A {{Bayesian}} Nonlinear Mixed-Effects Location Scale Model for Learning},
  author = {Williams, Donald R. and Zimprich, Daniel R. and Rast, Philippe},
  year = {2019},
  month = oct,
  volume = {51},
  pages = {1968--1986},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01255-9},
  url = {http://link.springer.com/10.3758/s13428-019-01255-9},
  urldate = {2020-05-17},
  journal = {Behavior Research Methods},
  language = {en},
  number = {5}
}

@article{williamsBayesianNonlinearMixedeffects2019a,
  title = {A {{Bayesian}} Nonlinear Mixed-Effects Location Scale Model for Learning},
  author = {Williams, Donald R. and Zimprich, Daniel R. and Rast, Philippe},
  year = {2019},
  month = oct,
  volume = {51},
  pages = {1968--1986},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01255-9},
  url = {https://doi.org/10.3758/s13428-019-01255-9},
  urldate = {2020-08-05},
  abstract = {We present a Bayesian nonlinear mixed-effects location scale model (NL-MELSM). The NL-MELSM allows for fitting nonlinear functions to the location, or individual means, and the scale, or within-person variance. Specifically, in the context of learning, this model allows the within-person variance to follow a nonlinear trajectory, where it can be determined whether variability reduces during learning. It incorporates a sub-model that can predict nonlinear parameters for both the location and scale. This specification estimates random effects for all nonlinear location and scale parameters that are drawn from a common multivariate distribution. This allows estimation of covariances among the random effects, within and across the location and the scale. These covariances offer new insights into the interplay between individual mean structures and intra-individual variability in nonlinear parameters. We take a fully Bayesian approach, not only for ease of estimation but also for inference because it provides the necessary and consistent information for use in psychological applications, such as model selection and hypothesis testing. To illustrate the model, we use data from 333 individuals, consisting of three age groups, who participated in five learning trials that assessed verbal memory. In an exploratory context, we demonstrate that fitting a nonlinear function to the within-person variance, and allowing for individual variation therein, improves predictive accuracy compared to customary modeling techniques (e.g., assuming constant variance). We conclude by discussing the usefulness, limitations, and future directions of the NL-MELSM.},
  file = {/Users/solomonkurz/Zotero/storage/Z5PSDTI9/Williams et al. - 2019 - A Bayesian nonlinear mixed-effects location scale .pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {5}
}

@article{williamsPuttingIndividualReliability2019,
  title = {Putting the Individual into Reliability: {{Bayesian}} Testing of Homogeneous within-Person Variance in Hierarchical Models},
  shorttitle = {Putting the {{Individual}} into {{Reliability}}},
  author = {Williams, Donald R. and Martin, Stephen R. and Rast, Philippe},
  year = {2019},
  month = jul,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/hpq7w},
  url = {https://psyarxiv.com/hpq7w/},
  urldate = {2020-08-05},
  abstract = {Measurement reliability is a fundamental concept in psychology. It is traditionally considered a stable property of a questionnaire, measurement device, or experimental task. 
Although intraclass correlation coefficients (ICC) are often used to assess reliability in repeated measure designs, their descriptive nature depends upon the assumption of a common
within-person variance.
This work focuses on the presumption that each individual is adequately described by the average within-person variance in hierarchical models. And thus whether reliability generalizes to the individual level, which leads directly into the notion of individually varying ICCs. In particular, we introduce a novel approach, using the Bayes factor, wherein a researcher can directly test for homogeneous within-person variance in hierarchical models. Additionally, we introduce a membership model that allows for classifying which (and how many) individuals belong to the common variance model. The utility of our methodology is demonstrated on cognitive inhibition tasks. We find that heterogeneous within-person variance is a defining feature of these tasks, and in one case, the ratio between the largest to smallest within-person variance exceeded 20. This translates into a 10 fold difference in person-specific reliability! We also find that few individuals belong to the common variance model, and thus traditional reliability indices are potentially masking important individual variation. We discuss the implications of our findings and possible future directions. The methods are implemented in the R package vICC.},
  file = {/Users/solomonkurz/Zotero/storage/7X3329PI/Williams et al. - 2019 - Putting the Individual into Reliability Bayesian .pdf;/Users/solomonkurz/Zotero/storage/46GZSWKM/hpq7w.html}
}

@article{williamsSurfaceUnearthingWithinperson2019,
  title = {Beneath the Surface: {{Unearthing}} within-{{Person}} Variability and Mean Relations with {{Bayesian}} Mixed Models},
  shorttitle = {Beneath the {{Surface}}},
  author = {Williams, Donald R. and Rouder, Jeffrey and Rast, Philippe},
  year = {2019},
  month = jun,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/gwatq},
  url = {https://osf.io/gwatq},
  urldate = {2020-08-05},
  abstract = {Mixed-effects models are becoming common in psychological science. Although they have many desirable features, there is still untapped potential that has not yet been fully realized. It is customary to view homogeneous variance as an assumption to satisfy. We argue to move beyond that perspective, and to view modeling within-person variance (``noise'') as an opportunity to gain a richer understanding of psychological processes. This can provide important insights into behavioral (in)stability. The technique to do so is based on the mixed-effects location scale model. The formulation can simultaneously estimate mixed-effects sub-models to both the mean (location) and within-person variance (scale) for clustered data common to psychology. We develop a framework that goes beyond assessing the sub-models in isolation of one another, and allows for testing structural relations between the mean and within-person variance with the Bayes factor. We first present a motivating example, which makes clear how the model can characterize mean\textendash variance relations. We then apply the method to reaction times gathered from two cognitive inference tasks. We find there are more individual differences in the within-person variance than the mean structure, as well as a complex web of structural mean\textendash variance relations in the random effects. This stands in contrast to the dominant view of within-person variance\textendash i.e., measurement ``error'' or ``noise.'' The results also point towards paradoxical within-person, as opposed to between-person, effects. That is, in both tasks, several people had \textbackslash emph\{slower\} and \textbackslash emph\{less\} variable incongruent responses. This contradicts the typical pattern, wherein \textbackslash emph\{larger\} means are expected to be \textbackslash emph\{more\} variable. We conclude with future directions. These span from methodological to theoretical inquires that can be answered with the presented methodology.}
}

@article{woodGeneralizedAdditiveModels,
  title = {Generalized {{Additive Models}}: An Introduction with {{R}}},
  author = {Wood, Simon N},
  pages = {397},
  file = {/Users/solomonkurz/Zotero/storage/W5HE99FH/Wood - Generalized Additive Models an introduction with .pdf},
  language = {en}
}

@book{woodGeneralizedAdditiveModels2017,
  title = {Generalized Additive Models: {{An}} Introduction with {{R}}},
  shorttitle = {Generalized {{Additive Models}}},
  author = {Wood, Simon N},
  year = {2017},
  month = may,
  edition = {Second Edition},
  publisher = {{CRC Press}},
  url = {https://www.routledge.com/Generalized-Additive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331},
  abstract = {The first edition of this book has established itself as one of the leading references on generalized additive models (GAMs), and the only book on the topic to be introductory in nature with a wealth of practical examples and software implementation. It is self-contained, providing the necessary background in linear models, linear mixed models, and generalized linear models (GLMs), before presenting a balanced treatment of the theory and applications of GAMs and related models.   The author bases his approach on a framework of penalized regression splines, and while firmly focused on the practical aspects of GAMs, discussions include fairly full explanations of the theory underlying the methods. Use of R software helps explain the theory and illustrates the practical application of the methodology. Each chapter contains an extensive set of exercises, with solutions in an appendix or in the book's R data package gamair, to enable use as a course text or for self-study. Simon N. Wood is a professor of Statistical Science at the University of Bristol, UK, and author of the R package mgcv.},
  isbn = {978-1-4987-2834-8},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@book{xieBookdownAuthoringBooks2016,
  title = {{{bookdown}}: {{Authoring}} Books and Technical Documents with {{R}} Markdown},
  author = {Xie, Yihui},
  year = {2016},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://bookdown.org/yihui/bookdown/}
}

@book{xieMarkdownDefinitiveGuide2020,
  title = {R Markdown: {{The}} Definitive Guide},
  author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
  year = {2020},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://bookdown.org/yihui/rmarkdown/}
}

@article{yaoUsingStackingAverage2018,
  title = {Using Stacking to Average {{Bayesian}} Predictive Distributions (with Discussion)},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew and others},
  year = {2018},
  volume = {13},
  pages = {917--1007},
  publisher = {{International Society for Bayesian Analysis}},
  doi = {10.1214/17-BA1091},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227},
  journal = {Bayesian Analysis},
  number = {3}
}

@article{yarkoniChoosingPredictionExplanation2017,
  title = {Choosing Prediction over Explanation in Psychology: {{Lessons}} from Machine Learning},
  shorttitle = {Choosing Prediction over Explanation in Psychology},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  month = nov,
  volume = {12},
  pages = {1100--1122},
  issn = {1745-6916},
  doi = {10.1177/1745691617693393},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6603289/},
  urldate = {2020-06-06},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism, but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  file = {/Users/solomonkurz/Zotero/storage/79P37THN/Yarkoni and Westfall - 2017 - Choosing prediction over explanation in psychology.pdf},
  journal = {Perspectives on psychological science : a journal of the Association for Psychological Science},
  number = {6},
  pmcid = {PMC6603289},
  pmid = {28841086}
}

@book{yuDataIntegrationManipulation2020,
  title = {Data Integration, Manipulation and Visualization of Phylogenetic Trees},
  author = {Yu, Guangchuang},
  year = {2020},
  month = jul,
  url = {https://yulab-smu.github.io/treedata-book/},
  urldate = {2020-08-03},
  abstract = {Data Integration, Manipulation and Visualization of Phylogenetic Trees},
  file = {/Users/solomonkurz/Zotero/storage/BC6T6WAC/treedata-book.html}
}

@article{yuGgtreePackageVisualization2017,
  title = {Ggtree: {{An}} r Package for Visualization and Annotation of Phylogenetic Trees with Their Covariates and Other Associated Data},
  shorttitle = {Ggtree},
  author = {Yu, Guangchuang and Smith, David K. and Zhu, Huachen and Guan, Yi and Lam, Tommy Tsan-Yuk},
  year = {2017},
  volume = {8},
  pages = {28--36},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12628},
  url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12628},
  urldate = {2020-08-03},
  abstract = {We present an r package, ggtree, which provides programmable visualization and annotation of phylogenetic trees. ggtree can read more tree file formats than other softwares, including newick, nexus, NHX, phylip and jplace formats, and support visualization of phylo, multiphylo, phylo4, phylo4d, obkdata and phyloseq tree objects defined in other r packages. It can also extract the tree/branch/node-specific and other data from the analysis outputs of beast, epa, hyphy, paml, phylodog, pplacer, r8s, raxml and revbayes software, and allows using these data to annotate the tree. The package allows colouring and annotation of a tree by numerical/categorical node attributes, manipulating a tree by rotating, collapsing and zooming out clades, highlighting user selected clades or operational taxonomic units and exploration of a large tree by zooming into a selected portion. A two-dimensional tree can be drawn by scaling the tree width based on an attribute of the nodes. A tree can be annotated with an associated numerical matrix (as a heat map), multiple sequence alignment, subplots or silhouette images. The package ggtree is released under the artistic-2.0 license. The source code and documents are freely available through bioconductor (http://www.bioconductor.org/packages/ggtree).},
  copyright = {\textcopyright{} 2016 The Authors. Methods in Ecology and Evolution \textcopyright{} 2016 British Ecological Society},
  file = {/Users/solomonkurz/Zotero/storage/IR7IJ87T/Yu et al. - 2017 - ggtree an r package for visualization and annotat.pdf;/Users/solomonkurz/Zotero/storage/DB2B76PZ/2041-210X.html},
  journal = {Methods in Ecology and Evolution},
  keywords = {annotation,bioconductor,evolution,phylogeny,r package,visualization},
  language = {en},
  number = {1}
}

@article{yuTwoMethodsMapping2018,
  title = {Two Methods for Mapping and Visualizing Associated Data on Phylogeny Using Ggtree},
  author = {Yu, Guangchuang and Lam, Tommy Tsan-Yuk and Zhu, Huachen and Guan, Yi},
  year = {2018},
  month = dec,
  volume = {35},
  pages = {3041--3043},
  publisher = {{Oxford Academic}},
  issn = {0737-4038},
  doi = {10.1093/molbev/msy194},
  url = {https://academic.oup.com/mbe/article/35/12/3041/5142656},
  urldate = {2020-08-03},
  abstract = {Abstract.  Ggtree is a comprehensive R package for visualizing and annotating phylogenetic trees with associated data. It can also map and visualize associated},
  file = {/Users/solomonkurz/Zotero/storage/CG9PRJX6/Yu et al. - 2018 - Two Methods for Mapping and Visualizing Associated.pdf;/Users/solomonkurz/Zotero/storage/HBF6GL5J/5142656.html},
  journal = {Molecular Biology and Evolution},
  language = {en},
  number = {12}
}

@article{yuUsingGgtreeVisualize2020,
  title = {Using Ggtree to Visualize Data on Tree-like Structures},
  author = {Yu, Guangchuang},
  year = {2020},
  volume = {69},
  pages = {e96},
  issn = {1934-340X},
  doi = {10.1002/cpbi.96},
  url = {https://currentprotocols.onlinelibrary.wiley.com/doi/abs/10.1002/cpbi.96},
  urldate = {2020-08-03},
  abstract = {Ggtree is an R/Bioconductor package for visualizing tree-like structures and associated data. After 5 years of continual development, ggtree has been evolved as a package suite that contains treeio for tree data input and output, tidytree for tree data manipulation, and ggtree for tree data visualization. Ggtree was originally designed to work with phylogenetic trees, and has been expanded to support other tree-like structures, which extends the application of ggtree to present tree data in other disciplines. This article contains five basic protocols describing how to visualize trees using the grammar of graphics syntax, how to visualize hierarchical clustering results with associated data, how to estimate bootstrap values and visualize the values on the tree, how to estimate continuous and discrete ancestral traits and visualize ancestral states on the tree, and how to visualize a multiple sequence alignment with a phylogenetic tree. The ggtree package is freely available at https://www.bioconductor.org/packages/ggtree. \textcopyright{} 2020 by John Wiley \& Sons, Inc. Basic Protocol 1: Using grammar of graphics for visualizing trees Basic Protocol 2: Visualizing hierarchical clustering using ggtree Basic Protocol 3: Visualizing bootstrap values as symbolic points Basic Protocol 4: Visualizing ancestral status Basic Protocol 5: Visualizing a multiple sequence alignment with a phylogenetic tree},
  copyright = {\textcopyright{} 2020 John Wiley \& Sons, Inc.},
  file = {/Users/solomonkurz/Zotero/storage/WUMP5VUX/cpbi.html},
  journal = {Current Protocols in Bioinformatics},
  keywords = {grammar of graphics,phylogeny,tree associated data,tree structure,visualization},
  language = {en},
  number = {1}
}

@article{zhangCrossvalidationSelectingModel2015,
  title = {Cross-Validation for Selecting a Model Selection Procedure},
  author = {Zhang, Yongli and Yang, Yuhong},
  year = {2015},
  month = jul,
  volume = {187},
  pages = {95--112},
  issn = {0304-4076},
  doi = {10.1016/j.jeconom.2015.02.006},
  url = {http://www.sciencedirect.com/science/article/pii/S0304407615000305},
  urldate = {2020-06-03},
  abstract = {While there are various model selection methods, an unanswered but important question is how to select one of them for data at hand. The difficulty is due to that the targeted behaviors of the model selection procedures depend heavily on uncheckable or difficult-to-check assumptions on the data generating process. Fortunately, cross-validation (CV) provides a general tool to solve this problem. In this work, results are provided on how to apply CV to consistently choose the best method, yielding new insights and guidance for potentially vast amount of application. In addition, we address several seemingly widely spread misconceptions on CV.},
  file = {/Users/solomonkurz/Zotero/storage/W4YYPU24/S0304407615000305.html},
  journal = {Journal of Econometrics},
  keywords = {Adaptive procedure selection,Cross-validation,Cross-validation paradox,Data splitting ratio,Information criterion,LASSO,MCP,SCAD},
  language = {en},
  number = {1}
}

@article{zhuCounterintuitiveNoninformativePrior2004,
  title = {The Counter-Intuitive Non-Informative Prior for the {{Bernoulli}} Family},
  author = {Zhu, Mu and Lu, Arthur Y.},
  year = {2004},
  month = jan,
  volume = {12},
  pages = {3},
  issn = {1069-1898},
  doi = {10.1080/10691898.2004.11910734},
  url = {https://www.tandfonline.com/doi/full/10.1080/10691898.2004.11910734},
  urldate = {2020-05-16},
  abstract = {In Bayesian statistics, the choice of the prior distribution is often controversial. Different rules for selecting priors have been suggested in the literature, which, sometimes, produce priors that are difficult for the students to understand intuitively. In this article, we use a simple heuristic to illustrate to the students the rather counter-intuitive fact that flat priors are not necessarily non-informative; and non-informative priors are not necessarily flat.},
  file = {/Users/solomonkurz/Zotero/storage/TGQZ4HPD/Zhu and Lu - 2004 - The Counter-intuitive Non-informative Prior for th.pdf},
  journal = {Journal of Statistics Education},
  language = {en},
  number = {2}
}

@misc{ZoteroYourPersonal2020,
  title = {Zotero | {{Your}} Personal Research Assistant},
  year = {2020},
  url = {https://www.zotero.org/},
  urldate = {2020-05-19},
  file = {/Users/solomonkurz/Zotero/storage/27W6TM9H/www.zotero.org.html}
}


