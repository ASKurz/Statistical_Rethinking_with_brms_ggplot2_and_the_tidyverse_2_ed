<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>16 Generalized Linear Madness | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition</title>
  <meta name="description" content="This book is an attempt to re-express the code in the second edition of McElreath’s textbook, ‘Statistical rethinking.’ His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="16 Generalized Linear Madness | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book is an attempt to re-express the code in the second edition of McElreath’s textbook, ‘Statistical rethinking.’ His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse_2_ed" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="16 Generalized Linear Madness | Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This book is an attempt to re-express the code in the second edition of McElreath’s textbook, ‘Statistical rethinking.’ His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-11-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="missing-data-and-other-opportunities.html"/>
<link rel="next" href="horoscopes-insights.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="libs/vembedr-0.1.4/css/vembedr.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>What and why</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#caution-work-in-progress"><i class="fa fa-check"></i>Caution: Work in progress</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#thank-yous-are-in-order"><i class="fa fa-check"></i>Thank-you’s are in order</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license-and-citation"><i class="fa fa-check"></i>License and citation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#combining-other-information."><i class="fa fa-check"></i><b>2.1.2</b> Combining other information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#variables."><i class="fa fa-check"></i><b>2.3.1</b> Variables.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#definitions."><i class="fa fa-check"></i><b>2.3.2</b> Definitions.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-model-is-born."><i class="fa fa-check"></i><b>2.3.3</b> A model is born.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayes-theorem."><i class="fa fa-check"></i><b>2.4.1</b> Bayes’ theorem.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#motors."><i class="fa fa-check"></i><b>2.4.2</b> Motors.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.3</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.4</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.5" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.5</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-with-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice with brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="geocentric-models.html"><a href="geocentric-models.html"><i class="fa fa-check"></i><b>4</b> Geocentric Models</a><ul>
<li class="chapter" data-level="4.1" data-path="geocentric-models.html"><a href="geocentric-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="geocentric-models.html"><a href="geocentric-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="geocentric-models.html"><a href="geocentric-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="geocentric-models.html"><a href="geocentric-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="geocentric-models.html"><a href="geocentric-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="geocentric-models.html"><a href="geocentric-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="geocentric-models.html"><a href="geocentric-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="geocentric-models.html"><a href="geocentric-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="geocentric-models.html"><a href="geocentric-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="geocentric-models.html"><a href="geocentric-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="geocentric-models.html"><a href="geocentric-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="geocentric-models.html"><a href="geocentric-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="geocentric-models.html"><a href="geocentric-models.html#finding-the-posterior-distribution-with-quap-brm."><i class="fa fa-check"></i><b>4.3.5</b> Finding the posterior distribution with <del><code>quap</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="geocentric-models.html"><a href="geocentric-models.html#sampling-from-a-quap-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>quap()</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="geocentric-models.html"><a href="geocentric-models.html#linear-prediction"><i class="fa fa-check"></i><b>4.4</b> Linear prediction</a><ul>
<li class="chapter" data-level="4.4.1" data-path="geocentric-models.html"><a href="geocentric-models.html#the-linear-model-strategy."><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy.</a></li>
<li class="chapter" data-level="4.4.2" data-path="geocentric-models.html"><a href="geocentric-models.html#finding-the-posterior-distribution."><i class="fa fa-check"></i><b>4.4.2</b> Finding the posterior distribution.</a></li>
<li class="chapter" data-level="4.4.3" data-path="geocentric-models.html"><a href="geocentric-models.html#interpreting-the-posterior-distribution."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the posterior distribution.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="geocentric-models.html"><a href="geocentric-models.html#curves-from-lines"><i class="fa fa-check"></i><b>4.5</b> Curves from lines</a><ul>
<li class="chapter" data-level="4.5.1" data-path="geocentric-models.html"><a href="geocentric-models.html#polynomial-regression."><i class="fa fa-check"></i><b>4.5.1</b> Polynomial regression.</a></li>
<li class="chapter" data-level="4.5.2" data-path="geocentric-models.html"><a href="geocentric-models.html#splines."><i class="fa fa-check"></i><b>4.5.2</b> Splines.</a></li>
<li class="chapter" data-level="4.5.3" data-path="geocentric-models.html"><a href="geocentric-models.html#smooth-functions-for-a-rough-world."><i class="fa fa-check"></i><b>4.5.3</b> Smooth functions for a rough world.</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="geocentric-models.html"><a href="geocentric-models.html#summary-b-splines-with-brms"><i class="fa fa-check"></i><b>4.6</b> <del>Summary</del> B-splines with <strong>brms</strong></a></li>
<li class="chapter" data-level="" data-path="geocentric-models.html"><a href="geocentric-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html"><i class="fa fa-check"></i><b>5</b> The Many Variables &amp; The Spurious Waffles</a><ul>
<li class="chapter" data-level="5.1" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#think-before-you-regress."><i class="fa fa-check"></i><b>5.1.1</b> Think before you regress.</a></li>
<li class="chapter" data-level="5.1.2" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#testable-implications."><i class="fa fa-check"></i><b>5.1.2</b> Testable implications.</a></li>
<li class="chapter" data-level="5.1.3" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#multiple-regression-notation."><i class="fa fa-check"></i><b>5.1.3</b> Multiple regression notation.</a></li>
<li class="chapter" data-level="5.1.4" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#approximating-the-posterior."><i class="fa fa-check"></i><b>5.1.4</b> Approximating the posterior.</a></li>
<li class="chapter" data-level="5.1.5" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.5</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#categorical-varaibles"><i class="fa fa-check"></i><b>5.3</b> Categorical varaibles</a><ul>
<li class="chapter" data-level="5.3.1" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#binary-categories."><i class="fa fa-check"></i><b>5.3.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.3.2" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#many-categories."><i class="fa fa-check"></i><b>5.3.2</b> Many categories.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#summary-bonus-we-can-model-categorical-variables-in-more-ways-than-one"><i class="fa fa-check"></i><b>5.4</b> <del>Summary</del> Bonus: We can model categorical variables in more ways than one</a><ul>
<li class="chapter" data-level="5.4.1" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#you-can-use-a-dummy."><i class="fa fa-check"></i><b>5.4.1</b> You can use a dummy.</a></li>
<li class="chapter" data-level="5.4.2" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#consider-contrast-coding."><i class="fa fa-check"></i><b>5.4.2</b> Consider contrast coding.</a></li>
<li class="chapter" data-level="5.4.3" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#theres-always-the-multilevel-anova-approach."><i class="fa fa-check"></i><b>5.4.3</b> There’s always the multilevel ANOVA approach.</a></li>
<li class="chapter" data-level="5.4.4" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#would-you-like-to-learn-more"><i class="fa fa-check"></i><b>5.4.4</b> Would you like to learn more?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="the-many-variables-the-spurious-waffles.html"><a href="the-many-variables-the-spurious-waffles.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html"><i class="fa fa-check"></i><b>6</b> The Haunted DAG &amp; The Causal Terror</a><ul>
<li class="chapter" data-level="6.1" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#multicollinearity"><i class="fa fa-check"></i><b>6.1</b> Multicollinearity</a><ul>
<li class="chapter" data-level="6.1.1" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#multicollinear-legs."><i class="fa fa-check"></i><b>6.1.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="6.1.2" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#multicollinear-milk."><i class="fa fa-check"></i><b>6.1.2</b> Multicollinear <code>milk</code>.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#post-treatment-bias"><i class="fa fa-check"></i><b>6.2</b> Post-treatment bias</a><ul>
<li class="chapter" data-level="6.2.1" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#a-prior-is-born."><i class="fa fa-check"></i><b>6.2.1</b> A prior is born.</a></li>
<li class="chapter" data-level="6.2.2" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#blocked-by-consequence."><i class="fa fa-check"></i><b>6.2.2</b> Blocked by consequence.</a></li>
<li class="chapter" data-level="6.2.3" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#fungus-and-d-separation."><i class="fa fa-check"></i><b>6.2.3</b> Fungus and <span class="math inline">\(d\)</span>-separation.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#collider-bias"><i class="fa fa-check"></i><b>6.3</b> Collider bias</a><ul>
<li class="chapter" data-level="6.3.1" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#collider-of-false-sorrow."><i class="fa fa-check"></i><b>6.3.1</b> Collider of false sorrow.</a></li>
<li class="chapter" data-level="6.3.2" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#the-haunted-dag."><i class="fa fa-check"></i><b>6.3.2</b> The haunted DAG.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#confronting-confounding"><i class="fa fa-check"></i><b>6.4</b> Confronting confounding</a><ul>
<li class="chapter" data-level="6.4.1" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#shutting-the-backdoor."><i class="fa fa-check"></i><b>6.4.1</b> Shutting the backdoor.</a></li>
<li class="chapter" data-level="6.4.2" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#two-roads."><i class="fa fa-check"></i><b>6.4.2</b> Two roads.</a></li>
<li class="chapter" data-level="6.4.3" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#backdoor-waffles."><i class="fa fa-check"></i><b>6.4.3</b> Backdoor waffles.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#summary-and-a-little-more-practice"><i class="fa fa-check"></i><b>6.5</b> Summary [and a little more practice]</a></li>
<li class="chapter" data-level="" data-path="the-haunted-dag-the-causal-terror.html"><a href="the-haunted-dag-the-causal-terror.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ulysses-compass.html"><a href="ulysses-compass.html"><i class="fa fa-check"></i><b>7</b> Ulysses’ Compass</a><ul>
<li class="chapter" data-level="7.1" data-path="ulysses-compass.html"><a href="ulysses-compass.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>7.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="7.1.1" data-path="ulysses-compass.html"><a href="ulysses-compass.html#more-parameters-almost-always-improve-fit."><i class="fa fa-check"></i><b>7.1.1</b> More parameters (almost) always improve fit.</a></li>
<li class="chapter" data-level="7.1.2" data-path="ulysses-compass.html"><a href="ulysses-compass.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>7.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ulysses-compass.html"><a href="ulysses-compass.html#entropy-and-accuracy"><i class="fa fa-check"></i><b>7.2</b> Entropy and accuracy</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ulysses-compass.html"><a href="ulysses-compass.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>7.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="7.2.2" data-path="ulysses-compass.html"><a href="ulysses-compass.html#information-and-uncertainty."><i class="fa fa-check"></i><b>7.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="7.2.3" data-path="ulysses-compass.html"><a href="ulysses-compass.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>7.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="7.2.4" data-path="ulysses-compass.html"><a href="ulysses-compass.html#estimating-divergence."><i class="fa fa-check"></i><b>7.2.4</b> Estimating divergence.</a></li>
<li class="chapter" data-level="7.2.5" data-path="ulysses-compass.html"><a href="ulysses-compass.html#scoring-the-right-data."><i class="fa fa-check"></i><b>7.2.5</b> Scoring the right data.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ulysses-compass.html"><a href="ulysses-compass.html#golem-taming-regularization"><i class="fa fa-check"></i><b>7.3</b> Golem taming: regularization</a></li>
<li class="chapter" data-level="7.4" data-path="ulysses-compass.html"><a href="ulysses-compass.html#predicting-predictive-accuracy"><i class="fa fa-check"></i><b>7.4</b> Predicting predictive accuracy</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ulysses-compass.html"><a href="ulysses-compass.html#cross-validation."><i class="fa fa-check"></i><b>7.4.1</b> Cross-validation.</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ulysses-compass.html"><a href="ulysses-compass.html#information-criteria"><i class="fa fa-check"></i><b>7.5</b> Information criteria</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ulysses-compass.html"><a href="ulysses-compass.html#comparing-cv-psis-and-waic."><i class="fa fa-check"></i><b>7.5.1</b> Comparing CV, PSIS, and WAIC.</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ulysses-compass.html"><a href="ulysses-compass.html#model-comparison"><i class="fa fa-check"></i><b>7.6</b> Model comparison</a><ul>
<li class="chapter" data-level="7.6.1" data-path="ulysses-compass.html"><a href="ulysses-compass.html#model-mis-selection."><i class="fa fa-check"></i><b>7.6.1</b> Model mis-selection.</a></li>
<li class="chapter" data-level="7.6.2" data-path="ulysses-compass.html"><a href="ulysses-compass.html#outliers-and-other-illusions."><i class="fa fa-check"></i><b>7.6.2</b> Outliers and other illusions.</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ulysses-compass.html"><a href="ulysses-compass.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>7.7</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="ulysses-compass.html"><a href="ulysses-compass.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conditional-manatees.html"><a href="conditional-manatees.html"><i class="fa fa-check"></i><b>8</b> Conditional Manatees</a><ul>
<li class="chapter" data-level="8.1" data-path="conditional-manatees.html"><a href="conditional-manatees.html#building-an-interaction."><i class="fa fa-check"></i><b>8.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="8.1.1" data-path="conditional-manatees.html"><a href="conditional-manatees.html#making-a-rugged-model."><i class="fa fa-check"></i><b>8.1.1</b> Making a rugged model.</a></li>
<li class="chapter" data-level="8.1.2" data-path="conditional-manatees.html"><a href="conditional-manatees.html#adding-an-indicator-variable-isnt-enough."><i class="fa fa-check"></i><b>8.1.2</b> Adding an indicator variable isn’t enough.</a></li>
<li class="chapter" data-level="8.1.3" data-path="conditional-manatees.html"><a href="conditional-manatees.html#adding-an-interaction-does-work."><i class="fa fa-check"></i><b>8.1.3</b> Adding an interaction does work.</a></li>
<li class="chapter" data-level="8.1.4" data-path="conditional-manatees.html"><a href="conditional-manatees.html#plotting-the-interaction."><i class="fa fa-check"></i><b>8.1.4</b> Plotting the interaction.</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="conditional-manatees.html"><a href="conditional-manatees.html#symmetry-of-interactions"><i class="fa fa-check"></i><b>8.2</b> Symmetry of interactions</a></li>
<li class="chapter" data-level="8.3" data-path="conditional-manatees.html"><a href="conditional-manatees.html#continuous-interactions"><i class="fa fa-check"></i><b>8.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="8.3.1" data-path="conditional-manatees.html"><a href="conditional-manatees.html#a-winter-flower."><i class="fa fa-check"></i><b>8.3.1</b> A winter flower.</a></li>
<li class="chapter" data-level="8.3.2" data-path="conditional-manatees.html"><a href="conditional-manatees.html#the-models."><i class="fa fa-check"></i><b>8.3.2</b> The models.</a></li>
<li class="chapter" data-level="8.3.3" data-path="conditional-manatees.html"><a href="conditional-manatees.html#plotting-posterior-predictions."><i class="fa fa-check"></i><b>8.3.3</b> Plotting posterior predictions.</a></li>
<li class="chapter" data-level="8.3.4" data-path="conditional-manatees.html"><a href="conditional-manatees.html#plotting-prior-predictions."><i class="fa fa-check"></i><b>8.3.4</b> Plotting prior predictions.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="conditional-manatees.html"><a href="conditional-manatees.html#summary-bonus-conditional_effects"><i class="fa fa-check"></i><b>8.4</b> <del>Summary</del> Bonus: <code>conditional_effects()</code></a></li>
<li class="chapter" data-level="" data-path="conditional-manatees.html"><a href="conditional-manatees.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>9</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="9.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>9.1</b> Good King Markov and his island kingdom</a></li>
<li class="chapter" data-level="9.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#metropolis-algorithms"><i class="fa fa-check"></i><b>9.2</b> Metropolis algorithms</a><ul>
<li class="chapter" data-level="9.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#gibbs-sampling."><i class="fa fa-check"></i><b>9.2.1</b> Gibbs sampling.</a></li>
<li class="chapter" data-level="9.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#high-dimensional-problems."><i class="fa fa-check"></i><b>9.2.2</b> High-dimensional problems.</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#hamiltonian-monte-carlo"><i class="fa fa-check"></i><b>9.3</b> Hamiltonian Monte Carlo</a><ul>
<li class="chapter" data-level="9.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#another-parable."><i class="fa fa-check"></i><b>9.3.1</b> Another parable.</a></li>
<li class="chapter" data-level="9.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#particles-in-space."><i class="fa fa-check"></i><b>9.3.2</b> Particles in space.</a></li>
<li class="chapter" data-level="9.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#limitations."><i class="fa fa-check"></i><b>9.3.3</b> Limitations.</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-ulam-brm"><i class="fa fa-check"></i><b>9.4</b> Easy HMC: <del>ulam</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="9.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>9.4.1</b> Preparation.</a></li>
<li class="chapter" data-level="9.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-from-the-posterior.-1"><i class="fa fa-check"></i><b>9.4.2</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="9.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>9.4.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="9.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>9.4.4</b> Visualization.</a></li>
<li class="chapter" data-level="9.4.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>9.4.5</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>9.5</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="9.5.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>9.5.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="9.5.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>9.5.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="9.5.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>9.5.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="9.5.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>9.5.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>10</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="10.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>10.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="10.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>10.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="10.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>10.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>10.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="10.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>10.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="10.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>10.2.2</b> Linking linear models to distributions.</a></li>
<li class="chapter" data-level="10.2.3" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#omitted-variable-bias-again."><i class="fa fa-check"></i><b>10.2.3</b> Omitted variable bias again.</a></li>
<li class="chapter" data-level="10.2.4" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#absolute-and-relative-differences."><i class="fa fa-check"></i><b>10.2.4</b> Absolute and relative differences.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html"><i class="fa fa-check"></i><b>11</b> God Spiked the Integers</a><ul>
<li class="chapter" data-level="11.1" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#binomial-regression"><i class="fa fa-check"></i><b>11.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="11.1.1" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>11.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="11.1.2" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#relative-shark-and-absolute-deer."><i class="fa fa-check"></i><b>11.1.2</b> Relative shark and absolute deer.</a></li>
<li class="chapter" data-level="11.1.3" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>11.1.3</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="11.1.4" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>11.1.4</b> Aggregated binomial: Graduate school admissions.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#poisson-regression"><i class="fa fa-check"></i><b>11.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="11.2.1" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>11.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="11.2.2" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#negative-binomial-gamma-poisson-models."><i class="fa fa-check"></i><b>11.2.2</b> Negative binomial (gamma-Poisson) models.</a></li>
<li class="chapter" data-level="11.2.3" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>11.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#multinomial-and-categorical-models"><i class="fa fa-check"></i><b>11.3</b> Multinomial and categorical models</a><ul>
<li class="chapter" data-level="11.3.1" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#predictors-matched-to-outcomes."><i class="fa fa-check"></i><b>11.3.1</b> Predictors matched to outcomes.</a></li>
<li class="chapter" data-level="11.3.2" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#predictors-matched-to-observations."><i class="fa fa-check"></i><b>11.3.2</b> Predictors matched to observations.</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#summary"><i class="fa fa-check"></i><b>11.4</b> Summary</a></li>
<li class="chapter" data-level="11.5" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#bonus-survival-analysis"><i class="fa fa-check"></i><b>11.5</b> Bonus: Survival analysis</a><ul>
<li class="chapter" data-level="11.5.1" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#survival-summary."><i class="fa fa-check"></i><b>11.5.1</b> Survival summary.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="god-spiked-the-integers.html"><a href="god-spiked-the-integers.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>12</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="12.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-counts"><i class="fa fa-check"></i><b>12.1</b> Over-dispersed counts</a><ul>
<li class="chapter" data-level="12.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>12.1.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="12.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>12.1.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="12.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>12.1.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>12.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="12.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>12.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>12.3</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="12.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>12.3.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="12.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>12.3.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="12.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>12.3.3</b> Adding predictor variables.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-predictors"><i class="fa fa-check"></i><b>12.4</b> Ordered categorical predictors</a></li>
<li class="chapter" data-level="12.5" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#summary-1"><i class="fa fa-check"></i><b>12.5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="models-with-memory.html"><a href="models-with-memory.html"><i class="fa fa-check"></i><b>13</b> Models With Memory</a><ul>
<li class="chapter" data-level="13.1" data-path="models-with-memory.html"><a href="models-with-memory.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>13.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="13.2" data-path="models-with-memory.html"><a href="models-with-memory.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>13.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="13.2.1" data-path="models-with-memory.html"><a href="models-with-memory.html#the-model.-1"><i class="fa fa-check"></i><b>13.2.1</b> The model.</a></li>
<li class="chapter" data-level="13.2.2" data-path="models-with-memory.html"><a href="models-with-memory.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>13.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="13.2.3" data-path="models-with-memory.html"><a href="models-with-memory.html#sumulate-survivors."><i class="fa fa-check"></i><b>13.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="13.2.4" data-path="models-with-memory.html"><a href="models-with-memory.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>13.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="13.2.5" data-path="models-with-memory.html"><a href="models-with-memory.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>13.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="models-with-memory.html"><a href="models-with-memory.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>13.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="13.3.1" data-path="models-with-memory.html"><a href="models-with-memory.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>13.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="13.3.2" data-path="models-with-memory.html"><a href="models-with-memory.html#even-more-clusters."><i class="fa fa-check"></i><b>13.3.2</b> Even more clusters.</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="models-with-memory.html"><a href="models-with-memory.html#divergent-transitions-and-non-centered-priors"><i class="fa fa-check"></i><b>13.4</b> Divergent transitions and non-centered priors</a><ul>
<li class="chapter" data-level="13.4.1" data-path="models-with-memory.html"><a href="models-with-memory.html#the-devils-funnel."><i class="fa fa-check"></i><b>13.4.1</b> The Devil’s Funnel.</a></li>
<li class="chapter" data-level="13.4.2" data-path="models-with-memory.html"><a href="models-with-memory.html#non-centered-chimpanzees."><i class="fa fa-check"></i><b>13.4.2</b> Non-centered chimpanzees.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="models-with-memory.html"><a href="models-with-memory.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>13.5</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="13.5.1" data-path="models-with-memory.html"><a href="models-with-memory.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>13.5.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="13.5.2" data-path="models-with-memory.html"><a href="models-with-memory.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>13.5.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="13.5.3" data-path="models-with-memory.html"><a href="models-with-memory.html#post-stratification."><i class="fa fa-check"></i><b>13.5.3</b> Post-stratification.</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="models-with-memory.html"><a href="models-with-memory.html#summary-bonus-post-stratification-in-an-example"><i class="fa fa-check"></i><b>13.6</b> <del>Summary</del> Bonus: Post-stratification in an example</a><ul>
<li class="chapter" data-level="13.6.1" data-path="models-with-memory.html"><a href="models-with-memory.html#meet-the-data."><i class="fa fa-check"></i><b>13.6.1</b> Meet the data.</a></li>
<li class="chapter" data-level="13.6.2" data-path="models-with-memory.html"><a href="models-with-memory.html#settle-the-mr-part-of-mrp."><i class="fa fa-check"></i><b>13.6.2</b> Settle the MR part of MRP.</a></li>
<li class="chapter" data-level="13.6.3" data-path="models-with-memory.html"><a href="models-with-memory.html#post-stratify-to-put-the-p-in-mrp."><i class="fa fa-check"></i><b>13.6.3</b> Post-stratify to put the P in MRP.</a></li>
<li class="chapter" data-level="13.6.4" data-path="models-with-memory.html"><a href="models-with-memory.html#wrap-this-mrp-up."><i class="fa fa-check"></i><b>13.6.4</b> Wrap this MRP up.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models-with-memory.html"><a href="models-with-memory.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>14</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="14.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>14.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="14.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>14.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="14.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>14.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="14.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>14.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#advanced-varying-slopes"><i class="fa fa-check"></i><b>14.2</b> Advanced varying slopes</a></li>
<li class="chapter" data-level="14.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#instruments-and-causal-designs"><i class="fa fa-check"></i><b>14.3</b> Instruments and causal designs</a><ul>
<li class="chapter" data-level="14.3.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#instrumental-variables."><i class="fa fa-check"></i><b>14.3.1</b> Instrumental variables.</a></li>
<li class="chapter" data-level="14.3.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#other-designs."><i class="fa fa-check"></i><b>14.3.2</b> Other designs.</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#social-relations-as-correlated-varying-effects"><i class="fa fa-check"></i><b>14.4</b> Social relations as correlated varying effects</a></li>
<li class="chapter" data-level="14.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>14.5</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="14.5.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>14.5.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
<li class="chapter" data-level="14.5.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-phylogenetic-distance."><i class="fa fa-check"></i><b>14.5.2</b> Example: Phylogenetic distance.</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-multilevel-growth-models-and-the-melsm"><i class="fa fa-check"></i><b>14.6</b> <del>Summary</del> Bonus: Multilevel growth models and the MELSM</a><ul>
<li class="chapter" data-level="14.6.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#borrow-some-data."><i class="fa fa-check"></i><b>14.6.1</b> Borrow some data.</a></li>
<li class="chapter" data-level="14.6.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#conventional-multilevel-growth-model."><i class="fa fa-check"></i><b>14.6.2</b> Conventional multilevel growth model.</a></li>
<li class="chapter" data-level="14.6.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#learn-more-about-your-data-with-the-melsm."><i class="fa fa-check"></i><b>14.6.3</b> Learn more about your data with the MELSM.</a></li>
<li class="chapter" data-level="14.6.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#time-to-go-multivariate."><i class="fa fa-check"></i><b>14.6.4</b> Time to go multivariate.</a></li>
<li class="chapter" data-level="14.6.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#growth-modelmelsm-wrap-up."><i class="fa fa-check"></i><b>14.6.5</b> Growth model/MELSM wrap-up.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>15</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="15.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>15.1</b> Measurement error</a><ul>
<li class="chapter" data-level="15.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>15.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="15.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>15.1.2</b> Error on both outcome and predictor.</a></li>
<li class="chapter" data-level="15.1.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-terrors."><i class="fa fa-check"></i><b>15.1.3</b> Measurement terrors.</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>15.2</b> Missing data</a><ul>
<li class="chapter" data-level="15.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#dag-ate-my-homework."><i class="fa fa-check"></i><b>15.2.1</b> DAG ate my homework.</a></li>
<li class="chapter" data-level="15.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-primates."><i class="fa fa-check"></i><b>15.2.2</b> Imputing primates.</a></li>
<li class="chapter" data-level="15.2.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#where-is-your-god-now"><i class="fa fa-check"></i><b>15.2.3</b> Where is your god now?</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#categorical-errors-and-discrete-absences"><i class="fa fa-check"></i><b>15.3</b> Categorical errors and discrete absences</a><ul>
<li class="chapter" data-level="15.3.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#discrete-cats."><i class="fa fa-check"></i><b>15.3.1</b> Discrete cats.</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#summary-2"><i class="fa fa-check"></i><b>15.4</b> Summary</a></li>
<li class="chapter" data-level="15.5" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#bonus-bayesian-meta-analysis-with-odds-ratios"><i class="fa fa-check"></i><b>15.5</b> Bonus: Bayesian meta-analysis with odds ratios</a><ul>
<li class="chapter" data-level="15.5.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#how-do-meta-analyses-fit-into-the-picture"><i class="fa fa-check"></i><b>15.5.1</b> How do meta-analyses fit into the picture?</a></li>
<li class="chapter" data-level="15.5.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#we-need-some-data."><i class="fa fa-check"></i><b>15.5.2</b> We need some data.</a></li>
<li class="chapter" data-level="15.5.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#our-effect-size-will-be-an-odds-ratio."><i class="fa fa-check"></i><b>15.5.3</b> Our effect size will be an odds ratio.</a></li>
<li class="chapter" data-level="15.5.4" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#log-odds-odds-ratios-and-modeling-effect-sizes."><i class="fa fa-check"></i><b>15.5.4</b> Log-odds, odds ratios, and modeling effect sizes.</a></li>
<li class="chapter" data-level="15.5.5" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#compute-the-study-specific-effect-sizes."><i class="fa fa-check"></i><b>15.5.5</b> Compute the study-specific effect sizes.</a></li>
<li class="chapter" data-level="15.5.6" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#fit-the-bayesian-meta-analysis."><i class="fa fa-check"></i><b>15.5.6</b> Fit the Bayesian meta-analysis.</a></li>
<li class="chapter" data-level="15.5.7" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#fit-the-bayesian-muiltilevel-alternative."><i class="fa fa-check"></i><b>15.5.7</b> Fit the Bayesian muiltilevel alternative.</a></li>
<li class="chapter" data-level="15.5.8" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#parting-thoughts."><i class="fa fa-check"></i><b>15.5.8</b> Parting thoughts.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html"><i class="fa fa-check"></i><b>16</b> Generalized Linear Madness</a><ul>
<li class="chapter" data-level="16.1" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#geometric-people"><i class="fa fa-check"></i><b>16.1</b> Geometric people</a><ul>
<li class="chapter" data-level="16.1.1" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#the-scientific-model."><i class="fa fa-check"></i><b>16.1.1</b> The scientific model.</a></li>
<li class="chapter" data-level="16.1.2" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#the-statistical-model."><i class="fa fa-check"></i><b>16.1.2</b> The statistical model.</a></li>
<li class="chapter" data-level="16.1.3" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#glm-in-disguise."><i class="fa fa-check"></i><b>16.1.3</b> GLM in disguise.</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#hidden-minds-and-observed-behavior"><i class="fa fa-check"></i><b>16.2</b> Hidden minds and observed behavior</a><ul>
<li class="chapter" data-level="16.2.1" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#the-scientific-model.-1"><i class="fa fa-check"></i><b>16.2.1</b> The scientific model.</a></li>
<li class="chapter" data-level="16.2.2" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#the-statistical-model.-1"><i class="fa fa-check"></i><b>16.2.2</b> The statistical model.</a></li>
<li class="chapter" data-level="16.2.3" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#coding-the-statistical-model."><i class="fa fa-check"></i><b>16.2.3</b> Coding the statistical model.</a></li>
<li class="chapter" data-level="16.2.4" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#state-space-models."><i class="fa fa-check"></i><b>16.2.4</b> State space models.</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#ordinary-differential-nut-cracking"><i class="fa fa-check"></i><b>16.3</b> Ordinary differential nut cracking</a><ul>
<li class="chapter" data-level="16.3.1" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#scientific-model."><i class="fa fa-check"></i><b>16.3.1</b> Scientific model.</a></li>
<li class="chapter" data-level="16.3.2" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#statistical-model."><i class="fa fa-check"></i><b>16.3.2</b> Statistical model.</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#population-dynamics"><i class="fa fa-check"></i><b>16.4</b> Population dynamics</a><ul>
<li class="chapter" data-level="16.4.1" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#the-scientific-model.-2"><i class="fa fa-check"></i><b>16.4.1</b> The scientific model.</a></li>
<li class="chapter" data-level="16.4.2" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#the-statistical-model.-2"><i class="fa fa-check"></i><b>16.4.2</b> The statistical model.</a></li>
<li class="chapter" data-level="16.4.3" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#lynx-lessons-bonus-practice-with-the-autoregressive-model."><i class="fa fa-check"></i><b>16.4.3</b> <del>Lynx lessons</del> Bonus: Practice with the autoregressive model.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="generalized-linear-madness.html"><a href="generalized-linear-madness.html#session-info-15"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>17</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="17.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>17.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="17.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>17.2</b> Save your model fits</a></li>
<li class="chapter" data-level="17.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>17.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="17.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>17.4</b> Look at your data</a></li>
<li class="chapter" data-level="17.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#consider-using-the-0-intercept-syntax"><i class="fa fa-check"></i><b>17.5</b> Consider using the <code>0 + Intercept</code> syntax</a></li>
<li class="chapter" data-level="17.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>17.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="17.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>17.7</b> Annotate your code</a></li>
<li class="chapter" data-level="17.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>17.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="17.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#code-in-public"><i class="fa fa-check"></i><b>17.9</b> Code in public</a></li>
<li class="chapter" data-level="17.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-social-media"><i class="fa fa-check"></i><b>17.10</b> Check out social media</a></li>
<li class="chapter" data-level="17.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>17.11</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-16"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical rethinking</em> with brms, ggplot2, and the tidyverse: Second edition</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalized-linear-madness" class="section level1">
<h1><span class="header-section-number">16</span> Generalized Linear Madness</h1>
<blockquote>
<p>Applied statistics has to apply to all the sciences, and so it is often much vaguer about models. Instead it focuses on average performance, regardless of the model. The generalized linear models in the preceding chapters are not credible scientific models of most natural processes. They are powerful, geocentric (<a href="geocentric-models.html#geocentric-models">Chapter 4</a>) descriptions of associations. In combination with a logic of causal inference, for example DAGs and <em>do</em>-calculus, generalized linear models can nevertheless be unreasonably powerful.</p>
<p>But there are problems with this GLMs-plus-DAGs approach. Not everything can be modeled as a GLM—a linear combination of variables mapped onto a non-linear outcome. But if it is the only approach you know, then you have to use it….</p>
<p>In this chapter, I will go <strong>beyond generalized linear madness</strong>. I’ll work through examples in which the scientific context provides a causal model that will breathe life into the statistical model. I’ve chosen examples which are individually distinct and highlight different challenges in developing and translating causal models into <em>bespoke</em> (see the Rethinking <del>box</del> [section] below) statistical models. You won’t require any specialized scientific expertise to grasp these examples. And the basic strategy is the same as it has been from the start: Define a generative model of a phenomenon and then use that model to design strategies for causal inference and statistical estimation. <span class="citation">(McElreath, <a href="#ref-mcelreathStatisticalRethinkingBayesian2020" role="doc-biblioref">2020</a><a href="#ref-mcelreathStatisticalRethinkingBayesian2020" role="doc-biblioref">b</a>, p. 525, <em>emphasis</em> in the original)</span></p>
</blockquote>
<p>McElreath then reported he was going to work with Stan code, via <code>rstan::stan()</code>, in this chapter because of the unique demands of some of the models. Our approach will be mixed. We can fit at least a few of the models with <strong>brms</strong>, particularly with help from the non-linear syntax. However, some of the models to ome are either beyond the current scope of <strong>brms</strong> or are at least beyond my current skill set. In those cases, we’ll follow McElreath’s approach and fit the models with <code>stan()</code>.</p>
<div id="rethinking-bespoken-for." class="section level4">
<h4><span class="header-section-number">16.0.0.1</span> Rethinking: Bespoken for.</h4>
<blockquote>
<p>Mass production has some advantages, but it also makes our clothes fit badly. Garments bought off-the-shelf are not manufactured with you in mind. They are not <em>bespoke</em> products, designed for any particular person with a particular body. Unless you are lucky to have a perfectly average body shape, you will need a tailor to get better.</p>
<p>Statistical analyses are similar. Generalized linear models are off-the-shelf products, mass produced for a consumer market of impatient researchers with diverse goals. Science asked statisticians for tools that could be used anywhere. And so they delivered. But the clothes don’t always fit. (p. 526, <em>emphasis</em> in the original)</p>
</blockquote>
</div>
<div id="geometric-people" class="section level2">
<h2><span class="header-section-number">16.1</span> Geometric people</h2>
<blockquote>
<p>Back in <a href="geocentric-models.html#geocentric-models">Chapter 4</a>, you met linear regression in the context of building a predictive model of height using weight. You even saw how to measure non-linear associations between the two variables. But nothing in that example was scientifically satisfying. The height-weight model was just a statistical device. It contains no biological information and tells us nothing about how the association between height and weight arises. Consider for example that weight obviously does not <em>cause</em> height, at least not in humans. If anything, the causal relationship is the reverse.</p>
<p>So now let’s try to do better. Why? Because when the model is scientifically inspired, rather than just statistically required, disagreements between model and data are informative of real causal relationships.</p>
<p>Suppose for example that a person is shaped like a cylinder. Of course a person isn’t exactly shaped like a cylinder. There are arms and a head. But let’s see how far this cylinder model gets us. The weight of the cylinder is a consequence of the volume of the cylinder. And the volume of the cylinder is a consequence of growth in the height and width of the cylinder. So if we can relate the height to the volume, then we’d have a model to predict weight from height. (p. 526, <em>emphasis</em> in the original)</p>
</blockquote>
<div id="the-scientific-model." class="section level3">
<h3><span class="header-section-number">16.1.1</span> The scientific model.</h3>
<p>If we let <span class="math inline">\(V\)</span> stand for volume, <span class="math inline">\(r\)</span> stand for a radius, and <span class="math inline">\(h\)</span> stand for height, we can solve for volume by</p>
<p><span class="math display">\[V = \pi r^2 h.\]</span>
If we further presume a person’s radius is unknown, but some proportion (<span class="math inline">\(p\)</span>) of height (<span class="math inline">\(ph\)</span>), we can rewrite the formula as</p>
<p><span class="math display">\[
\begin{align*}
V &amp; = \pi (ph)^2 h \\
  &amp; = \pi p^2 h^3.
\end{align*}
\]</span></p>
<p>Though we’re not interested in volume per se, we might presume weight is some proportion of volume. Thus we could include a final parameter <span class="math inline">\(k\)</span> to stand for the conversion form weight to volume, leaving us with the formula</p>
<p><span class="math display">\[W = kV = k \pi p^2 h^3,\]</span></p>
<p>where <span class="math inline">\(W\)</span> denotes weight.</p>
</div>
<div id="the-statistical-model." class="section level3">
<h3><span class="header-section-number">16.1.2</span> The statistical model.</h3>
<p>For one last time, together, let’s load the <code>Howell1</code> data.</p>
<div class="sourceCode" id="cb2057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2057-1"><a href="generalized-linear-madness.html#cb2057-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb2057-2"><a href="generalized-linear-madness.html#cb2057-2"></a><span class="kw">data</span>(Howell1, <span class="dt">package =</span> <span class="st">&quot;rethinking&quot;</span>)</span>
<span id="cb2057-3"><a href="generalized-linear-madness.html#cb2057-3"></a>d &lt;-<span class="st"> </span>Howell1</span>
<span id="cb2057-4"><a href="generalized-linear-madness.html#cb2057-4"></a><span class="kw">rm</span>(Howell1)</span>
<span id="cb2057-5"><a href="generalized-linear-madness.html#cb2057-5"></a></span>
<span id="cb2057-6"><a href="generalized-linear-madness.html#cb2057-6"></a><span class="co"># scale observed variables</span></span>
<span id="cb2057-7"><a href="generalized-linear-madness.html#cb2057-7"></a>d &lt;-</span>
<span id="cb2057-8"><a href="generalized-linear-madness.html#cb2057-8"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2057-9"><a href="generalized-linear-madness.html#cb2057-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">w =</span> weight <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(weight),</span>
<span id="cb2057-10"><a href="generalized-linear-madness.html#cb2057-10"></a>         <span class="dt">h =</span> height <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(height))</span></code></pre></div>
<p>McElreath’s proposed statistical model follows the form</p>
<p><span class="math display">\[
\begin{align*}
\text{w}_i  &amp; \sim \operatorname{Log-Normal}(\mu_i, \sigma) \\
\exp(\mu_i) &amp; = k \pi p^2 \text{h}_i^3 \\
k      &amp; \sim \operatorname{Exponential}(0.5) \\
p      &amp; \sim \operatorname{Beta}(2, 18) \\
\sigma &amp; \sim \operatorname{Exponential}(1), &amp;&amp; \text{where} \\
\text w_i &amp; = \text{weight}_i \big / \overline{\text{weight}}, &amp;&amp; \text{and} \\
\text h_i &amp; = \text{height}_i \big / \overline{\text{height}}.
\end{align*}
\]</span></p>
<p>The Log-Normal likelihood ensures the predictions for <span class="math inline">\(\text{weight}_i\)</span> will always be non-negative. Because our parameter <span class="math inline">\(p\)</span> is the ratio of radius to height, <span class="math inline">\(p = r / h\)</span>, it must be positive. Since people are typically taller than their width, it should also be less than one, and probably substantially less than that. Our next step will be taking a look at our priors.</p>
<p>For the plots in this chapter, we’ll give a nod the minimalistic plots in the authoritative text by <span class="citation">Gelman, Carlin, et al. (<a href="#ref-gelman2013bayesian" role="doc-biblioref">2013</a>)</span>, <a href="https://stat.columbia.edu/~gelman/book/"><em>Bayesian data analysis: Third edition</em></a>. Just to be a little kick, we’ll set the font to <code>family = "Times"</code>. Most of the adjustments will come from <code>ggthemes::theme_base()</code>.</p>
<div class="sourceCode" id="cb2058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2058-1"><a href="generalized-linear-madness.html#cb2058-1"></a><span class="kw">library</span>(ggthemes)</span>
<span id="cb2058-2"><a href="generalized-linear-madness.html#cb2058-2"></a></span>
<span id="cb2058-3"><a href="generalized-linear-madness.html#cb2058-3"></a><span class="kw">theme_set</span>(</span>
<span id="cb2058-4"><a href="generalized-linear-madness.html#cb2058-4"></a>  <span class="kw">theme_base</span>(<span class="dt">base_size =</span> <span class="dv">12</span>) <span class="op">+</span></span>
<span id="cb2058-5"><a href="generalized-linear-madness.html#cb2058-5"></a><span class="st">    </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb2058-6"><a href="generalized-linear-madness.html#cb2058-6"></a>          <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb2058-7"><a href="generalized-linear-madness.html#cb2058-7"></a>          <span class="dt">axis.ticks =</span> <span class="kw">element_line</span>(<span class="dt">size =</span> <span class="fl">0.25</span>),</span>
<span id="cb2058-8"><a href="generalized-linear-madness.html#cb2058-8"></a>          <span class="dt">axis.ticks.length =</span> <span class="kw">unit</span>(<span class="fl">0.1</span>, <span class="st">&quot;cm&quot;</span>),</span>
<span id="cb2058-9"><a href="generalized-linear-madness.html#cb2058-9"></a>          <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">size =</span> <span class="fl">0.1</span>),</span>
<span id="cb2058-10"><a href="generalized-linear-madness.html#cb2058-10"></a>          <span class="dt">plot.background =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb2058-11"><a href="generalized-linear-madness.html#cb2058-11"></a>          )</span>
<span id="cb2058-12"><a href="generalized-linear-madness.html#cb2058-12"></a>  )</span></code></pre></div>
<p>Now we have our theme, let’s get a sense of our priors.</p>
<div class="sourceCode" id="cb2059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2059-1"><a href="generalized-linear-madness.html#cb2059-1"></a><span class="kw">library</span>(tidybayes)</span>
<span id="cb2059-2"><a href="generalized-linear-madness.html#cb2059-2"></a><span class="kw">library</span>(brms)</span>
<span id="cb2059-3"><a href="generalized-linear-madness.html#cb2059-3"></a></span>
<span id="cb2059-4"><a href="generalized-linear-madness.html#cb2059-4"></a><span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">beta</span>(<span class="dv">2</span>, <span class="dv">18</span>), <span class="dt">nlpar =</span> p, <span class="dt">coef =</span> <span class="kw">italic</span>(p)),</span>
<span id="cb2059-5"><a href="generalized-linear-madness.html#cb2059-5"></a>  <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="fl">0.5</span>), <span class="dt">nlpar =</span> p, <span class="dt">coef =</span> <span class="kw">italic</span>(k)),</span>
<span id="cb2059-6"><a href="generalized-linear-madness.html#cb2059-6"></a>  <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="dv">1</span>), <span class="dt">class =</span> sigma, <span class="dt">coef =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2059-7"><a href="generalized-linear-madness.html#cb2059-7"></a><span class="st">  </span></span>
<span id="cb2059-8"><a href="generalized-linear-madness.html#cb2059-8"></a><span class="st">  </span><span class="kw">parse_dist</span>(prior) <span class="op">%&gt;%</span></span>
<span id="cb2059-9"><a href="generalized-linear-madness.html#cb2059-9"></a><span class="st">  </span></span>
<span id="cb2059-10"><a href="generalized-linear-madness.html#cb2059-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>, <span class="dt">dist =</span> .dist, <span class="dt">args =</span> .args)) <span class="op">+</span></span>
<span id="cb2059-11"><a href="generalized-linear-madness.html#cb2059-11"></a><span class="st">  </span><span class="kw">stat_dist_halfeye</span>(<span class="dt">.width =</span> <span class="fl">.5</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">p_limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.9995</span>),</span>
<span id="cb2059-12"><a href="generalized-linear-madness.html#cb2059-12"></a>                    <span class="dt">n =</span> <span class="fl">2e3</span>, <span class="dt">normalize =</span> <span class="st">&quot;xy&quot;</span>) <span class="op">+</span></span>
<span id="cb2059-13"><a href="generalized-linear-madness.html#cb2059-13"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2059-14"><a href="generalized-linear-madness.html#cb2059-14"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span></span>
<span id="cb2059-15"><a href="generalized-linear-madness.html#cb2059-15"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>coef, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Here the points are the posterior medians and the horizontal lines the quantile-based 50% intervals. Turns out that <span class="math inline">\(\operatorname{Beta}(2, 18)\)</span> prior for <span class="math inline">\(p\)</span> pushes the bulk of the prior mass down near zero. The beta distribution also forces the parameter space for <span class="math inline">\(p\)</span> to range between 0 and 1. If we denote the two parameters of the beta distribution as <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we can compute the mean for any beta distribution as <span class="math inline">\(\alpha / (\alpha + \beta)\)</span>. Thus the mean for our <span class="math inline">\(\operatorname{Beta}(2, 18)\)</span> prior is <span class="math inline">\(2 / (2 + 18) = 2 / 20 = 0.1\)</span>.</p>
<p>Because we computed our weight and height variables, <code>w</code> and <code>h</code>, by dividing the original variables by their respective means, each now has a mean of 1.</p>
<div class="sourceCode" id="cb2060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2060-1"><a href="generalized-linear-madness.html#cb2060-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2060-2"><a href="generalized-linear-madness.html#cb2060-2"></a><span class="st">  </span><span class="kw">pivot_longer</span>(w<span class="op">:</span>h) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2060-3"><a href="generalized-linear-madness.html#cb2060-3"></a><span class="st">  </span><span class="kw">group_by</span>(name) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2060-4"><a href="generalized-linear-madness.html#cb2060-4"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(value))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   name   mean
##   &lt;chr&gt; &lt;dbl&gt;
## 1 h         1
## 2 w         1</code></pre>
<p>Here’s their bivariate distribution in a scatter plot.</p>
<div class="sourceCode" id="cb2062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2062-1"><a href="generalized-linear-madness.html#cb2062-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2062-2"><a href="generalized-linear-madness.html#cb2062-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> h, <span class="dt">y =</span> w)) <span class="op">+</span></span>
<span id="cb2062-3"><a href="generalized-linear-madness.html#cb2062-3"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></span>
<span id="cb2062-4"><a href="generalized-linear-madness.html#cb2062-4"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></span>
<span id="cb2062-5"><a href="generalized-linear-madness.html#cb2062-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-6-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>With this scaling, here is the formula for an individual with average weight and height:</p>
<p><span class="math display">\[
\begin{align*}
1 &amp; = k \pi p^2 1^3 \\
  &amp; = k \pi p^2.
\end{align*}
\]</span></p>
<p>If you assume <span class="math inline">\(p &lt; .5\)</span>, <span class="math inline">\(k\)</span> must be greater than 1. <span class="math inline">\(k\)</span> also has to be positive. To get a sense of this, we can further work the algebra:</p>
<p><span class="math display">\[
\begin{align*}
1 &amp; = k \pi p^2 \\
1/k  &amp; = \pi p^2 \\
k  &amp; = 1 / \pi p^2.
\end{align*}
\]</span></p>
<p>To get a better sense of that relation, we might plot.</p>
<div class="sourceCode" id="cb2063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2063-1"><a href="generalized-linear-madness.html#cb2063-1"></a><span class="kw">tibble</span>(<span class="dt">p =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">0.001</span>, <span class="dt">to =</span> <span class="fl">0.499</span>, <span class="dt">by =</span> <span class="fl">0.001</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2063-2"><a href="generalized-linear-madness.html#cb2063-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">k =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(pi <span class="op">*</span><span class="st"> </span>p<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2063-3"><a href="generalized-linear-madness.html#cb2063-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> p, <span class="dt">y =</span> k)) <span class="op">+</span></span>
<span id="cb2063-4"><a href="generalized-linear-madness.html#cb2063-4"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb2063-5"><a href="generalized-linear-madness.html#cb2063-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(p)),</span>
<span id="cb2063-6"><a href="generalized-linear-madness.html#cb2063-6"></a>       <span class="dt">y =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(k))) <span class="op">+</span></span>
<span id="cb2063-7"><a href="generalized-linear-madness.html#cb2063-7"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">500</span>))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-7-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>McElreath’s quick and dirty solution was to set <span class="math inline">\(k \sim \operatorname{Exponential}(0.5)\)</span>, which has a prior predictive mean of 2.</p>
<p>By setting up his model formula as <code>exp(mu) = ...</code>, McElreath effectively used the log link. It turns out that <strong>brms</strong> only supports the <code>identity</code> and <code>inverse</code> links for <code>family = lognormal</code>. However, we can sneak in the log link by nesting the right-hand side of the formula within <code>log()</code>.</p>
<div class="sourceCode" id="cb2064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2064-1"><a href="generalized-linear-madness.html#cb2064-1"></a>b16<span class="fl">.1</span> &lt;-<span class="st"> </span></span>
<span id="cb2064-2"><a href="generalized-linear-madness.html#cb2064-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</span>
<span id="cb2064-3"><a href="generalized-linear-madness.html#cb2064-3"></a>      <span class="dt">family =</span> lognormal,</span>
<span id="cb2064-4"><a href="generalized-linear-madness.html#cb2064-4"></a>      <span class="kw">bf</span>(w <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(<span class="fl">3.141593</span> <span class="op">*</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>p<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>h<span class="op">^</span><span class="dv">3</span>),</span>
<span id="cb2064-5"><a href="generalized-linear-madness.html#cb2064-5"></a>         k <span class="op">+</span><span class="st"> </span>p <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb2064-6"><a href="generalized-linear-madness.html#cb2064-6"></a>         <span class="dt">nl =</span> <span class="ot">TRUE</span>),</span>
<span id="cb2064-7"><a href="generalized-linear-madness.html#cb2064-7"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">beta</span>(<span class="dv">2</span>, <span class="dv">18</span>), <span class="dt">nlpar =</span> p, <span class="dt">lb =</span> <span class="dv">0</span>, <span class="dt">ub =</span> <span class="dv">1</span>),</span>
<span id="cb2064-8"><a href="generalized-linear-madness.html#cb2064-8"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="fl">0.5</span>), <span class="dt">nlpar =</span> k, <span class="dt">lb =</span> <span class="dv">0</span>),</span>
<span id="cb2064-9"><a href="generalized-linear-madness.html#cb2064-9"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb2064-10"><a href="generalized-linear-madness.html#cb2064-10"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb2064-11"><a href="generalized-linear-madness.html#cb2064-11"></a>      <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2064-12"><a href="generalized-linear-madness.html#cb2064-12"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b16.01&quot;</span>)</span></code></pre></div>
<p>Check the parameter summary.</p>
<div class="sourceCode" id="cb2065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2065-1"><a href="generalized-linear-madness.html#cb2065-1"></a><span class="kw">print</span>(b16<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##  Family: lognormal 
##   Links: mu = identity; sigma = identity 
## Formula: w ~ log(3.141593 * k * p^2 * h^3) 
##          k ~ 1
##          p ~ 1
##    Data: d (Number of observations: 544) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## k_Intercept     5.79      2.72     2.16    12.49 1.00     1177     1488
## p_Intercept     0.25      0.06     0.16     0.37 1.00     1178     1459
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.21      0.01     0.19     0.22 1.00     1345     1133
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>McElreath didn’t show the parameter summary for his <code>m16.1</code> in the text. If you fit the model with both <strong>rethinking</strong> and <strong>brms</strong>, you’ll see our <code>b16.1</code> matches up quite well. To make our version of Figure 16.2, we’ll use a <code>GGally::ggpairs()</code> workflow. First we’ll save our customizes settings for the three subplot types.</p>
<div class="sourceCode" id="cb2067"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2067-1"><a href="generalized-linear-madness.html#cb2067-1"></a>my_lower &lt;-<span class="st"> </span><span class="cf">function</span>(data, mapping, ...) {</span>
<span id="cb2067-2"><a href="generalized-linear-madness.html#cb2067-2"></a>  </span>
<span id="cb2067-3"><a href="generalized-linear-madness.html#cb2067-3"></a>  <span class="co"># get the x and y data to use the other code</span></span>
<span id="cb2067-4"><a href="generalized-linear-madness.html#cb2067-4"></a>  x &lt;-<span class="st"> </span><span class="kw">eval_data_col</span>(data, mapping<span class="op">$</span>x)</span>
<span id="cb2067-5"><a href="generalized-linear-madness.html#cb2067-5"></a>  y &lt;-<span class="st"> </span><span class="kw">eval_data_col</span>(data, mapping<span class="op">$</span>y)</span>
<span id="cb2067-6"><a href="generalized-linear-madness.html#cb2067-6"></a>  </span>
<span id="cb2067-7"><a href="generalized-linear-madness.html#cb2067-7"></a>  <span class="co"># compute the correlations</span></span>
<span id="cb2067-8"><a href="generalized-linear-madness.html#cb2067-8"></a>  corr &lt;-<span class="st"> </span><span class="kw">cor</span>(x, y, <span class="dt">method =</span> <span class="st">&quot;p&quot;</span>, <span class="dt">use =</span> <span class="st">&quot;pairwise&quot;</span>)</span>
<span id="cb2067-9"><a href="generalized-linear-madness.html#cb2067-9"></a>  abs_corr &lt;-<span class="st"> </span><span class="kw">abs</span>(corr)</span>
<span id="cb2067-10"><a href="generalized-linear-madness.html#cb2067-10"></a>  </span>
<span id="cb2067-11"><a href="generalized-linear-madness.html#cb2067-11"></a>  <span class="co"># plot the cor value</span></span>
<span id="cb2067-12"><a href="generalized-linear-madness.html#cb2067-12"></a>  <span class="kw">ggally_text</span>(</span>
<span id="cb2067-13"><a href="generalized-linear-madness.html#cb2067-13"></a>    <span class="dt">label =</span> <span class="kw">formatC</span>(corr, <span class="dt">digits =</span> <span class="dv">2</span>, <span class="dt">format =</span> <span class="st">&quot;f&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">str_replace</span>(., <span class="st">&quot;0.&quot;</span>, <span class="st">&quot;.&quot;</span>),</span>
<span id="cb2067-14"><a href="generalized-linear-madness.html#cb2067-14"></a>    <span class="dt">mapping =</span> <span class="kw">aes</span>(),</span>
<span id="cb2067-15"><a href="generalized-linear-madness.html#cb2067-15"></a>    <span class="dt">size =</span> <span class="fl">3.5</span>, </span>
<span id="cb2067-16"><a href="generalized-linear-madness.html#cb2067-16"></a>    <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb2067-17"><a href="generalized-linear-madness.html#cb2067-17"></a>    <span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>) <span class="op">+</span></span>
<span id="cb2067-18"><a href="generalized-linear-madness.html#cb2067-18"></a><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2067-19"><a href="generalized-linear-madness.html#cb2067-19"></a><span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>)</span>
<span id="cb2067-20"><a href="generalized-linear-madness.html#cb2067-20"></a>}</span>
<span id="cb2067-21"><a href="generalized-linear-madness.html#cb2067-21"></a></span>
<span id="cb2067-22"><a href="generalized-linear-madness.html#cb2067-22"></a>my_diag &lt;-<span class="st"> </span><span class="cf">function</span>(data, mapping, ...) {</span>
<span id="cb2067-23"><a href="generalized-linear-madness.html#cb2067-23"></a>  <span class="kw">ggplot</span>(<span class="dt">data =</span> data, <span class="dt">mapping =</span> mapping) <span class="op">+</span><span class="st"> </span></span>
<span id="cb2067-24"><a href="generalized-linear-madness.html#cb2067-24"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">bins =</span> <span class="dv">20</span>) <span class="op">+</span></span>
<span id="cb2067-25"><a href="generalized-linear-madness.html#cb2067-25"></a><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2067-26"><a href="generalized-linear-madness.html#cb2067-26"></a><span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>)</span>
<span id="cb2067-27"><a href="generalized-linear-madness.html#cb2067-27"></a>}</span>
<span id="cb2067-28"><a href="generalized-linear-madness.html#cb2067-28"></a></span>
<span id="cb2067-29"><a href="generalized-linear-madness.html#cb2067-29"></a>my_upper &lt;-<span class="st"> </span><span class="cf">function</span>(data, mapping, ...) {</span>
<span id="cb2067-30"><a href="generalized-linear-madness.html#cb2067-30"></a>  <span class="kw">ggplot</span>(<span class="dt">data =</span> data, <span class="dt">mapping =</span> mapping) <span class="op">+</span><span class="st"> </span></span>
<span id="cb2067-31"><a href="generalized-linear-madness.html#cb2067-31"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb2067-32"><a href="generalized-linear-madness.html#cb2067-32"></a><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2067-33"><a href="generalized-linear-madness.html#cb2067-33"></a><span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>)</span>
<span id="cb2067-34"><a href="generalized-linear-madness.html#cb2067-34"></a>}</span></code></pre></div>
<p>Now we make our version of Figure 16.2.a.</p>
<div class="sourceCode" id="cb2068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2068-1"><a href="generalized-linear-madness.html#cb2068-1"></a><span class="kw">library</span>(GGally)</span>
<span id="cb2068-2"><a href="generalized-linear-madness.html#cb2068-2"></a></span>
<span id="cb2068-3"><a href="generalized-linear-madness.html#cb2068-3"></a><span class="kw">posterior_samples</span>(b16<span class="fl">.1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2068-4"><a href="generalized-linear-madness.html#cb2068-4"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>lp__) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2068-5"><a href="generalized-linear-madness.html#cb2068-5"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="kw">c</span>(<span class="st">&quot;italic(k)&quot;</span>, <span class="st">&quot;italic(p)&quot;</span>, <span class="st">&quot;sigma&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2068-6"><a href="generalized-linear-madness.html#cb2068-6"></a><span class="st">  </span><span class="kw">ggpairs</span>(<span class="dt">upper =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> my_upper),</span>
<span id="cb2068-7"><a href="generalized-linear-madness.html#cb2068-7"></a>          <span class="dt">diag =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> my_diag),</span>
<span id="cb2068-8"><a href="generalized-linear-madness.html#cb2068-8"></a>          <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> my_lower),</span>
<span id="cb2068-9"><a href="generalized-linear-madness.html#cb2068-9"></a>          <span class="dt">labeller =</span> label_parsed) <span class="op">+</span></span>
<span id="cb2068-10"><a href="generalized-linear-madness.html#cb2068-10"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>),</span>
<span id="cb2068-11"><a href="generalized-linear-madness.html#cb2068-11"></a>        <span class="dt">strip.text.y =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">0</span>))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-10-1.png" width="432" style="display: block; margin: auto;" /></p>
<p>We see the lack of identifiability of <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span> resulted in a strong inverse relation between them. Now here’s how we might make Figure 16.2.b.</p>
<div class="sourceCode" id="cb2069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2069-1"><a href="generalized-linear-madness.html#cb2069-1"></a>nd &lt;-<span class="st"> </span></span>
<span id="cb2069-2"><a href="generalized-linear-madness.html#cb2069-2"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">h =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="fl">1.5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>))</span>
<span id="cb2069-3"><a href="generalized-linear-madness.html#cb2069-3"></a></span>
<span id="cb2069-4"><a href="generalized-linear-madness.html#cb2069-4"></a>p &lt;-</span>
<span id="cb2069-5"><a href="generalized-linear-madness.html#cb2069-5"></a><span class="st">  </span><span class="kw">predict</span>(b16<span class="fl">.1</span>,</span>
<span id="cb2069-6"><a href="generalized-linear-madness.html#cb2069-6"></a>          <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2069-7"><a href="generalized-linear-madness.html#cb2069-7"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2069-8"><a href="generalized-linear-madness.html#cb2069-8"></a><span class="st">  </span><span class="kw">bind_cols</span>(nd)</span>
<span id="cb2069-9"><a href="generalized-linear-madness.html#cb2069-9"></a></span>
<span id="cb2069-10"><a href="generalized-linear-madness.html#cb2069-10"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2069-11"><a href="generalized-linear-madness.html#cb2069-11"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> h)) <span class="op">+</span></span>
<span id="cb2069-12"><a href="generalized-linear-madness.html#cb2069-12"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> p,</span>
<span id="cb2069-13"><a href="generalized-linear-madness.html#cb2069-13"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb2069-14"><a href="generalized-linear-madness.html#cb2069-14"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb2069-15"><a href="generalized-linear-madness.html#cb2069-15"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb2069-16"><a href="generalized-linear-madness.html#cb2069-16"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> w),</span>
<span id="cb2069-17"><a href="generalized-linear-madness.html#cb2069-17"></a>             <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb2069-18"><a href="generalized-linear-madness.html#cb2069-18"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(d<span class="op">$</span>h)),</span>
<span id="cb2069-19"><a href="generalized-linear-madness.html#cb2069-19"></a>                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(d<span class="op">$</span>w))) <span class="op">+</span></span>
<span id="cb2069-20"><a href="generalized-linear-madness.html#cb2069-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;height (scaled)&quot;</span>,</span>
<span id="cb2069-21"><a href="generalized-linear-madness.html#cb2069-21"></a>       <span class="dt">y =</span> <span class="st">&quot;weight (scaled)&quot;</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-11-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Overall the model did okay, but the poor fit for the cases with lower values of height and weight suggests we might be missing important differences between children and adults.</p>
</div>
<div id="glm-in-disguise." class="section level3">
<h3><span class="header-section-number">16.1.3</span> GLM in disguise.</h3>
<p>Recall that because <strong>brms</strong> does not support the log link for the Log-Normal likelihood, we recast our <code>b16.1</code> likelihood as</p>
<p><span class="math display">\[
\begin{align*}
\text{w}_i &amp; \sim \operatorname{Log-Normal}(\mu_i, \sigma) \\
\mu_i      &amp; = \log(k \pi p^2 \text{h}_i^3).
\end{align*}
\]</span></p>
<p>Because multiplication becomes addition on the log scale, we can also express this as</p>
<p><span class="math display">\[
\begin{align*}
\text{w}_i &amp; \sim \operatorname{Log-Normal}(\mu_i, \sigma) \\
\mu_i      &amp; = \log(k) + \log(\pi) + 2 \log(p) + 3 \log(\text{h}_i),
\end{align*}
\]</span></p>
<p>which means our fancy non-linear model is just linear regression on the log scale. McElreath pointed this out</p>
<blockquote>
<p>to highlight one of the reasons that generalized linear models are so powerful. Lots of natural relationships are GLM relationships, on a specific scale of measurement. At the same time, the GLM approach wants to simply estimate parameters which may be informed by a proper theory, as in this case. (p. 531)</p>
</blockquote>
</div>
</div>
<div id="hidden-minds-and-observed-behavior" class="section level2">
<h2><span class="header-section-number">16.2</span> Hidden minds and observed behavior</h2>
<p>Load the <code>Boxes</code> data <span class="citation">(van Leeuwen et al., <a href="#ref-vanleeuwenDevelopmentHumanSocial2018" role="doc-biblioref">2018</a>)</span>.</p>
<div class="sourceCode" id="cb2070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2070-1"><a href="generalized-linear-madness.html#cb2070-1"></a><span class="kw">data</span>(Boxes, <span class="dt">package =</span> <span class="st">&quot;rethinking&quot;</span>)</span>
<span id="cb2070-2"><a href="generalized-linear-madness.html#cb2070-2"></a>d &lt;-<span class="st"> </span>Boxes</span>
<span id="cb2070-3"><a href="generalized-linear-madness.html#cb2070-3"></a><span class="kw">rm</span>(Boxes)</span>
<span id="cb2070-4"><a href="generalized-linear-madness.html#cb2070-4"></a></span>
<span id="cb2070-5"><a href="generalized-linear-madness.html#cb2070-5"></a>rethinking<span class="op">::</span><span class="kw">precis</span>(d)</span></code></pre></div>
<pre><code>##                     mean        sd 5.5% 94.5%      histogram
## y              2.1208267 0.7279860    1     3     ▃▁▁▁▇▁▁▁▁▅
## gender         1.5055644 0.5003669    1     2     ▇▁▁▁▁▁▁▁▁▇
## age            8.0302067 2.4979055    5    13     ▇▃▅▃▃▃▂▂▂▁
## majority_first 0.4848967 0.5001696    0     1     ▇▁▁▁▁▁▁▁▁▇
## culture        3.7519873 1.9603189    1     8 ▃▂▁▇▁▂▁▂▁▂▁▁▁▁</code></pre>
<p>The data are from 629 children.</p>
<div class="sourceCode" id="cb2072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2072-1"><a href="generalized-linear-madness.html#cb2072-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>()</span></code></pre></div>
<pre><code>##     n
## 1 629</code></pre>
<p>Their ages ranged from 4 to 14 years and, as indicated by the histogram above, the bulk were on the younger end.</p>
<div class="sourceCode" id="cb2074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2074-1"><a href="generalized-linear-madness.html#cb2074-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2074-2"><a href="generalized-linear-madness.html#cb2074-2"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">min =</span> <span class="kw">min</span>(age),</span>
<span id="cb2074-3"><a href="generalized-linear-madness.html#cb2074-3"></a>            <span class="dt">max =</span> <span class="kw">max</span>(age))</span></code></pre></div>
<pre><code>##   min max
## 1   4  14</code></pre>
<p>Here’s a depiction of our criterion variable <code>y</code>.</p>
<div class="sourceCode" id="cb2076"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2076-1"><a href="generalized-linear-madness.html#cb2076-1"></a><span class="co"># wrangle</span></span>
<span id="cb2076-2"><a href="generalized-linear-madness.html#cb2076-2"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2076-3"><a href="generalized-linear-madness.html#cb2076-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">color =</span> <span class="kw">factor</span>(y,</span>
<span id="cb2076-4"><a href="generalized-linear-madness.html#cb2076-4"></a>                        <span class="dt">levels =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,</span>
<span id="cb2076-5"><a href="generalized-linear-madness.html#cb2076-5"></a>                        <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;unchosen&quot;</span>, <span class="st">&quot;majority&quot;</span>, <span class="st">&quot;minority&quot;</span>))) <span class="op">%&gt;%</span></span>
<span id="cb2076-6"><a href="generalized-linear-madness.html#cb2076-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">str_c</span>(y, <span class="st">&quot; (&quot;</span>, color, <span class="st">&quot;)&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2076-7"><a href="generalized-linear-madness.html#cb2076-7"></a><span class="st">  </span><span class="kw">count</span>(y) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2076-8"><a href="generalized-linear-madness.html#cb2076-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">percent =</span> (<span class="dv">100</span> <span class="op">*</span><span class="st"> </span>n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2076-9"><a href="generalized-linear-madness.html#cb2076-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">label =</span> <span class="kw">str_c</span>(<span class="kw">round</span>(percent, <span class="dt">digits =</span> <span class="dv">1</span>), <span class="st">&quot;%&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2076-10"><a href="generalized-linear-madness.html#cb2076-10"></a><span class="st">  </span></span>
<span id="cb2076-11"><a href="generalized-linear-madness.html#cb2076-11"></a><span class="st">  </span><span class="co"># plot</span></span>
<span id="cb2076-12"><a href="generalized-linear-madness.html#cb2076-12"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb2076-13"><a href="generalized-linear-madness.html#cb2076-13"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n)) <span class="op">+</span></span>
<span id="cb2076-14"><a href="generalized-linear-madness.html#cb2076-14"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n <span class="op">+</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">label =</span> label),</span>
<span id="cb2076-15"><a href="generalized-linear-madness.html#cb2076-15"></a>            <span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>) <span class="op">+</span></span>
<span id="cb2076-16"><a href="generalized-linear-madness.html#cb2076-16"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(n)), <span class="dt">expand =</span> <span class="kw">expansion</span>(<span class="dt">mult =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.1</span>))) <span class="op">+</span></span>
<span id="cb2076-17"><a href="generalized-linear-madness.html#cb2076-17"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;The criterion variable y indexes three kinds of color choices&quot;</span>,</span>
<span id="cb2076-18"><a href="generalized-linear-madness.html#cb2076-18"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Children tended to prefer the &#39;majority&#39; color.&quot;</span>,</span>
<span id="cb2076-19"><a href="generalized-linear-madness.html#cb2076-19"></a>       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2076-20"><a href="generalized-linear-madness.html#cb2076-20"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>),</span>
<span id="cb2076-21"><a href="generalized-linear-madness.html#cb2076-21"></a>        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-15-1.png" width="600" style="display: block; margin: auto;" /></p>
<div id="the-scientific-model.-1" class="section level3">
<h3><span class="header-section-number">16.2.1</span> The scientific model.</h3>
<blockquote>
<p>The key, as always, is to think generatively. Consider for example a group of children in which half of them choose at random and the other half follow the majority. If we simulate choices for these children, we can figure out how often we might see the “2” choice, the one that indicates the majority color. (p. 532)</p>
</blockquote>
<p>Here’s an alternative way to set up McEreath’s <strong>R</strong> code 16.6.</p>
<div class="sourceCode" id="cb2077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2077-1"><a href="generalized-linear-madness.html#cb2077-1"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2077-2"><a href="generalized-linear-madness.html#cb2077-2"></a></span>
<span id="cb2077-3"><a href="generalized-linear-madness.html#cb2077-3"></a>n &lt;-<span class="st"> </span><span class="dv">30</span> <span class="co"># number of children</span></span>
<span id="cb2077-4"><a href="generalized-linear-madness.html#cb2077-4"></a></span>
<span id="cb2077-5"><a href="generalized-linear-madness.html#cb2077-5"></a><span class="kw">tibble</span>(<span class="dt">name  =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;y1&quot;</span>, <span class="st">&quot;y2&quot;</span>), <span class="dt">each =</span> n <span class="op">/</span><span class="st"> </span><span class="dv">2</span>),</span>
<span id="cb2077-6"><a href="generalized-linear-madness.html#cb2077-6"></a>       <span class="dt">value =</span> <span class="kw">c</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> n <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">replace =</span> T),</span>
<span id="cb2077-7"><a href="generalized-linear-madness.html#cb2077-7"></a>                 <span class="kw">rep</span>(<span class="dv">2</span>, n <span class="op">/</span><span class="st"> </span><span class="dv">2</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2077-8"><a href="generalized-linear-madness.html#cb2077-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">sample</span>(value)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2077-9"><a href="generalized-linear-madness.html#cb2077-9"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="st">`</span><span class="dt">number of 2s</span><span class="st">`</span> =<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>n)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   `number of 2s`
##            &lt;dbl&gt;
## 1          0.633</code></pre>
<blockquote>
<p>We’ll consider 5 different strategies children might use.</p>
<ol style="list-style-type: decimal">
<li>Follow the Majority: Copy the majority demonstrated color.</li>
<li>Follow the Minority: Copy the minority demonstrated color.</li>
<li>Maverick: Choose the color that no demonstrator chose.</li>
<li>Random: Choose a color at random, ignoring the demonstrators.</li>
<li>Follow First: Copy the color that was demonstrated first. This was either the majority color (when <code>majority_first</code> equals 1) or the minority color (when 0). (p. 533)</li>
</ol>
</blockquote>
</div>
<div id="the-statistical-model.-1" class="section level3">
<h3><span class="header-section-number">16.2.2</span> The statistical model.</h3>
<p>Our statistical will follow the form</p>
<p><span class="math display">\[
\begin{align*}
y_i &amp; \sim \operatorname{Categorical}(\theta) \\
\theta_j &amp; = \sum_{s = 1}^5 p_s \operatorname{Pr}(j | s) \;\;\; \text{for} \; j = 1, \dots, 3 \\
p &amp; \sim \operatorname{Dirichlet}(4, 4, 4, 4, 4),
\end{align*}
\]</span></p>
<p>where <span class="math inline">\(s\)</span> indexes one of our five latent strategies and <span class="math inline">\(\operatorname{Pr}(j | s)\)</span> is the probability of one of the three color choices given a child is using the <span class="math inline">\(s\)</span>th strategy. The <span class="math inline">\(\sum_{s = 1}^5 p_s\)</span> portion conveys these five probabilities are treated as a simplex, which means they will sum to one. We give these probabilities a Dirichlet prior, which we learned about back in <a href="monsters-and-mixtures.html#ordered-categorical-predictors">Section 12.4</a>. Here’s what that prior looks like.</p>
<div class="sourceCode" id="cb2079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2079-1"><a href="generalized-linear-madness.html#cb2079-1"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2079-2"><a href="generalized-linear-madness.html#cb2079-2"></a></span>
<span id="cb2079-3"><a href="generalized-linear-madness.html#cb2079-3"></a><span class="kw">rdirichlet</span>(<span class="dt">n =</span> <span class="fl">1e5</span>, <span class="dt">alpha =</span> <span class="kw">rep</span>(<span class="dv">4</span>, <span class="dt">times =</span> <span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2079-4"><a href="generalized-linear-madness.html#cb2079-4"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2079-5"><a href="generalized-linear-madness.html#cb2079-5"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2079-6"><a href="generalized-linear-madness.html#cb2079-6"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2079-7"><a href="generalized-linear-madness.html#cb2079-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name  =</span> name <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.double</span>(),</span>
<span id="cb2079-8"><a href="generalized-linear-madness.html#cb2079-8"></a>         <span class="dt">alpha =</span> <span class="kw">str_c</span>(<span class="st">&quot;alpha[&quot;</span>, name, <span class="st">&quot;]&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2079-9"><a href="generalized-linear-madness.html#cb2079-9"></a><span class="st">  </span></span>
<span id="cb2079-10"><a href="generalized-linear-madness.html#cb2079-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">group =</span> name)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb2079-11"><a href="generalized-linear-madness.html#cb2079-11"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">.02</span>, <span class="dt">boundary =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb2079-12"><a href="generalized-linear-madness.html#cb2079-12"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(p[s])), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2079-13"><a href="generalized-linear-madness.html#cb2079-13"></a>                     <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">.2</span>, <span class="fl">.5</span>, <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;0&quot;</span>, <span class="st">&quot;.2&quot;</span>, <span class="st">&quot;.5&quot;</span>, <span class="st">&quot;1&quot;</span>), ) <span class="op">+</span></span>
<span id="cb2079-14"><a href="generalized-linear-madness.html#cb2079-14"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2079-15"><a href="generalized-linear-madness.html#cb2079-15"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;Dirichlet&quot;</span><span class="op">*</span>(<span class="dv">4</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="dv">4</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="dv">4</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="dv">4</span><span class="op">*</span><span class="st">&quot;, &quot;</span><span class="op">*</span><span class="dv">4</span>))) <span class="op">+</span></span>
<span id="cb2079-16"><a href="generalized-linear-madness.html#cb2079-16"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>alpha, <span class="dt">labeller =</span> label_parsed, <span class="dt">nrow =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-17-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="coding-the-statistical-model." class="section level3">
<h3><span class="header-section-number">16.2.3</span> Coding the statistical model.</h3>
<p>Let’s take a look at McElreath’s Stan code.</p>
<div class="sourceCode" id="cb2080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2080-1"><a href="generalized-linear-madness.html#cb2080-1"></a><span class="kw">library</span>(rethinking)</span>
<span id="cb2080-2"><a href="generalized-linear-madness.html#cb2080-2"></a><span class="kw">data</span>(Boxes_model) </span>
<span id="cb2080-3"><a href="generalized-linear-madness.html#cb2080-3"></a><span class="kw">cat</span>(Boxes_model)</span></code></pre></div>
<pre><code>## 
## data{
##     int N;
##     int y[N];
##     int majority_first[N];
## }
## parameters{
##     simplex[5] p;
## }
## model{
##     vector[5] phi;
##     
##     // prior
##     p ~ dirichlet( rep_vector(4,5) );
##     
##     // probability of data
##     for ( i in 1:N ) {
##         if ( y[i]==2 ) phi[1]=1; else phi[1]=0; // majority
##         if ( y[i]==3 ) phi[2]=1; else phi[2]=0; // minority
##         if ( y[i]==1 ) phi[3]=1; else phi[3]=0; // maverick
##         phi[4]=1.0/3.0;                         // random
##         if ( majority_first[i]==1 )             // follow first
##             if ( y[i]==2 ) phi[5]=1; else phi[5]=0;
##         else
##             if ( y[i]==3 ) phi[5]=1; else phi[5]=0;
##         
##         // compute log( p_s * Pr(y_i|s )
##         for ( j in 1:5 ) phi[j] = log(p[j]) + log(phi[j]);
##         // compute average log-probability of y_i
##         target += log_sum_exp( phi );
##     }
## }</code></pre>
<p>I’m not aware that one can fit this model directly with <strong>brms</strong>. My guess is that if it’s possible, it would require a custom likelihood <span class="citation">(see Bürkner, <a href="#ref-Bürkner2020Define" role="doc-biblioref">2020</a><a href="#ref-Bürkner2020Define" role="doc-biblioref">e</a>)</span>. If you can reproduce McElreath’s Stan code with this or some other approach in <strong>brms</strong>, please <a href="https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse_2_ed/issues">share your code on GitHub</a>. In the mean time, we’re going to follow along with the text and fit the model with <code>rstan::stan()</code>.</p>
<div class="sourceCode" id="cb2082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2082-1"><a href="generalized-linear-madness.html#cb2082-1"></a><span class="co"># prep data </span></span>
<span id="cb2082-2"><a href="generalized-linear-madness.html#cb2082-2"></a>dat_list &lt;-<span class="st"> </span><span class="kw">list</span>(</span>
<span id="cb2082-3"><a href="generalized-linear-madness.html#cb2082-3"></a>  <span class="dt">N =</span> <span class="kw">nrow</span>(d),</span>
<span id="cb2082-4"><a href="generalized-linear-madness.html#cb2082-4"></a>  <span class="dt">y =</span> d<span class="op">$</span>y,</span>
<span id="cb2082-5"><a href="generalized-linear-madness.html#cb2082-5"></a>  <span class="dt">majority_first =</span> d<span class="op">$</span>majority_first )</span>
<span id="cb2082-6"><a href="generalized-linear-madness.html#cb2082-6"></a></span>
<span id="cb2082-7"><a href="generalized-linear-madness.html#cb2082-7"></a><span class="co"># run the sampler</span></span>
<span id="cb2082-8"><a href="generalized-linear-madness.html#cb2082-8"></a>m16<span class="fl">.2</span> &lt;-</span>
<span id="cb2082-9"><a href="generalized-linear-madness.html#cb2082-9"></a><span class="st">  </span><span class="kw">stan</span>(<span class="dt">model_code =</span> Boxes_model, </span>
<span id="cb2082-10"><a href="generalized-linear-madness.html#cb2082-10"></a>       <span class="dt">data =</span> dat_list, </span>
<span id="cb2082-11"><a href="generalized-linear-madness.html#cb2082-11"></a>       <span class="dt">chains =</span> <span class="dv">3</span>, <span class="dt">cores =</span> <span class="dv">3</span>,</span>
<span id="cb2082-12"><a href="generalized-linear-madness.html#cb2082-12"></a>       <span class="dt">seed =</span> <span class="dv">16</span>)</span></code></pre></div>
<p>Here’s what it looks like if you <code>print()</code> a fit object from the <code>stan()</code> function.</p>
<div class="sourceCode" id="cb2083"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2083-1"><a href="generalized-linear-madness.html#cb2083-1"></a><span class="kw">print</span>(m16<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Inference for Stan model: 27b25f2c261c65f6230541a266cbbdbd.
## 3 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=3000.
## 
##         mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
## p[1]    0.26    0.00 0.04    0.19    0.23    0.26    0.28    0.32   986 1.00
## p[2]    0.14    0.00 0.03    0.07    0.12    0.14    0.16    0.20  1087 1.01
## p[3]    0.15    0.00 0.03    0.09    0.13    0.15    0.17    0.20  1066 1.01
## p[4]    0.20    0.00 0.08    0.07    0.14    0.19    0.25    0.37   792 1.01
## p[5]    0.26    0.00 0.03    0.20    0.24    0.26    0.28    0.32  2559 1.00
## lp__ -667.17    0.04 1.44 -670.69 -667.91 -666.81 -666.12 -665.32  1203 1.00
## 
## Samples were drawn using NUTS(diag_e) at Sat Nov  7 14:32:59 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>Here’s the summary with <code>rethinking::precis()</code>.</p>
<div class="sourceCode" id="cb2085"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2085-1"><a href="generalized-linear-madness.html#cb2085-1"></a><span class="kw">precis</span>(m16<span class="fl">.2</span>, <span class="dt">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##           mean         sd       5.5%     94.5%     n_eff     Rhat4
## p[1] 0.2576792 0.03642940 0.19925939 0.3143086  985.7502 1.0042274
## p[2] 0.1390785 0.03299730 0.08584531 0.1916790 1086.6851 1.0056198
## p[3] 0.1479720 0.03021546 0.09678031 0.1942334 1066.2915 1.0066600
## p[4] 0.1961164 0.07966720 0.08178310 0.3356874  791.8116 1.0078264
## p[5] 0.2591538 0.03212438 0.20681421 0.3103560 2559.2139 0.9991496</code></pre>
<p>Here we show marginal posterior for <span class="math inline">\(p_s\)</span>.</p>
<div class="sourceCode" id="cb2087"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2087-1"><a href="generalized-linear-madness.html#cb2087-1"></a>label &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Majority~(italic(s)[1])&quot;</span>, </span>
<span id="cb2087-2"><a href="generalized-linear-madness.html#cb2087-2"></a>           <span class="st">&quot;Minority~(italic(s)[2])&quot;</span>,</span>
<span id="cb2087-3"><a href="generalized-linear-madness.html#cb2087-3"></a>           <span class="st">&quot;Maverick~(italic(s)[3])&quot;</span>, </span>
<span id="cb2087-4"><a href="generalized-linear-madness.html#cb2087-4"></a>           <span class="st">&quot;Random~(italic(s)[4])&quot;</span>, </span>
<span id="cb2087-5"><a href="generalized-linear-madness.html#cb2087-5"></a>           <span class="st">&quot;Follow~First~(italic(s)[5])&quot;</span>)</span>
<span id="cb2087-6"><a href="generalized-linear-madness.html#cb2087-6"></a></span>
<span id="cb2087-7"><a href="generalized-linear-madness.html#cb2087-7"></a><span class="kw">precis</span>(m16<span class="fl">.2</span>, <span class="dt">depth =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2087-8"><a href="generalized-linear-madness.html#cb2087-8"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2087-9"><a href="generalized-linear-madness.html#cb2087-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name =</span> <span class="kw">factor</span>(label, <span class="dt">levels =</span> label)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2087-10"><a href="generalized-linear-madness.html#cb2087-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name =</span> <span class="kw">fct_rev</span>(name)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2087-11"><a href="generalized-linear-madness.html#cb2087-11"></a><span class="st">  </span></span>
<span id="cb2087-12"><a href="generalized-linear-madness.html#cb2087-12"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mean, <span class="dt">xmin =</span> X5.<span class="fl">5.</span>, <span class="dt">xmax =</span> X94.<span class="fl">5.</span>, <span class="dt">y =</span> name)) <span class="op">+</span></span>
<span id="cb2087-13"><a href="generalized-linear-madness.html#cb2087-13"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">.2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2087-14"><a href="generalized-linear-madness.html#cb2087-14"></a><span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">fatten =</span> <span class="dv">6</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb2087-15"><a href="generalized-linear-madness.html#cb2087-15"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(p[s])), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2087-16"><a href="generalized-linear-madness.html#cb2087-16"></a>                     <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">5</span> <span class="op">/</span><span class="st"> </span><span class="dv">5</span>) <span class="op">+</span></span>
<span id="cb2087-17"><a href="generalized-linear-madness.html#cb2087-17"></a><span class="st">  </span><span class="kw">scale_y_discrete</span>(<span class="ot">NULL</span>, <span class="dt">labels =</span> ggplot2<span class="op">:::</span>parse_safe) <span class="op">+</span></span>
<span id="cb2087-18"><a href="generalized-linear-madness.html#cb2087-18"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-23-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>As an alternative, this might be a good time to revisit the <code>tidybayes::stat_ccdfinterval()</code> approach (see <a href="monsters-and-mixtures.html#adding-predictor-variables.">Section 12.3.3</a>), which will depict those posteriors with a bar plot where the ends of the bars depict our uncertainty in terms of cumulative density curves.</p>
<div class="sourceCode" id="cb2088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2088-1"><a href="generalized-linear-madness.html#cb2088-1"></a><span class="kw">extract.samples</span>(m16<span class="fl">.2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-2"><a href="generalized-linear-madness.html#cb2088-2"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-3"><a href="generalized-linear-madness.html#cb2088-3"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>lp__) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-4"><a href="generalized-linear-madness.html#cb2088-4"></a><span class="st">  </span><span class="kw">set_names</span>(label) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-5"><a href="generalized-linear-madness.html#cb2088-5"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-6"><a href="generalized-linear-madness.html#cb2088-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name =</span> <span class="kw">factor</span>(name, <span class="dt">levels =</span> label)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-7"><a href="generalized-linear-madness.html#cb2088-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name =</span> <span class="kw">fct_rev</span>(name)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2088-8"><a href="generalized-linear-madness.html#cb2088-8"></a><span class="st">  </span></span>
<span id="cb2088-9"><a href="generalized-linear-madness.html#cb2088-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">y =</span> name)) <span class="op">+</span></span>
<span id="cb2088-10"><a href="generalized-linear-madness.html#cb2088-10"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">.2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2088-11"><a href="generalized-linear-madness.html#cb2088-11"></a><span class="st">  </span><span class="kw">stat_ccdfinterval</span>(<span class="dt">.width =</span> <span class="fl">.95</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="fl">.8</span>) <span class="op">+</span></span>
<span id="cb2088-12"><a href="generalized-linear-madness.html#cb2088-12"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(p[s])), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2088-13"><a href="generalized-linear-madness.html#cb2088-13"></a>                     <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">5</span> <span class="op">/</span><span class="st"> </span><span class="dv">5</span>) <span class="op">+</span></span>
<span id="cb2088-14"><a href="generalized-linear-madness.html#cb2088-14"></a><span class="st">  </span><span class="kw">scale_y_discrete</span>(<span class="ot">NULL</span>, <span class="dt">labels =</span> ggplot2<span class="op">:::</span>parse_safe) <span class="op">+</span></span>
<span id="cb2088-15"><a href="generalized-linear-madness.html#cb2088-15"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>),</span>
<span id="cb2088-16"><a href="generalized-linear-madness.html#cb2088-16"></a>        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-24-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="state-space-models." class="section level3">
<h3><span class="header-section-number">16.2.4</span> State space models.</h3>
<p>In this section of the text, McElreath mentioned state space models and hidden Markov models. Based on <a href="https://discourse.mc-stan.org/t/state-space-models-with-brms/4087">this thread</a> in the Stan forums and <a href="https://github.com/paul-buerkner/brms/issues/173">this issue</a> in the <strong>brms</strong> GitHub repo, it looks like state space models are not supported in <strong>brms</strong> at this time. As for hidden Markov models, I’m not sure whether they are supported by <strong>brms</strong>. The best I could find was <a href="https://discourse.mc-stan.org/t/modelling-with-non-binary-proportions-as-outcome/12324">this thread</a> on the Stan forums. If you know more about either of these topics, please share your knowledge <a href="https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse_2_ed/issues">on this book’s GitHub repo</a>.</p>
</div>
</div>
<div id="ordinary-differential-nut-cracking" class="section level2">
<h2><span class="header-section-number">16.3</span> Ordinary differential nut cracking</h2>
<p>Load the <code>Panda_nuts</code> data <span class="citation">(Boesch et al., <a href="#ref-boeschLearningCurvesTeaching2019" role="doc-biblioref">2019</a>)</span>.</p>
<div class="sourceCode" id="cb2089"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2089-1"><a href="generalized-linear-madness.html#cb2089-1"></a><span class="kw">data</span>(Panda_nuts, <span class="dt">package =</span> <span class="st">&quot;rethinking&quot;</span>)</span>
<span id="cb2089-2"><a href="generalized-linear-madness.html#cb2089-2"></a>d &lt;-<span class="st"> </span>Panda_nuts</span>
<span id="cb2089-3"><a href="generalized-linear-madness.html#cb2089-3"></a><span class="kw">rm</span>(Panda_nuts)</span></code></pre></div>
<p>Anticipating McElreath’s <strong>R</strong> code 16.11, we’ll wrangle a little.</p>
<div class="sourceCode" id="cb2090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2090-1"><a href="generalized-linear-madness.html#cb2090-1"></a>d &lt;-</span>
<span id="cb2090-2"><a href="generalized-linear-madness.html#cb2090-2"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2090-3"><a href="generalized-linear-madness.html#cb2090-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n     =</span> nuts_opened,</span>
<span id="cb2090-4"><a href="generalized-linear-madness.html#cb2090-4"></a>         <span class="dt">age_s =</span> age <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(age))</span>
<span id="cb2090-5"><a href="generalized-linear-madness.html#cb2090-5"></a></span>
<span id="cb2090-6"><a href="generalized-linear-madness.html#cb2090-6"></a><span class="kw">glimpse</span>(d)</span></code></pre></div>
<pre><code>## Rows: 84
## Columns: 9
## $ chimpanzee  &lt;int&gt; 11, 11, 18, 18, 18, 11, 11, 17, 7, 1, 22, 9, 9, 9, 9, 9, 9, 9, 9, 9, 15, 7, 9, 1, 7, 13…
## $ age         &lt;int&gt; 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, …
## $ sex         &lt;fct&gt; m, m, f, f, f, m, m, f, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, m, …
## $ hammer      &lt;fct&gt; G, G, wood, G, L, Q, Q, wood, G, L, wood, G, G, G, G, G, G, G, G, G, G, G, G, L, G, woo…
## $ nuts_opened &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 58, 4, 21, 9, 2, 30, 19, 13, 6, 11, 1, 2, 0, 1, 0, 0, …
## $ seconds     &lt;dbl&gt; 61.0, 37.0, 20.0, 14.0, 13.0, 24.0, 30.5, 135.0, 24.0, 13.0, 34.0, 66.5, 5.0, 24.0, 20.…
## $ help        &lt;fct&gt; N, N, N, y, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, y, N, N, N, N, N, y, y, …
## $ n           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 58, 4, 21, 9, 2, 30, 19, 13, 6, 11, 1, 2, 0, 1, 0, 0, …
## $ age_s       &lt;dbl&gt; 0.1875, 0.1875, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.3125, 0.3125, 0.3125, 0.3125,…</code></pre>
<p>Our criterion is <code>n</code>, the number of <em>Panda</em> nuts opened by a chimpanzee on a given occasion. The two focal predictor variables are <code>age</code> and <code>seconds</code>. Here they are depicted in a pairs plot.</p>
<div class="sourceCode" id="cb2092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2092-1"><a href="generalized-linear-madness.html#cb2092-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2092-2"><a href="generalized-linear-madness.html#cb2092-2"></a><span class="st">  </span><span class="kw">select</span>(n, age, seconds) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2092-3"><a href="generalized-linear-madness.html#cb2092-3"></a><span class="st">  </span><span class="kw">ggpairs</span>(<span class="dt">upper =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> my_upper),</span>
<span id="cb2092-4"><a href="generalized-linear-madness.html#cb2092-4"></a>          <span class="dt">diag =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> my_diag),</span>
<span id="cb2092-5"><a href="generalized-linear-madness.html#cb2092-5"></a>          <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> my_lower)) <span class="op">+</span></span>
<span id="cb2092-6"><a href="generalized-linear-madness.html#cb2092-6"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.text.y =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">angle =</span> <span class="dv">0</span>))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-27-1.png" width="432" style="display: block; margin: auto;" /></p>
<div id="scientific-model." class="section level3">
<h3><span class="header-section-number">16.3.1</span> Scientific model.</h3>
<p>As a starting point, McElreath proposed we the strength of a chimpanzee would relate to the number of nuts they might open. We don’t have a measure of strength, but we do have <code>age</code>, which is a proxy for how close a chimp might be to their maximum body size, and we presume body size would be proportional to strength. If we let <span class="math inline">\(t\)</span> index time, <span class="math inline">\(M_\text{max}\)</span> be the maximum body size (mass), <span class="math inline">\(M_t\)</span> be the current body size, and <span class="math inline">\(k\)</span> stand for the rate of skill gain the comes with age, we can write</p>
<p><span class="math display">\[M_t = M_\text{max} [1 - \exp(-kt) ]\]</span></p>
<p>to solve for mass at a given age <span class="citation">(von Bertalanffy, <a href="#ref-vonbertalanffyUntersuchungenUeberGesetzlichkeit1934" role="doc-biblioref">1934</a>)</span>. But again, we actually care about strength, not mass. Letting <span class="math inline">\(S_t\)</span> be strength at time <span class="math inline">\(t\)</span>, we can express a proportional relation between the two as <span class="math inline">\(S_t = \beta M_t\)</span>. Now if we let <span class="math inline">\(\lambda\)</span> stand in for the number of nuts opening, <span class="math inline">\(\alpha\)</span> express the relation of strength to nut opening, we can write</p>
<p><span class="math display">\[\lambda = \alpha S_t^\theta = \alpha \big ( \beta M_\text{max} [1 - \exp(-kt) ]  \big ) ^\theta,\]</span></p>
<p>“where <span class="math inline">\(\theta\)</span> is some exponent greater than 1” (p. 538). If we rescale <span class="math inline">\(M_\text{max} = 1\)</span>, we can simplify the equation to</p>
<p><span class="math display">\[\lambda = \alpha \beta^\theta [1 - \exp(-kt) ]^\theta.\]</span></p>
<p>As “the product <span class="math inline">\(\alpha \beta^\theta\)</span> in the front just rescales strength to nuts-opened-per-second” (p. 538), we can colapse it to a single parameter, <span class="math inline">\(\phi\)</span>, which leaves us with</p>
<p><span class="math display">\[\lambda = \phi [1 - \exp(-kt) ]^\theta.\]</span></p>
<p>This is our scientific model.</p>
</div>
<div id="statistical-model." class="section level3">
<h3><span class="header-section-number">16.3.2</span> Statistical model.</h3>
<p>Now if we let <span class="math inline">\(n_i\)</span> be the number of nuts opened, we can write our statistical model as</p>
<p><span class="math display">\[
\begin{align*}
n_i &amp; \sim \operatorname{Poisson}(\lambda_i) \\
\lambda_i &amp; = \text{seconds}_i \, \phi [1 - \exp(-k \,\text{age}_i) ]^\theta,
\end{align*}
\]</span></p>
<p>where we have replaced our time index, <span class="math inline">\(t\)</span>, with the variable <code>age</code>. By including the variable <code>seconds</code> in the equation, we have scaled the results to be nuts per second. McElreath proposed the priors:</p>
<p><span class="math display">\[
\begin{align*}
\phi   &amp; \sim \operatorname{Log-Normal}(\log 1, 0.10) \\
k      &amp; \sim \operatorname{Log-Normal}(\log 2, 0.25) \\
\theta &amp; \sim \operatorname{Log-Normal}(\log 5, 0.25),
\end{align*}
\]</span></p>
<p>all of which were Log-Normal to ensure the parameters were positive and continuous. To get a sense of what these priors implied, he simulated. Here’s our version of his simulations, which make up Figure 16.4.</p>
<div class="sourceCode" id="cb2093"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2093-1"><a href="generalized-linear-madness.html#cb2093-1"></a>n &lt;-<span class="st"> </span><span class="fl">1e4</span></span>
<span id="cb2093-2"><a href="generalized-linear-madness.html#cb2093-2"></a></span>
<span id="cb2093-3"><a href="generalized-linear-madness.html#cb2093-3"></a><span class="co"># define the x-axis breaks</span></span>
<span id="cb2093-4"><a href="generalized-linear-madness.html#cb2093-4"></a>at &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">6</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span></span>
<span id="cb2093-5"><a href="generalized-linear-madness.html#cb2093-5"></a></span>
<span id="cb2093-6"><a href="generalized-linear-madness.html#cb2093-6"></a><span class="co"># how many prior draws would you like?</span></span>
<span id="cb2093-7"><a href="generalized-linear-madness.html#cb2093-7"></a>sample_n &lt;-<span class="st"> </span><span class="dv">50</span></span>
<span id="cb2093-8"><a href="generalized-linear-madness.html#cb2093-8"></a></span>
<span id="cb2093-9"><a href="generalized-linear-madness.html#cb2093-9"></a><span class="co"># simulate</span></span>
<span id="cb2093-10"><a href="generalized-linear-madness.html#cb2093-10"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2093-11"><a href="generalized-linear-madness.html#cb2093-11"></a></span>
<span id="cb2093-12"><a href="generalized-linear-madness.html#cb2093-12"></a>prior &lt;-</span>
<span id="cb2093-13"><a href="generalized-linear-madness.html#cb2093-13"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">index =</span> <span class="dv">1</span><span class="op">:</span>n,</span>
<span id="cb2093-14"><a href="generalized-linear-madness.html#cb2093-14"></a>         <span class="dt">phi   =</span> <span class="kw">rlnorm</span>(n, <span class="dt">meanlog =</span> <span class="kw">log</span>(<span class="dv">1</span>), <span class="dt">sdlog =</span> <span class="fl">0.1</span>),</span>
<span id="cb2093-15"><a href="generalized-linear-madness.html#cb2093-15"></a>         <span class="dt">k     =</span> <span class="kw">rlnorm</span>(n, <span class="dt">meanlog =</span> <span class="kw">log</span>(<span class="dv">2</span>), <span class="dt">sdlog =</span> <span class="fl">0.25</span>),</span>
<span id="cb2093-16"><a href="generalized-linear-madness.html#cb2093-16"></a>         <span class="dt">theta =</span> <span class="kw">rlnorm</span>(n, <span class="dt">meanlog =</span> <span class="kw">log</span>(<span class="dv">5</span>), <span class="dt">sdlog =</span> <span class="fl">0.25</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2093-17"><a href="generalized-linear-madness.html#cb2093-17"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> sample_n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2093-18"><a href="generalized-linear-madness.html#cb2093-18"></a><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(index, phi, k, theta),</span>
<span id="cb2093-19"><a href="generalized-linear-madness.html#cb2093-19"></a>         <span class="dt">age =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="fl">1.5</span>, <span class="dt">length.out =</span> <span class="fl">1e2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2093-20"><a href="generalized-linear-madness.html#cb2093-20"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">bm =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>k <span class="op">*</span><span class="st"> </span>age),</span>
<span id="cb2093-21"><a href="generalized-linear-madness.html#cb2093-21"></a>         <span class="dt">ns =</span> phi <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>k <span class="op">*</span><span class="st"> </span>age))<span class="op">^</span>theta) </span>
<span id="cb2093-22"><a href="generalized-linear-madness.html#cb2093-22"></a></span>
<span id="cb2093-23"><a href="generalized-linear-madness.html#cb2093-23"></a><span class="co"># left panel</span></span>
<span id="cb2093-24"><a href="generalized-linear-madness.html#cb2093-24"></a>p1 &lt;-</span>
<span id="cb2093-25"><a href="generalized-linear-madness.html#cb2093-25"></a><span class="st">  </span>prior <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2093-26"><a href="generalized-linear-madness.html#cb2093-26"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> bm, <span class="dt">group =</span> index)) <span class="op">+</span></span>
<span id="cb2093-27"><a href="generalized-linear-madness.html#cb2093-27"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2093-28"><a href="generalized-linear-madness.html#cb2093-28"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> at, <span class="dt">labels =</span> <span class="kw">round</span>(at <span class="op">*</span><span class="st"> </span><span class="kw">max</span>(d<span class="op">$</span>age))) <span class="op">+</span></span>
<span id="cb2093-29"><a href="generalized-linear-madness.html#cb2093-29"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;body mass&quot;</span>)</span>
<span id="cb2093-30"><a href="generalized-linear-madness.html#cb2093-30"></a></span>
<span id="cb2093-31"><a href="generalized-linear-madness.html#cb2093-31"></a><span class="co"># right panel</span></span>
<span id="cb2093-32"><a href="generalized-linear-madness.html#cb2093-32"></a>p2 &lt;-</span>
<span id="cb2093-33"><a href="generalized-linear-madness.html#cb2093-33"></a><span class="st">  </span>prior <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2093-34"><a href="generalized-linear-madness.html#cb2093-34"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> ns, <span class="dt">group =</span> index)) <span class="op">+</span></span>
<span id="cb2093-35"><a href="generalized-linear-madness.html#cb2093-35"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2093-36"><a href="generalized-linear-madness.html#cb2093-36"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> at, <span class="dt">labels =</span> <span class="kw">round</span>(at <span class="op">*</span><span class="st"> </span><span class="kw">max</span>(d<span class="op">$</span>age))) <span class="op">+</span></span>
<span id="cb2093-37"><a href="generalized-linear-madness.html#cb2093-37"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;nuts per second&quot;</span>)</span>
<span id="cb2093-38"><a href="generalized-linear-madness.html#cb2093-38"></a></span>
<span id="cb2093-39"><a href="generalized-linear-madness.html#cb2093-39"></a><span class="co"># combine and plot</span></span>
<span id="cb2093-40"><a href="generalized-linear-madness.html#cb2093-40"></a><span class="kw">library</span>(patchwork)</span>
<span id="cb2093-41"><a href="generalized-linear-madness.html#cb2093-41"></a></span>
<span id="cb2093-42"><a href="generalized-linear-madness.html#cb2093-42"></a>p1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span></span>
<span id="cb2093-43"><a href="generalized-linear-madness.html#cb2093-43"></a><span class="st">  </span><span class="kw">plot_annotation</span>(<span class="dt">title =</span> <span class="st">&quot;Prior predictive simulation for the nut opening model&quot;</span>,</span>
<span id="cb2093-44"><a href="generalized-linear-madness.html#cb2093-44"></a>                  <span class="dt">subtitle =</span> <span class="st">&quot;Each panel shows the results from 50 prior draws.&quot;</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-28-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>McElreath suggested we inspect the distributions of these priors. Here they are in a series of histograms.</p>
<div class="sourceCode" id="cb2094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2094-1"><a href="generalized-linear-madness.html#cb2094-1"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2094-2"><a href="generalized-linear-madness.html#cb2094-2"></a></span>
<span id="cb2094-3"><a href="generalized-linear-madness.html#cb2094-3"></a><span class="kw">tibble</span>(<span class="dt">phi         =</span> <span class="kw">rlnorm</span>(n, <span class="dt">meanlog =</span> <span class="kw">log</span>(<span class="dv">1</span>), <span class="dt">sdlog =</span> <span class="fl">0.1</span>),</span>
<span id="cb2094-4"><a href="generalized-linear-madness.html#cb2094-4"></a>       <span class="st">`</span><span class="dt">italic(k)</span><span class="st">`</span> =<span class="st"> </span><span class="kw">rlnorm</span>(n, <span class="dt">meanlog =</span> <span class="kw">log</span>(<span class="dv">2</span>), <span class="dt">sdlog =</span> <span class="fl">0.25</span>),</span>
<span id="cb2094-5"><a href="generalized-linear-madness.html#cb2094-5"></a>       <span class="dt">theta       =</span> <span class="kw">rlnorm</span>(n, <span class="dt">meanlog =</span> <span class="kw">log</span>(<span class="dv">5</span>), <span class="dt">sdlog =</span> <span class="fl">0.25</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2094-6"><a href="generalized-linear-madness.html#cb2094-6"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2094-7"><a href="generalized-linear-madness.html#cb2094-7"></a><span class="st">  </span></span>
<span id="cb2094-8"><a href="generalized-linear-madness.html#cb2094-8"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></span>
<span id="cb2094-9"><a href="generalized-linear-madness.html#cb2094-9"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">bins =</span> <span class="dv">40</span>, <span class="dt">boundary =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb2094-10"><a href="generalized-linear-madness.html#cb2094-10"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2094-11"><a href="generalized-linear-madness.html#cb2094-11"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;marginal prior&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">NA</span>)) <span class="op">+</span></span>
<span id="cb2094-12"><a href="generalized-linear-madness.html#cb2094-12"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>name, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-29-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Happily, we can fit this model using the non-linear <strong>brms</strong> syntax.</p>
<div class="sourceCode" id="cb2095"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2095-1"><a href="generalized-linear-madness.html#cb2095-1"></a>b16<span class="fl">.4</span> &lt;-<span class="st"> </span></span>
<span id="cb2095-2"><a href="generalized-linear-madness.html#cb2095-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</span>
<span id="cb2095-3"><a href="generalized-linear-madness.html#cb2095-3"></a>      <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> identity),</span>
<span id="cb2095-4"><a href="generalized-linear-madness.html#cb2095-4"></a>      <span class="kw">bf</span>(n <span class="op">~</span><span class="st"> </span>seconds <span class="op">*</span><span class="st"> </span>phi <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>k <span class="op">*</span><span class="st"> </span>age_s))<span class="op">^</span>theta,</span>
<span id="cb2095-5"><a href="generalized-linear-madness.html#cb2095-5"></a>         phi <span class="op">+</span><span class="st"> </span>k <span class="op">+</span><span class="st"> </span>theta <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb2095-6"><a href="generalized-linear-madness.html#cb2095-6"></a>         <span class="dt">nl =</span> <span class="ot">TRUE</span>),</span>
<span id="cb2095-7"><a href="generalized-linear-madness.html#cb2095-7"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">lognormal</span>(<span class="kw">log</span>(<span class="dv">1</span>), <span class="fl">0.1</span>), <span class="dt">nlpar =</span> phi, <span class="dt">lb =</span> <span class="dv">0</span>),</span>
<span id="cb2095-8"><a href="generalized-linear-madness.html#cb2095-8"></a>                <span class="kw">prior</span>(<span class="kw">lognormal</span>(<span class="kw">log</span>(<span class="dv">2</span>), <span class="fl">0.25</span>), <span class="dt">nlpar =</span> k, <span class="dt">lb =</span> <span class="dv">0</span>),</span>
<span id="cb2095-9"><a href="generalized-linear-madness.html#cb2095-9"></a>                <span class="kw">prior</span>(<span class="kw">lognormal</span>(<span class="kw">log</span>(<span class="dv">5</span>), <span class="fl">0.25</span>), <span class="dt">nlpar =</span> theta, <span class="dt">lb =</span> <span class="dv">0</span>)),</span>
<span id="cb2095-10"><a href="generalized-linear-madness.html#cb2095-10"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb2095-11"><a href="generalized-linear-madness.html#cb2095-11"></a>      <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2095-12"><a href="generalized-linear-madness.html#cb2095-12"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b16.04&quot;</span>)</span></code></pre></div>
<p>Check the parameter summary.</p>
<div class="sourceCode" id="cb2096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2096-1"><a href="generalized-linear-madness.html#cb2096-1"></a><span class="kw">print</span>(b16<span class="fl">.4</span>)</span></code></pre></div>
<pre><code>##  Family: poisson 
##   Links: mu = identity 
## Formula: n ~ seconds * phi * (1 - exp(-k * age_s))^theta 
##          phi ~ 1
##          k ~ 1
##          theta ~ 1
##    Data: d (Number of observations: 84) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## phi_Intercept       0.86      0.04     0.79     0.95 1.00     1045     1589
## k_Intercept         5.97      0.56     4.88     7.09 1.00      787     1151
## theta_Intercept     9.81      2.00     6.50    14.31 1.00      858     1276
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>No we might get a sense of what this posterior means by plotting nuts per second as a function of <code>age</code> in our version of Figure 16.5.</p>
<div class="sourceCode" id="cb2098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2098-1"><a href="generalized-linear-madness.html#cb2098-1"></a><span class="kw">posterior_samples</span>(b16<span class="fl">.4</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2098-2"><a href="generalized-linear-madness.html#cb2098-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2098-3"><a href="generalized-linear-madness.html#cb2098-3"></a><span class="st">  </span><span class="kw">sample_n</span>(sample_n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2098-4"><a href="generalized-linear-madness.html#cb2098-4"></a><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(iter, b_phi_Intercept, b_k_Intercept, b_theta_Intercept),</span>
<span id="cb2098-5"><a href="generalized-linear-madness.html#cb2098-5"></a>         <span class="dt">age =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="fl">1.5</span>, <span class="dt">length.out =</span> <span class="fl">1e2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2098-6"><a href="generalized-linear-madness.html#cb2098-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ns =</span> b_phi_Intercept <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>b_k_Intercept <span class="op">*</span><span class="st"> </span>age))<span class="op">^</span>b_theta_Intercept) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2098-7"><a href="generalized-linear-madness.html#cb2098-7"></a><span class="st">  </span></span>
<span id="cb2098-8"><a href="generalized-linear-madness.html#cb2098-8"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb2098-9"><a href="generalized-linear-madness.html#cb2098-9"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> ns, <span class="dt">group =</span> iter),</span>
<span id="cb2098-10"><a href="generalized-linear-madness.html#cb2098-10"></a>            <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2098-11"><a href="generalized-linear-madness.html#cb2098-11"></a><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">data =</span> d,</span>
<span id="cb2098-12"><a href="generalized-linear-madness.html#cb2098-12"></a>              <span class="kw">aes</span>(<span class="dt">x =</span> age_s, <span class="dt">y =</span> n <span class="op">/</span><span class="st"> </span>seconds, <span class="dt">size =</span> seconds),</span>
<span id="cb2098-13"><a href="generalized-linear-madness.html#cb2098-13"></a>              <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">width =</span> <span class="fl">0.01</span>, <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></span>
<span id="cb2098-14"><a href="generalized-linear-madness.html#cb2098-14"></a><span class="st">  </span><span class="kw">scale_size_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="dv">100</span>), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="ot">NA</span>)) <span class="op">+</span></span>
<span id="cb2098-15"><a href="generalized-linear-madness.html#cb2098-15"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> at, <span class="dt">labels =</span> <span class="kw">round</span>(at <span class="op">*</span><span class="st"> </span><span class="kw">max</span>(d<span class="op">$</span>age))) <span class="op">+</span></span>
<span id="cb2098-16"><a href="generalized-linear-madness.html#cb2098-16"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Posterior predictive distribution for the</span><span class="ch">\n</span><span class="st">nut opening model&quot;</span>,</span>
<span id="cb2098-17"><a href="generalized-linear-madness.html#cb2098-17"></a>       <span class="dt">y =</span> <span class="st">&quot;nuts per second&quot;</span>) <span class="op">+</span></span>
<span id="cb2098-18"><a href="generalized-linear-madness.html#cb2098-18"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.background =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb2098-19"><a href="generalized-linear-madness.html#cb2098-19"></a>        <span class="dt">legend.position =</span> <span class="kw">c</span>(.<span class="dv">9</span>, <span class="fl">.25</span>))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-31-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Looks like things flatten out around <code>age == 16</code>. Yet since the data drop off at that <code>age</code>, we probably shouldn’t get overconfident.</p>
</div>
</div>
<div id="population-dynamics" class="section level2">
<h2><span class="header-section-number">16.4</span> Population dynamics</h2>
<p>Load the <code>Lynx_Hare</code> population dynamics data <span class="citation">(Hewitt, <a href="#ref-hewittTheConservation1921" role="doc-biblioref">1921</a>)</span>.</p>
<div class="sourceCode" id="cb2099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2099-1"><a href="generalized-linear-madness.html#cb2099-1"></a><span class="kw">data</span>(Lynx_Hare, <span class="dt">package =</span> <span class="st">&quot;rethinking&quot;</span>)</span>
<span id="cb2099-2"><a href="generalized-linear-madness.html#cb2099-2"></a></span>
<span id="cb2099-3"><a href="generalized-linear-madness.html#cb2099-3"></a><span class="kw">glimpse</span>(Lynx_Hare)</span></code></pre></div>
<pre><code>## Rows: 21
## Columns: 3
## $ Year &lt;int&gt; 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915…
## $ Lynx &lt;dbl&gt; 4.0, 6.1, 9.8, 35.2, 59.4, 41.7, 19.0, 13.0, 8.3, 9.1, 7.4, 8.0, 12.3, 19.5, 45.7, 51.1, 29.7,…
## $ Hare &lt;dbl&gt; 30.0, 47.2, 70.2, 77.4, 36.3, 20.6, 18.1, 21.4, 22.0, 25.4, 27.1, 40.3, 57.0, 76.6, 52.3, 19.5…</code></pre>
<p>Figure 6.6 will give us a sense of how the lynx and hare populations ebbed and flowed.</p>
<div class="sourceCode" id="cb2101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2101-1"><a href="generalized-linear-madness.html#cb2101-1"></a><span class="co"># for annotation</span></span>
<span id="cb2101-2"><a href="generalized-linear-madness.html#cb2101-2"></a>text &lt;-</span>
<span id="cb2101-3"><a href="generalized-linear-madness.html#cb2101-3"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">name  =</span> <span class="kw">c</span>(<span class="st">&quot;Hare&quot;</span>, <span class="st">&quot;Lynx&quot;</span>),</span>
<span id="cb2101-4"><a href="generalized-linear-madness.html#cb2101-4"></a>         <span class="dt">label =</span> <span class="kw">c</span>(<span class="st">&quot;Lepus&quot;</span>, <span class="st">&quot;Lynx&quot;</span>),</span>
<span id="cb2101-5"><a href="generalized-linear-madness.html#cb2101-5"></a>         <span class="dt">Year  =</span> <span class="kw">c</span>(<span class="fl">1913.5</span>, <span class="fl">1915.5</span>),</span>
<span id="cb2101-6"><a href="generalized-linear-madness.html#cb2101-6"></a>         <span class="dt">value =</span> <span class="kw">c</span>(<span class="dv">78</span>, <span class="dv">52</span>))</span>
<span id="cb2101-7"><a href="generalized-linear-madness.html#cb2101-7"></a></span>
<span id="cb2101-8"><a href="generalized-linear-madness.html#cb2101-8"></a><span class="co"># wrangle</span></span>
<span id="cb2101-9"><a href="generalized-linear-madness.html#cb2101-9"></a>Lynx_Hare <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2101-10"><a href="generalized-linear-madness.html#cb2101-10"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>Year) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2101-11"><a href="generalized-linear-madness.html#cb2101-11"></a><span class="st">  </span></span>
<span id="cb2101-12"><a href="generalized-linear-madness.html#cb2101-12"></a><span class="st">  </span><span class="co"># plot!</span></span>
<span id="cb2101-13"><a href="generalized-linear-madness.html#cb2101-13"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> value)) <span class="op">+</span></span>
<span id="cb2101-14"><a href="generalized-linear-madness.html#cb2101-14"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> name),</span>
<span id="cb2101-15"><a href="generalized-linear-madness.html#cb2101-15"></a>            <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb2101-16"><a href="generalized-linear-madness.html#cb2101-16"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> name),</span>
<span id="cb2101-17"><a href="generalized-linear-madness.html#cb2101-17"></a>             <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb2101-18"><a href="generalized-linear-madness.html#cb2101-18"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> text,</span>
<span id="cb2101-19"><a href="generalized-linear-madness.html#cb2101-19"></a>            <span class="kw">aes</span>(<span class="dt">label =</span> label, <span class="dt">color =</span> name),</span>
<span id="cb2101-20"><a href="generalized-linear-madness.html#cb2101-20"></a>            <span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>) <span class="op">+</span></span>
<span id="cb2101-21"><a href="generalized-linear-madness.html#cb2101-21"></a><span class="st">  </span><span class="kw">scale_fill_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>) <span class="op">+</span></span>
<span id="cb2101-22"><a href="generalized-linear-madness.html#cb2101-22"></a><span class="st">  </span><span class="kw">scale_color_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>) <span class="op">+</span></span>
<span id="cb2101-23"><a href="generalized-linear-madness.html#cb2101-23"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;thousands of pelts&quot;</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="dv">20</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">90</span>)) <span class="op">+</span></span>
<span id="cb2101-24"><a href="generalized-linear-madness.html#cb2101-24"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-33-1.png" width="624" style="display: block; margin: auto;" /></p>
<p>Note, however, that these are numbers of pelts, not of actual animals.</p>
<p>A typical way to model evenly-spaced time series data like this would be with an autoregressive model with the basic structure</p>
<p><span class="math display">\[\operatorname{E}(y_t) = \alpha + \beta_1 y_{t-1},\]</span></p>
<p>where <span class="math inline">\(t\)</span> indexes time and <span class="math inline">\(t - 1\)</span> is the time point immediately before <span class="math inline">\(t\)</span>. Models following this form are called first-order autoregressive models, AR(1), meaning that the current time point is only influenced by the previous time point, but none of the earlier ones. You can build on this format by adding other predictors. A natural way would be to use a predictor from <span class="math inline">\(t - 1\)</span> to predict <span class="math inline">\(y_t\)</span>, following the form</p>
<p><span class="math display">\[\operatorname{E}(y_t) = \alpha + \beta_1 y_{t-1} + \beta_2 x_{t-1}.\]</span></p>
<p>But that’s still a first-order model. A second-order model, AR(2), would include a term for <span class="math inline">\(y_{t - 2}\)</span>, such as</p>
<p><span class="math display">\[\operatorname{E}(y_t) = \alpha + \beta_1 y_{t-1} + \beta_2 x_{t-1} + \beta_3 y_{t-2}.\]</span></p>
<p>McElreath isn’t a huge fan of these models, particularly from the scientific modeling perspective he developed in this chapter. But <strong>brms</strong> can fit them and we’ll practice a little in a bonus section, later on. In the mean time, we’ll follow along and learn about <strong>ordinary differential equations</strong> (ODEs).</p>
<div id="the-scientific-model.-2" class="section level3">
<h3><span class="header-section-number">16.4.1</span> The scientific model.</h3>
<p>If we let <span class="math inline">\(H_t\)</span> be the number of hares at time <span class="math inline">\(t\)</span>, we can express the <strong>rate of change</strong> in the hare population as</p>
<p><span class="math display">\[\frac{\mathrm{d} H}{\mathrm{d} t} = H_t \times (\text{birth rate}) - H_t \times (\text{death rate}).\]</span></p>
<p>If we presume both birth rates and death rates (<em>mortality</em> rates) are constants, we might denote them <span class="math inline">\(b_H\)</span> and <span class="math inline">\(m_H\)</span>, respectively, and re-express the formula as</p>
<p><span class="math display">\[\frac{\mathrm{d} H}{\mathrm{d} t} = H_t b_H - H_t m_H = H_t (b_H - m_H).\]</span></p>
<p>If we let <span class="math inline">\(L_t\)</span> stand for the number of lynx present at time <span class="math inline">\(t\)</span>, we can allow the mortality rate depend on that variable with the expanded formula</p>
<p><span class="math display">\[\frac{\mathrm{d} H}{\mathrm{d} t} = H_t (b_H - L_t m_H).\]</span></p>
<p>We can expand this even further to model how the number of hares at a given time influence the birth rate for lynx (<span class="math inline">\(b_L\)</span>) to help us model the rate of change in the lynx population as</p>
<p><span class="math display">\[\frac{\mathrm{d} L}{\mathrm{d} t} = L_t (H_t b_L - m_L),\]</span></p>
<p>where the lynx mortality rate (<span class="math inline">\(m_l\)</span>) is now constant. This is called the <strong>Lotka-Volterra model</strong> <span class="citation">(Lotka, <a href="#ref-lotkaPrinciplesOfPhysicalBiology1925" role="doc-biblioref">1925</a>; Volterra, <a href="#ref-volterraFluctuationsAbundanceSpecies1926" role="doc-biblioref">1926</a>)</span>. You may have noticed how the above equations shifted our focus from what were were originally interested in, <span class="math inline">\(\operatorname{E}(H_t)\)</span>, to a rate of change, <span class="math inline">\(\mathrm{d} H / \mathrm{d} t\)</span>. Happily, our equation for <span class="math inline">\(\mathrm{d} H / \mathrm{d} t\)</span>, “tells us how to update <span class="math inline">\(H\)</span> after each tiny unit of passing time <span class="math inline">\(\mathrm d t\)</span>” (p. 544). You update by</p>
<p><span class="math display">\[H_{t +\mathrm d t} = H_t + \mathrm d t \frac{\mathrm d H}{\mathrm d t} = H_t + \mathrm d t H_t (b_H - L_t m_H).\]</span>
Here we’ll use the custom <code>sim_lynx_hare()</code> function to simulate how this can work. Our version of the function is very similar to the one McElreath displayed in his <strong>R</strong> code 16.14, but we changed it so it returns a tibble.</p>
<div class="sourceCode" id="cb2102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2102-1"><a href="generalized-linear-madness.html#cb2102-1"></a>sim_lynx_hare &lt;-<span class="st"> </span><span class="cf">function</span>(n_steps, init, theta, <span class="dt">dt =</span> <span class="fl">0.002</span>) { </span>
<span id="cb2102-2"><a href="generalized-linear-madness.html#cb2102-2"></a>  </span>
<span id="cb2102-3"><a href="generalized-linear-madness.html#cb2102-3"></a>  L &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_steps)</span>
<span id="cb2102-4"><a href="generalized-linear-madness.html#cb2102-4"></a>  H &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n_steps)</span>
<span id="cb2102-5"><a href="generalized-linear-madness.html#cb2102-5"></a>  L[<span class="dv">1</span>] &lt;-<span class="st"> </span>init[<span class="dv">1</span>]</span>
<span id="cb2102-6"><a href="generalized-linear-madness.html#cb2102-6"></a>  H[<span class="dv">1</span>] &lt;-<span class="st"> </span>init[<span class="dv">2</span>]</span>
<span id="cb2102-7"><a href="generalized-linear-madness.html#cb2102-7"></a>  </span>
<span id="cb2102-8"><a href="generalized-linear-madness.html#cb2102-8"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>n_steps) {</span>
<span id="cb2102-9"><a href="generalized-linear-madness.html#cb2102-9"></a>    H[i] &lt;-<span class="st"> </span>H[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>dt <span class="op">*</span><span class="st"> </span>H[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>(theta[<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>theta[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>L[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>])</span>
<span id="cb2102-10"><a href="generalized-linear-madness.html#cb2102-10"></a>    L[i] &lt;-<span class="st"> </span>L[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>dt <span class="op">*</span><span class="st"> </span>L[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>(theta[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>H[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>theta[<span class="dv">4</span>])</span>
<span id="cb2102-11"><a href="generalized-linear-madness.html#cb2102-11"></a>  }</span>
<span id="cb2102-12"><a href="generalized-linear-madness.html#cb2102-12"></a>  </span>
<span id="cb2102-13"><a href="generalized-linear-madness.html#cb2102-13"></a>  <span class="co"># return a tibble</span></span>
<span id="cb2102-14"><a href="generalized-linear-madness.html#cb2102-14"></a>  <span class="kw">tibble</span>(<span class="dt">H =</span> H,</span>
<span id="cb2102-15"><a href="generalized-linear-madness.html#cb2102-15"></a>         <span class="dt">L =</span> L)</span>
<span id="cb2102-16"><a href="generalized-linear-madness.html#cb2102-16"></a>  </span>
<span id="cb2102-17"><a href="generalized-linear-madness.html#cb2102-17"></a>}</span></code></pre></div>
<p>Now we simulate.</p>
<div class="sourceCode" id="cb2103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2103-1"><a href="generalized-linear-madness.html#cb2103-1"></a>theta &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.05</span>, <span class="fl">0.025</span>, <span class="fl">0.5</span>)</span>
<span id="cb2103-2"><a href="generalized-linear-madness.html#cb2103-2"></a></span>
<span id="cb2103-3"><a href="generalized-linear-madness.html#cb2103-3"></a><span class="co"># simulate</span></span>
<span id="cb2103-4"><a href="generalized-linear-madness.html#cb2103-4"></a>z &lt;-<span class="st"> </span><span class="kw">sim_lynx_hare</span>(<span class="dt">n_steps =</span> <span class="fl">1e4</span>, </span>
<span id="cb2103-5"><a href="generalized-linear-madness.html#cb2103-5"></a>                   <span class="dt">init =</span> <span class="kw">as.numeric</span>(Lynx_Hare[<span class="dv">1</span>, <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>]), </span>
<span id="cb2103-6"><a href="generalized-linear-madness.html#cb2103-6"></a>                   theta)</span>
<span id="cb2103-7"><a href="generalized-linear-madness.html#cb2103-7"></a></span>
<span id="cb2103-8"><a href="generalized-linear-madness.html#cb2103-8"></a><span class="co"># what did we do?</span></span>
<span id="cb2103-9"><a href="generalized-linear-madness.html#cb2103-9"></a><span class="kw">glimpse</span>(z)</span></code></pre></div>
<pre><code>## Rows: 10,000
## Columns: 2
## $ H &lt;dbl&gt; 30.00000, 30.01800, 30.03600, 30.05401, 30.07203, 30.09005, 30.10807, 30.12610, 30.14413, 30.1621…
## $ L &lt;dbl&gt; 4.000000, 4.002000, 4.004005, 4.006014, 4.008028, 4.010046, 4.012069, 4.014097, 4.016129, 4.01816…</code></pre>
<p>Each row is a stand-in index for time. Here we’ll explicitly add a <code>time</code> column and them plot the results in our version of Figure 16.7.</p>
<div class="sourceCode" id="cb2105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2105-1"><a href="generalized-linear-madness.html#cb2105-1"></a>z <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2105-2"><a href="generalized-linear-madness.html#cb2105-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">time =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2105-3"><a href="generalized-linear-madness.html#cb2105-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>time) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2105-4"><a href="generalized-linear-madness.html#cb2105-4"></a><span class="st">  </span></span>
<span id="cb2105-5"><a href="generalized-linear-madness.html#cb2105-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> time, <span class="dt">y =</span> value)) <span class="op">+</span></span>
<span id="cb2105-6"><a href="generalized-linear-madness.html#cb2105-6"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> name),</span>
<span id="cb2105-7"><a href="generalized-linear-madness.html#cb2105-7"></a>            <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb2105-8"><a href="generalized-linear-madness.html#cb2105-8"></a><span class="st">  </span><span class="kw">scale_color_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>) <span class="op">+</span></span>
<span id="cb2105-9"><a href="generalized-linear-madness.html#cb2105-9"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2105-10"><a href="generalized-linear-madness.html#cb2105-10"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;number (thousands)&quot;</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="dv">10</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">45</span>)) <span class="op">+</span></span>
<span id="cb2105-11"><a href="generalized-linear-madness.html#cb2105-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-36-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>“This model produces cycles, similar to what we see in the data. The model behaves this way, because lynx eat hares. Once the hares are eaten, the lynx begin to die off. Then the cycle repeats (p. 545).”</p>
</div>
<div id="the-statistical-model.-2" class="section level3">
<h3><span class="header-section-number">16.4.2</span> The statistical model.</h3>
<p>If we continue to let <span class="math inline">\(H_t\)</span> and <span class="math inline">\(L_t\)</span> be the number of hares and lynx at time <span class="math inline">\(t\)</span>, we might also want to acknowledge the distinction between those numbers and our observations by letting <span class="math inline">\(h_t\)</span> and <span class="math inline">\(l_t\)</span> stand for the observed numbers of hares and lynx. These observed numbers, recall, are from counts of pelts. We want a statistical model that can connect <span class="math inline">\(h_t\)</span> to <span class="math inline">\(H_t\)</span> and connect <span class="math inline">\(l_t\)</span> to <span class="math inline">\(L_t\)</span>. Part of that model would include the probability a hare was trapped on a given year, <span class="math inline">\(p_h\)</span>, and a similar probability for a lynx getting trapped, <span class="math inline">\(p_l\)</span>. To make things worse, further imagine the number of pelts for each, in a given year, was rounded to the nearest <span class="math inline">\(100\)</span> and divided by <span class="math inline">\(1{,}000\)</span>. Those are our values.</p>
<p>We practice simulating all this in Figure 16.8. Here we propose a population of <span class="math inline">\(H_t = 10^4\)</span> hares and an average trapping rate of about <span class="math inline">\(10\%\)</span>, as expressed by <span class="math inline">\(p_t \sim \operatorname{Beta}(2, 18)\)</span>. As described above, we then divide the number of observed pelts by <span class="math inline">\(1{,}000\)</span> and round the results, yielding <span class="math inline">\(h_t\)</span>.</p>
<div class="sourceCode" id="cb2106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2106-1"><a href="generalized-linear-madness.html#cb2106-1"></a>n &lt;-<span class="st"> </span><span class="fl">1e4</span></span>
<span id="cb2106-2"><a href="generalized-linear-madness.html#cb2106-2"></a>Ht &lt;-<span class="st"> </span><span class="fl">1e4</span></span>
<span id="cb2106-3"><a href="generalized-linear-madness.html#cb2106-3"></a></span>
<span id="cb2106-4"><a href="generalized-linear-madness.html#cb2106-4"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2106-5"><a href="generalized-linear-madness.html#cb2106-5"></a></span>
<span id="cb2106-6"><a href="generalized-linear-madness.html#cb2106-6"></a><span class="co"># simulate</span></span>
<span id="cb2106-7"><a href="generalized-linear-madness.html#cb2106-7"></a><span class="kw">tibble</span>(<span class="dt">pt =</span> <span class="kw">rbeta</span>(n, <span class="dt">shape1 =</span> <span class="dv">2</span>, <span class="dt">shape2 =</span> <span class="dv">18</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2106-8"><a href="generalized-linear-madness.html#cb2106-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ht =</span> <span class="kw">rbinom</span>(n, <span class="dt">size =</span> Ht, <span class="dt">prob =</span> pt)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2106-9"><a href="generalized-linear-madness.html#cb2106-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ht =</span> <span class="kw">round</span>(ht <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>, <span class="dt">digits =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2106-10"><a href="generalized-linear-madness.html#cb2106-10"></a><span class="st">  </span></span>
<span id="cb2106-11"><a href="generalized-linear-madness.html#cb2106-11"></a><span class="st">  </span><span class="co"># plot</span></span>
<span id="cb2106-12"><a href="generalized-linear-madness.html#cb2106-12"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ht)) <span class="op">+</span></span>
<span id="cb2106-13"><a href="generalized-linear-madness.html#cb2106-13"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>,</span>
<span id="cb2106-14"><a href="generalized-linear-madness.html#cb2106-14"></a>                 <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></span>
<span id="cb2106-15"><a href="generalized-linear-madness.html#cb2106-15"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2106-16"><a href="generalized-linear-madness.html#cb2106-16"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(thousand<span class="op">~</span>of<span class="op">~</span>pelts<span class="op">~</span>(<span class="kw">italic</span>(h[t]))))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-37-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>On page 546, McElreath encouraged us to try the simulation with different values of <span class="math inline">\(H_t\)</span> and <span class="math inline">\(p_t\)</span>. Here we’ll do so with a <span class="math inline">\(3 \times 3\)</span> grid of <span class="math inline">\(H_t = \{5{,}000, 10{,}000, 15{,}000\}\)</span> and <span class="math inline">\(p_t \sim \{ \operatorname{Beta}(2, 18), \operatorname{Beta}(10, 10), \operatorname{Beta}(18, 2) \}\)</span>.</p>
<div class="sourceCode" id="cb2107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2107-1"><a href="generalized-linear-madness.html#cb2107-1"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2107-2"><a href="generalized-linear-madness.html#cb2107-2"></a></span>
<span id="cb2107-3"><a href="generalized-linear-madness.html#cb2107-3"></a><span class="co"># define the 3X3 grid</span></span>
<span id="cb2107-4"><a href="generalized-linear-madness.html#cb2107-4"></a><span class="kw">tibble</span>(<span class="dt">shape1 =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">18</span>),</span>
<span id="cb2107-5"><a href="generalized-linear-madness.html#cb2107-5"></a>       <span class="dt">shape2 =</span> <span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">10</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2107-6"><a href="generalized-linear-madness.html#cb2107-6"></a><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(shape1, shape2),</span>
<span id="cb2107-7"><a href="generalized-linear-madness.html#cb2107-7"></a>         <span class="dt">Ht =</span> <span class="kw">c</span>(<span class="fl">5e3</span>, <span class="fl">1e4</span>, <span class="fl">15e3</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2107-8"><a href="generalized-linear-madness.html#cb2107-8"></a><span class="st">  </span><span class="co"># simulate</span></span>
<span id="cb2107-9"><a href="generalized-linear-madness.html#cb2107-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pt =</span> purrr<span class="op">::</span><span class="kw">map2</span>(shape1, shape2, <span class="op">~</span><span class="kw">rbeta</span>(n, <span class="dt">shape1 =</span> .x, <span class="dt">shape2 =</span> .y))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2107-10"><a href="generalized-linear-madness.html#cb2107-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ht =</span> purrr<span class="op">::</span><span class="kw">map2</span>(Ht, pt, <span class="op">~</span><span class="kw">rbinom</span>(n, <span class="dt">size =</span> .x, <span class="dt">prob =</span> .y))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2107-11"><a href="generalized-linear-madness.html#cb2107-11"></a><span class="st">  </span><span class="kw">unnest</span>(<span class="kw">c</span>(pt, ht)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2107-12"><a href="generalized-linear-madness.html#cb2107-12"></a><span class="st">  </span><span class="co"># wrangle</span></span>
<span id="cb2107-13"><a href="generalized-linear-madness.html#cb2107-13"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ht    =</span> <span class="kw">round</span>(ht <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>, <span class="dt">digits =</span> <span class="dv">2</span>),</span>
<span id="cb2107-14"><a href="generalized-linear-madness.html#cb2107-14"></a>         <span class="dt">beta  =</span> <span class="kw">str_c</span>(<span class="st">&quot;italic(p[t])%~%&#39;Beta &#39;(&quot;</span>, shape1, <span class="st">&quot;, &quot;</span>, shape2, <span class="st">&quot;)&quot;</span>),</span>
<span id="cb2107-15"><a href="generalized-linear-madness.html#cb2107-15"></a>         <span class="dt">Htlab =</span> <span class="kw">str_c</span>(<span class="st">&quot;italic(H[t])==&quot;</span>, Ht)) <span class="op">%&gt;%</span></span>
<span id="cb2107-16"><a href="generalized-linear-madness.html#cb2107-16"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">beta  =</span> <span class="kw">factor</span>(beta,</span>
<span id="cb2107-17"><a href="generalized-linear-madness.html#cb2107-17"></a>                        <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;italic(p[t])%~%&#39;Beta &#39;(2, 18)&quot;</span>, <span class="st">&quot;italic(p[t])%~%&#39;Beta &#39;(10, 10)&quot;</span>, <span class="st">&quot;italic(p[t])%~%&#39;Beta &#39;(18, 2)&quot;</span>)),</span>
<span id="cb2107-18"><a href="generalized-linear-madness.html#cb2107-18"></a>         <span class="dt">Htlab =</span> <span class="kw">factor</span>(Htlab,</span>
<span id="cb2107-19"><a href="generalized-linear-madness.html#cb2107-19"></a>                        <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;italic(H[t])==15000&quot;</span>, <span class="st">&quot;italic(H[t])==10000&quot;</span>, <span class="st">&quot;italic(H[t])==5000&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2107-20"><a href="generalized-linear-madness.html#cb2107-20"></a><span class="st">  </span></span>
<span id="cb2107-21"><a href="generalized-linear-madness.html#cb2107-21"></a><span class="st">  </span><span class="co"># plot!</span></span>
<span id="cb2107-22"><a href="generalized-linear-madness.html#cb2107-22"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> ht)) <span class="op">+</span></span>
<span id="cb2107-23"><a href="generalized-linear-madness.html#cb2107-23"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> beta <span class="op">==</span><span class="st"> &quot;italic(p[t])%~%&#39;Beta &#39;(2, 18)&quot;</span> <span class="op">&amp;</span><span class="st"> </span>Htlab <span class="op">==</span><span class="st"> &quot;italic(H[t])==10000&quot;</span>),</span>
<span id="cb2107-24"><a href="generalized-linear-madness.html#cb2107-24"></a>                 <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">binwidth =</span> <span class="fl">0.25</span>) <span class="op">+</span></span>
<span id="cb2107-25"><a href="generalized-linear-madness.html#cb2107-25"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> Ht <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>), </span>
<span id="cb2107-26"><a href="generalized-linear-madness.html#cb2107-26"></a>             <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2107-27"><a href="generalized-linear-madness.html#cb2107-27"></a><span class="st">  </span><span class="kw">scale_fill_grey</span>(<span class="dt">start =</span> <span class="fl">.67</span>, <span class="dt">end =</span> <span class="dv">0</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2107-28"><a href="generalized-linear-madness.html#cb2107-28"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2107-29"><a href="generalized-linear-madness.html#cb2107-29"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(thousand<span class="op">~</span>of<span class="op">~</span>pelts<span class="op">~</span>(<span class="kw">italic</span>(h[t])))) <span class="op">+</span></span>
<span id="cb2107-30"><a href="generalized-linear-madness.html#cb2107-30"></a><span class="st">  </span><span class="kw">facet_grid</span>(Htlab<span class="op">~</span>beta, <span class="dt">labeller =</span> label_parsed, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-38-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The vertical dashed lines mark off the maximum values in each panel. The histogram in black is of the simulation parameters based on our version of Figure 16.8, above.</p>
<p>McElreath’s proposed model is</p>
<p><span class="math display">\[
\begin{align*}
h_t &amp; \sim \operatorname{Log-Normal} \big (\log(p_H H_t), \sigma_H \big) \\
l_t &amp; \sim \operatorname{Log-Normal} \big (\log(p_L L_t), \sigma_L \big) \\
H_1 &amp; \sim \operatorname{Log-Normal}(\log 10, 1) \\
L_1 &amp; \sim \operatorname{Log-Normal}(\log 10, 1) \\
H_{T &gt;1} &amp; = H_1 + \int_1^T H_t (b_H - m_H L_t) \mathrm{d} t \\
L_{T &gt;1} &amp; = L_1 + \int_1^T L_t (b_L H_T - m_L) \mathrm{d} t \\
\sigma_H &amp; \sim \operatorname{Exponential}(1) \\
\sigma_L &amp; \sim \operatorname{Exponential}(1) \\
p_H &amp; \sim \operatorname{Beta}(\alpha_H, \beta_H) \\
p_L &amp; \sim \operatorname{Beta}(\alpha_L, \beta_L) \\
b_H &amp; \sim \operatorname{Half-Normal}(1, 0.5) \\
b_L &amp; \sim \operatorname{Half-Normal}(0.5, 0.5) \\
m_H &amp; \sim \operatorname{Half-Normal}(0.5, 0.5) \\
m_L &amp; \sim \operatorname{Half-Normal}(1, 0.5).
\end{align*}
\]</span></p>
<p>It’s not immediately clear from the text, but if you look closely at the output from <code>cat(Lynx_Hare_model)</code> (see below), you’ll see <span class="math inline">\(\alpha_H = \alpha_L = 40\)</span> and <span class="math inline">\(\beta_H = \beta_L = 200\)</span>.</p>
<p>Happily, Stan has built-in functions for solving differential equations <span class="citation">(Stan Development Team, <a href="#ref-standevelopmentteamStanReferenceManual2020" role="doc-biblioref">2020</a><a href="#ref-standevelopmentteamStanReferenceManual2020" role="doc-biblioref">b</a>, Chapter 13)</span> and using them is, in principle, possible with <strong>brms</strong>, For an example of an ODE model with <strong>brms</strong>, see <a href="https://twitter.com/MarkusGesmann">Markus Gesmann</a>’s blog post, <a href="https://magesblog.com/post/2018-01-30-pkpd-reserving-models/"><em>PK/PD reserving models</em></a>. However, this model is beyond my current skill set. Instead of attempting to fit the model with <code>brms::brm()</code>, we’ll follow McElreath’s example and load his pre-written Stan code.</p>
<div class="sourceCode" id="cb2108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2108-1"><a href="generalized-linear-madness.html#cb2108-1"></a><span class="kw">data</span>(Lynx_Hare_model) </span>
<span id="cb2108-2"><a href="generalized-linear-madness.html#cb2108-2"></a><span class="kw">cat</span>(Lynx_Hare_model)</span></code></pre></div>
<pre><code>## functions {
##   real[] dpop_dt( real t,                 // time
##                 real[] pop_init,          // initial state {lynx, hares}
##                 real[] theta,             // parameters
##                 real[] x_r, int[] x_i) {  // unused
##     real L = pop_init[1];
##     real H = pop_init[2];
##     real bh = theta[1];
##     real mh = theta[2];
##     real ml = theta[3];
##     real bl = theta[4];
##     // differential equations
##     real dH_dt = (bh - mh * L) * H;
##     real dL_dt = (bl * H - ml) * L;
##     return { dL_dt , dH_dt };
##   }
## }
## data {
##   int&lt;lower=0&gt; N;              // number of measurement times
##   real&lt;lower=0&gt; pelts[N,2];    // measured populations
## }
## transformed data{
##   real times_measured[N-1];    // N-1 because first time is initial state
##   for ( i in 2:N ) times_measured[i-1] = i;
## }
## parameters {
##   real&lt;lower=0&gt; theta[4];      // { bh, mh, ml, bl }
##   real&lt;lower=0&gt; pop_init[2];   // initial population state
##   real&lt;lower=0&gt; sigma[2];      // measurement errors
##   real&lt;lower=0,upper=1&gt; p[2];  // trap rate
## }
## transformed parameters {
##   real pop[N, 2];
##   pop[1,1] = pop_init[1];
##   pop[1,2] = pop_init[2];
##   pop[2:N,1:2] = integrate_ode_rk45(
##     dpop_dt, pop_init, 0, times_measured, theta,
##     rep_array(0.0, 0), rep_array(0, 0),
##     1e-5, 1e-3, 5e2);
## }
## model {
##   // priors
##   theta[{1,3}] ~ normal( 1 , 0.5 );    // bh,ml
##   theta[{2,4}] ~ normal( 0.05, 0.05 ); // mh,bl
##   sigma ~ exponential( 1 );
##   pop_init ~ lognormal( log(10) , 1 );
##   p ~ beta(40,200);
##   // observation model
##   // connect latent population state to observed pelts
##   for ( t in 1:N )
##     for ( k in 1:2 )
##       pelts[t,k] ~ lognormal( log(pop[t,k]*p[k]) , sigma[k] );
## }
## generated quantities {
##   real pelts_pred[N,2];
##   for ( t in 1:N )
##     for ( k in 1:2 )
##       pelts_pred[t,k] = lognormal_rng( log(pop[t,k]*p[k]) , sigma[k] );
## }</code></pre>
<p>Fit the model directly with <code>rstan::stan()</code>.</p>
<div class="sourceCode" id="cb2110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2110-1"><a href="generalized-linear-madness.html#cb2110-1"></a>dat_list &lt;-<span class="st"> </span><span class="kw">list</span>(</span>
<span id="cb2110-2"><a href="generalized-linear-madness.html#cb2110-2"></a>  <span class="dt">N     =</span> <span class="kw">nrow</span>(Lynx_Hare), </span>
<span id="cb2110-3"><a href="generalized-linear-madness.html#cb2110-3"></a>  <span class="dt">pelts =</span> Lynx_Hare[, <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>])</span>
<span id="cb2110-4"><a href="generalized-linear-madness.html#cb2110-4"></a></span>
<span id="cb2110-5"><a href="generalized-linear-madness.html#cb2110-5"></a>m16<span class="fl">.5</span> &lt;-<span class="st"> </span></span>
<span id="cb2110-6"><a href="generalized-linear-madness.html#cb2110-6"></a><span class="st">  </span><span class="kw">stan</span>(<span class="dt">model_code =</span> Lynx_Hare_model, </span>
<span id="cb2110-7"><a href="generalized-linear-madness.html#cb2110-7"></a>       <span class="dt">data =</span> dat_list,</span>
<span id="cb2110-8"><a href="generalized-linear-madness.html#cb2110-8"></a>       <span class="dt">chains =</span> <span class="dv">3</span>, <span class="dt">cores =</span> <span class="dv">3</span>,</span>
<span id="cb2110-9"><a href="generalized-linear-madness.html#cb2110-9"></a>       <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2110-10"><a href="generalized-linear-madness.html#cb2110-10"></a>       <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">.95</span>))</span></code></pre></div>
<p>Check the model summary.</p>
<div class="sourceCode" id="cb2111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2111-1"><a href="generalized-linear-madness.html#cb2111-1"></a><span class="kw">precis</span>(m16<span class="fl">.5</span>, <span class="dt">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                     mean           sd         5.5%        94.5%    n_eff     Rhat4
## theta[1]    5.302960e-01 6.213675e-02 4.373223e-01 6.337997e-01 1423.953 1.0010038
## theta[2]    4.763520e-03 9.846471e-04 3.360071e-03 6.445385e-03 1512.500 1.0000350
## theta[3]    8.125347e-01 9.350351e-02 6.751197e-01 9.678926e-01 1366.636 1.0016958
## theta[4]    4.336111e-03 9.126261e-04 3.047285e-03 5.888605e-03 1343.215 1.0011623
## pop_init[1] 3.654094e+01 6.423735e+00 2.733513e+01 4.753749e+01 1866.678 0.9996136
## pop_init[2] 1.416329e+02 2.378115e+01 1.078512e+02 1.824840e+02 1452.160 1.0002786
## sigma[1]    2.630953e-01 4.485646e-02 2.009274e-01 3.446896e-01 2453.048 0.9999045
## sigma[2]    2.516346e-01 4.442872e-02 1.914259e-01 3.293270e-01 2258.857 0.9994789
## p[1]        1.753958e-01 2.455033e-02 1.386690e-01 2.149848e-01 1740.960 0.9993156
## p[2]        1.794219e-01 2.460429e-02 1.424884e-01 2.198799e-01 1545.822 1.0005882</code></pre>
<p>For a more elaborate summary, execute <code>precis(m16.5, depth = 3)</code>. Here we extract the posterior samples with <code>extract.samples()</code>. Since this differs a bit from our typical <strong>brms</strong> workflow, we’ll want to inspect the structure of its contents.</p>
<div class="sourceCode" id="cb2113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2113-1"><a href="generalized-linear-madness.html#cb2113-1"></a>post &lt;-<span class="st"> </span><span class="kw">extract.samples</span>(m16<span class="fl">.5</span>) </span>
<span id="cb2113-2"><a href="generalized-linear-madness.html#cb2113-2"></a></span>
<span id="cb2113-3"><a href="generalized-linear-madness.html#cb2113-3"></a>post <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2113-4"><a href="generalized-linear-madness.html#cb2113-4"></a><span class="st">  </span><span class="kw">glimpse</span>()</span></code></pre></div>
<pre><code>## List of 7
##  $ theta     : num [1:3000, 1:4] 0.572 0.587 0.637 0.61 0.54 ...
##  $ pop_init  : num [1:3000, 1:2] 42.2 38 43.5 30.1 39 ...
##  $ sigma     : num [1:3000, 1:2] 0.262 0.237 0.421 0.287 0.292 ...
##  $ p         : num [1:3000, 1:2] 0.171 0.183 0.139 0.21 0.171 ...
##  $ pop       : num [1:3000, 1:21, 1:2] 42.2 38 43.5 30.1 39 ...
##  $ pelts_pred: num [1:3000, 1:21, 1:2] 8.34 9.96 3.63 9.88 10.57 ...
##  $ lp__      : num [1:3000(1d)] -200 -200 -207 -202 -199 ...</code></pre>
<p>To make our version of the top portion of Figure 16.9, we’ll want to draw from the contents of <code>post$pelts_pred</code>.</p>
<div class="sourceCode" id="cb2115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2115-1"><a href="generalized-linear-madness.html#cb2115-1"></a><span class="co"># for annotation</span></span>
<span id="cb2115-2"><a href="generalized-linear-madness.html#cb2115-2"></a>text &lt;-</span>
<span id="cb2115-3"><a href="generalized-linear-madness.html#cb2115-3"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">name  =</span> <span class="kw">c</span>(<span class="st">&quot;Hare&quot;</span>, <span class="st">&quot;Lynx&quot;</span>),</span>
<span id="cb2115-4"><a href="generalized-linear-madness.html#cb2115-4"></a>         <span class="dt">label =</span> <span class="kw">c</span>(<span class="st">&quot;Lepus&quot;</span>, <span class="st">&quot;Lynx&quot;</span>),</span>
<span id="cb2115-5"><a href="generalized-linear-madness.html#cb2115-5"></a>         <span class="dt">year  =</span> <span class="kw">c</span>(<span class="dv">1914</span>, <span class="fl">1916.5</span>),</span>
<span id="cb2115-6"><a href="generalized-linear-madness.html#cb2115-6"></a>         <span class="dt">value =</span> <span class="kw">c</span>(<span class="dv">92</span>, <span class="dv">54</span>))</span>
<span id="cb2115-7"><a href="generalized-linear-madness.html#cb2115-7"></a></span>
<span id="cb2115-8"><a href="generalized-linear-madness.html#cb2115-8"></a><span class="co"># subset the relevant posterior draws</span></span>
<span id="cb2115-9"><a href="generalized-linear-madness.html#cb2115-9"></a>p1 &lt;-</span>
<span id="cb2115-10"><a href="generalized-linear-madness.html#cb2115-10"></a><span class="st">  </span><span class="kw">rbind</span>(post<span class="op">$</span>pelts_pred[<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">2</span>],</span>
<span id="cb2115-11"><a href="generalized-linear-madness.html#cb2115-11"></a>        post<span class="op">$</span>pelts_pred[<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">1</span>])<span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2115-12"><a href="generalized-linear-madness.html#cb2115-12"></a><span class="st">  </span><span class="co"># wrangle</span></span>
<span id="cb2115-13"><a href="generalized-linear-madness.html#cb2115-13"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2115-14"><a href="generalized-linear-madness.html#cb2115-14"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="dv">1900</span><span class="op">:</span><span class="dv">1920</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2115-15"><a href="generalized-linear-madness.html#cb2115-15"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dt">times =</span> <span class="dv">2</span>),</span>
<span id="cb2115-16"><a href="generalized-linear-madness.html#cb2115-16"></a>         <span class="dt">name =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Hare&quot;</span>, <span class="st">&quot;Lynx&quot;</span>), <span class="dt">each =</span> <span class="dv">21</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2115-17"><a href="generalized-linear-madness.html#cb2115-17"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span><span class="kw">c</span>(iter, name),</span>
<span id="cb2115-18"><a href="generalized-linear-madness.html#cb2115-18"></a>               <span class="dt">names_to =</span> <span class="st">&quot;year&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2115-19"><a href="generalized-linear-madness.html#cb2115-19"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year =</span> <span class="kw">as.numeric</span>(year)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2115-20"><a href="generalized-linear-madness.html#cb2115-20"></a><span class="st">  </span></span>
<span id="cb2115-21"><a href="generalized-linear-madness.html#cb2115-21"></a><span class="st">  </span><span class="co"># plot</span></span>
<span id="cb2115-22"><a href="generalized-linear-madness.html#cb2115-22"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> value)) <span class="op">+</span></span>
<span id="cb2115-23"><a href="generalized-linear-madness.html#cb2115-23"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> <span class="kw">interaction</span>(iter, name), <span class="dt">color =</span> name),</span>
<span id="cb2115-24"><a href="generalized-linear-madness.html#cb2115-24"></a>            <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2115-25"><a href="generalized-linear-madness.html#cb2115-25"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> Lynx_Hare <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(Lynx<span class="op">:</span>Hare),</span>
<span id="cb2115-26"><a href="generalized-linear-madness.html#cb2115-26"></a>             <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">fill =</span> name),</span>
<span id="cb2115-27"><a href="generalized-linear-madness.html#cb2115-27"></a>             <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">stroke =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb2115-28"><a href="generalized-linear-madness.html#cb2115-28"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> text,</span>
<span id="cb2115-29"><a href="generalized-linear-madness.html#cb2115-29"></a>            <span class="kw">aes</span>(<span class="dt">label =</span> label, <span class="dt">color =</span> name),</span>
<span id="cb2115-30"><a href="generalized-linear-madness.html#cb2115-30"></a>            <span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>) <span class="op">+</span></span>
<span id="cb2115-31"><a href="generalized-linear-madness.html#cb2115-31"></a><span class="st">  </span><span class="kw">scale_fill_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2115-32"><a href="generalized-linear-madness.html#cb2115-32"></a><span class="st">  </span><span class="kw">scale_color_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2115-33"><a href="generalized-linear-madness.html#cb2115-33"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2115-34"><a href="generalized-linear-madness.html#cb2115-34"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;thousands of pelts&quot;</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">6</span> <span class="op">*</span><span class="st"> </span><span class="dv">20</span>) <span class="op">+</span></span>
<span id="cb2115-35"><a href="generalized-linear-madness.html#cb2115-35"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">120</span>))</span></code></pre></div>
<p>The workflow for the bottom portion of Figure 16.9 will be very similar. The main difference is this time we’re subsetting the posterior draws from <code>post$pop</code>.</p>
<div class="sourceCode" id="cb2116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2116-1"><a href="generalized-linear-madness.html#cb2116-1"></a><span class="co"># subset the relevant posterior draws</span></span>
<span id="cb2116-2"><a href="generalized-linear-madness.html#cb2116-2"></a>p2 &lt;-</span>
<span id="cb2116-3"><a href="generalized-linear-madness.html#cb2116-3"></a><span class="st">  </span><span class="kw">rbind</span>(post<span class="op">$</span>pop[<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">2</span>],</span>
<span id="cb2116-4"><a href="generalized-linear-madness.html#cb2116-4"></a>        post<span class="op">$</span>pop[<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dv">1</span>])<span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2116-5"><a href="generalized-linear-madness.html#cb2116-5"></a><span class="st">  </span><span class="co"># wrangle</span></span>
<span id="cb2116-6"><a href="generalized-linear-madness.html#cb2116-6"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2116-7"><a href="generalized-linear-madness.html#cb2116-7"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="dv">1900</span><span class="op">:</span><span class="dv">1920</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2116-8"><a href="generalized-linear-madness.html#cb2116-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="dt">times =</span> <span class="dv">2</span>),</span>
<span id="cb2116-9"><a href="generalized-linear-madness.html#cb2116-9"></a>         <span class="dt">name =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Hare&quot;</span>, <span class="st">&quot;Lynx&quot;</span>), <span class="dt">each =</span> <span class="dv">21</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2116-10"><a href="generalized-linear-madness.html#cb2116-10"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span><span class="kw">c</span>(iter, name),</span>
<span id="cb2116-11"><a href="generalized-linear-madness.html#cb2116-11"></a>               <span class="dt">names_to =</span> <span class="st">&quot;year&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2116-12"><a href="generalized-linear-madness.html#cb2116-12"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year =</span> <span class="kw">as.numeric</span>(year)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2116-13"><a href="generalized-linear-madness.html#cb2116-13"></a><span class="st">  </span></span>
<span id="cb2116-14"><a href="generalized-linear-madness.html#cb2116-14"></a><span class="st">  </span><span class="co"># plot</span></span>
<span id="cb2116-15"><a href="generalized-linear-madness.html#cb2116-15"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> value)) <span class="op">+</span></span>
<span id="cb2116-16"><a href="generalized-linear-madness.html#cb2116-16"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> <span class="kw">interaction</span>(iter, name), <span class="dt">color =</span> name),</span>
<span id="cb2116-17"><a href="generalized-linear-madness.html#cb2116-17"></a>            <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2116-18"><a href="generalized-linear-madness.html#cb2116-18"></a><span class="st">  </span><span class="kw">scale_color_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2116-19"><a href="generalized-linear-madness.html#cb2116-19"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;thousands of animals&quot;</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">5</span> <span class="op">*</span><span class="st"> </span><span class="dv">100</span>) <span class="op">+</span></span>
<span id="cb2116-20"><a href="generalized-linear-madness.html#cb2116-20"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">500</span>))</span>
<span id="cb2116-21"><a href="generalized-linear-madness.html#cb2116-21"></a></span>
<span id="cb2116-22"><a href="generalized-linear-madness.html#cb2116-22"></a><span class="co"># combine and add a title</span></span>
<span id="cb2116-23"><a href="generalized-linear-madness.html#cb2116-23"></a>p1 <span class="op">/</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span></span>
<span id="cb2116-24"><a href="generalized-linear-madness.html#cb2116-24"></a><span class="st">  </span><span class="kw">plot_annotation</span>(<span class="dt">title =</span> <span class="st">&quot;Posterior predictions for the lynx-hare model&quot;</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-45-1.png" width="624" style="display: block; margin: auto;" /></p>
</div>
<div id="lynx-lessons-bonus-practice-with-the-autoregressive-model." class="section level3">
<h3><span class="header-section-number">16.4.3</span> <del>Lynx lessons</del> Bonus: Practice with the autoregressive model.</h3>
<p>Back in <a href="generalized-linear-madness.html#population-dynamics">Section 16.4</a>, we briefly discussed how autoregressive models are a typical way to explore processes like those in lynx-hare data. In this bonus section, we’ll practice fitting a few of these. To start off, we’ll restrict ourselves to focusing on just one of the criteria, <code>Hare</code>. Our basic autoregressive model will follow the form</p>
<p><span class="math display">\[
\begin{align*}
\text{Hare}_t &amp; \sim \operatorname{Normal}(\mu_t, \sigma) \\
\mu_t &amp; = \alpha + \beta_1 \text{Hare}_{t - 1} \\
\alpha  &amp; \sim \; ? \\
\beta_1 &amp; \sim \; ? \\
\sigma  &amp; \sim \operatorname{Exponential}(1),
\end{align*}
\]</span></p>
<p>were <span class="math inline">\(\beta_1\)</span> is the first-order autoregressive coefficient and the question marks in the third and fourth lines indicate we’re not wedding ourselves to specific priors, at the moment. Also, note the <span class="math inline">\(t\)</span> subscripts, which denote which time period the observation is drawn from, which in these data is <span class="math inline">\(\text{Year} = 1900, 1901, \dots, 1920\)</span>. Conceptually, <span class="math inline">\(t\)</span> is <em>now</em> and <span class="math inline">\(t - 1\)</span> the time point just before now. So if we were particularly interested in <span class="math inline">\(\operatorname E (\text{Hare}_{t = 1920})\)</span>, <span class="math inline">\(\text{Hare}_{t - 1}\)</span> would be the same as <span class="math inline">\(\text{Hare}_{t = 1919}\)</span>.</p>
<p>With <strong>brms</strong>, you can fit a model like this using the <code>ar()</code> function. By default, <code>ar()</code> presumes the criterion variable (<code>Hare</code>, in this case) is ordered chronologically. If you’re unsure or just want to be on the safe side, you can enter your <em>time</em> variable in the <code>time</code> argument. Also, though the <code>ar()</code> function presumes a first-order autoregressive structure by default, it is capable of fitting models with higher-order autoregressive structures. You can manually specify this with the <code>p</code> argument. Here’s how to fit our simple AR(1) model with explicit <code>ar()</code> syntax.</p>
<div class="sourceCode" id="cb2117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2117-1"><a href="generalized-linear-madness.html#cb2117-1"></a>b16<span class="fl">.6</span> &lt;-</span>
<span id="cb2117-2"><a href="generalized-linear-madness.html#cb2117-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> Lynx_Hare,</span>
<span id="cb2117-3"><a href="generalized-linear-madness.html#cb2117-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb2117-4"><a href="generalized-linear-madness.html#cb2117-4"></a>      Hare <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">ar</span>(<span class="dt">time =</span> Year, <span class="dt">p =</span> <span class="dv">1</span>),</span>
<span id="cb2117-5"><a href="generalized-linear-madness.html#cb2117-5"></a>      <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="fl">0.04669846</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb2117-6"><a href="generalized-linear-madness.html#cb2117-6"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb2117-7"><a href="generalized-linear-madness.html#cb2117-7"></a>      <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2117-8"><a href="generalized-linear-madness.html#cb2117-8"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b16.06&quot;</span>)</span></code></pre></div>
<p>You may have noticed we just went with the default <strong>brms</strong> priors for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta_1\)</span>. We got the value for the exponential prior for <span class="math inline">\(\sigma\)</span> by executing the following.</p>
<div class="sourceCode" id="cb2118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2118-1"><a href="generalized-linear-madness.html#cb2118-1"></a><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(Lynx_Hare<span class="op">$</span>Hare)</span></code></pre></div>
<pre><code>## [1] 0.04669846</code></pre>
<p>Here’s the model summary.</p>
<div class="sourceCode" id="cb2120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2120-1"><a href="generalized-linear-madness.html#cb2120-1"></a><span class="kw">print</span>(b16<span class="fl">.6</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Hare ~ 1 + ar(time = Year, p = 1) 
##    Data: Lynx_Hare (Number of observations: 21) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Correlation Structures:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## ar[1]     0.74      0.17     0.38     1.05 1.00     2313     1813
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    30.22      9.68     9.34    48.88 1.00     2044     1739
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    16.42      2.87    12.00    23.19 1.00     2516     1985
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Our autoregressive <span class="math inline">\(\beta_1\)</span> parameter is summarized in the ‘Correlation Structures,’ in which it’s called ‘ar[1].’ Another more old-school way to fit a autoregressive model is by manually computing a lagged version of your criterion variable. In <strong>R</strong>, you can do this with the <code>lag()</code> function.</p>
<div class="sourceCode" id="cb2122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2122-1"><a href="generalized-linear-madness.html#cb2122-1"></a>Lynx_Hare &lt;-</span>
<span id="cb2122-2"><a href="generalized-linear-madness.html#cb2122-2"></a><span class="st">  </span>Lynx_Hare <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2122-3"><a href="generalized-linear-madness.html#cb2122-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Hare_1 =</span> <span class="kw">lag</span>(Hare))</span>
<span id="cb2122-4"><a href="generalized-linear-madness.html#cb2122-4"></a></span>
<span id="cb2122-5"><a href="generalized-linear-madness.html#cb2122-5"></a><span class="kw">head</span>(Lynx_Hare)</span></code></pre></div>
<pre><code>##   Year Lynx Hare Hare_1
## 1 1900  4.0 30.0     NA
## 2 1901  6.1 47.2   30.0
## 3 1902  9.8 70.2   47.2
## 4 1903 35.2 77.4   70.2
## 5 1904 59.4 36.3   77.4
## 6 1905 41.7 20.6   36.3</code></pre>
<p>Look closely at the relation between the values in the <code>Hare</code> and <code>Hare_1</code> columns. They are set up such that <span class="math inline">\(\text{Hare}_{\text{Year} = 1901} = \text{Hare_1}_{\text{Year} = 1900}\)</span>, <span class="math inline">\(\text{Hare}_{\text{Year} = 1902} = \text{Hare_1}_{\text{Year} = 1901}\)</span>, and so on. Unfortunately, this approach does produce a single missing value in the first time point for the lagged variable, <code>Hare_1</code>. Here’s how you might use such a variable to manually fit an autoregressive model with <code>brms::brm()</code>.</p>
<div class="sourceCode" id="cb2124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2124-1"><a href="generalized-linear-madness.html#cb2124-1"></a>b16<span class="fl">.7</span> &lt;-</span>
<span id="cb2124-2"><a href="generalized-linear-madness.html#cb2124-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> Lynx_Hare,</span>
<span id="cb2124-3"><a href="generalized-linear-madness.html#cb2124-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb2124-4"><a href="generalized-linear-madness.html#cb2124-4"></a>      Hare <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Hare_<span class="dv">1</span>,</span>
<span id="cb2124-5"><a href="generalized-linear-madness.html#cb2124-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b),</span>
<span id="cb2124-6"><a href="generalized-linear-madness.html#cb2124-6"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="fl">0.04669846</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb2124-7"><a href="generalized-linear-madness.html#cb2124-7"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb2124-8"><a href="generalized-linear-madness.html#cb2124-8"></a>      <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2124-9"><a href="generalized-linear-madness.html#cb2124-9"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b16.07&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2125-1"><a href="generalized-linear-madness.html#cb2125-1"></a><span class="kw">print</span>(b16<span class="fl">.7</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Hare ~ 1 + Hare_1 
##    Data: Lynx_Hare (Number of observations: 20) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    10.17      7.36    -4.65    24.86 1.00     3244     2561
## Hare_1        0.68      0.18     0.32     1.04 1.00     3123     2681
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    16.96      2.99    12.33    23.87 1.00     2777     2193
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Did you notice how the fourth line in the output read ‘Number of observations: 20?’ That’s because we had that one missing value for <code>Hare_1</code>. One quick and dirty hack might be to use the missing data syntax we learned from <a href="missing-data-and-other-opportunities.html#missing-data-and-other-opportunities">Chapter 15</a>. Here’s how that might look like.</p>
<div class="sourceCode" id="cb2127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2127-1"><a href="generalized-linear-madness.html#cb2127-1"></a>b16<span class="fl">.8</span> &lt;-</span>
<span id="cb2127-2"><a href="generalized-linear-madness.html#cb2127-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> Lynx_Hare,</span>
<span id="cb2127-3"><a href="generalized-linear-madness.html#cb2127-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb2127-4"><a href="generalized-linear-madness.html#cb2127-4"></a>      <span class="kw">bf</span>(Hare <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">mi</span>(Hare_<span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb2127-5"><a href="generalized-linear-madness.html#cb2127-5"></a><span class="st">        </span><span class="kw">bf</span>(Hare_<span class="dv">1</span> <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>() <span class="op">~</span><span class="st"> </span><span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb2127-6"><a href="generalized-linear-madness.html#cb2127-6"></a><span class="st">        </span><span class="kw">set_rescor</span>(<span class="ot">FALSE</span>),</span>
<span id="cb2127-7"><a href="generalized-linear-madness.html#cb2127-7"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b),</span>
<span id="cb2127-8"><a href="generalized-linear-madness.html#cb2127-8"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="fl">0.04669846</span>), <span class="dt">class =</span> sigma, <span class="dt">resp =</span> Hare),</span>
<span id="cb2127-9"><a href="generalized-linear-madness.html#cb2127-9"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="fl">0.04669846</span>), <span class="dt">class =</span> sigma, <span class="dt">resp =</span> Hare1)),</span>
<span id="cb2127-10"><a href="generalized-linear-madness.html#cb2127-10"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb2127-11"><a href="generalized-linear-madness.html#cb2127-11"></a>      <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2127-12"><a href="generalized-linear-madness.html#cb2127-12"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b16.08&quot;</span>)</span></code></pre></div>
<p>Check the model summary.</p>
<div class="sourceCode" id="cb2128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2128-1"><a href="generalized-linear-madness.html#cb2128-1"></a><span class="kw">print</span>(b16<span class="fl">.8</span>)</span></code></pre></div>
<pre><code>##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: Hare ~ 1 + mi(Hare_1) 
##          Hare_1 | mi() ~ 1 
##    Data: Lynx_Hare (Number of observations: 21) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Hare_Intercept     11.90      7.06    -2.36    25.76 1.00     2430     2477
## Hare1_Intercept    34.44      5.12    24.39    44.43 1.00     3926     2758
## Hare_miHare_1       0.65      0.17     0.29     0.98 1.00     2317     2319
## 
## Family Specific Parameters: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_Hare     16.80      2.81    12.32    23.21 1.00     2660     2192
## sigma_Hare1    22.43      3.65    16.67    30.67 1.00     3394     2674
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Now we have a model based on all 21 observations, again. I’m still not in love with this fix, because it presumes that value in <code>Hare_1</code> was missing at random, with no accounting for the autoregressive structure. This is why, when you can, it’s probably better to use the <code>ar()</code> syntax.</p>
<p>Anyway, here’s how we might use <code>fitted()</code> to get a sense of <span class="math inline">\(\operatorname{E}(\text{Hare}_t)\)</span> from our first autoregressive model, <code>b16.6</code>.</p>
<div class="sourceCode" id="cb2130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2130-1"><a href="generalized-linear-madness.html#cb2130-1"></a><span class="kw">set.seed</span>(<span class="dv">16</span>)</span>
<span id="cb2130-2"><a href="generalized-linear-madness.html#cb2130-2"></a></span>
<span id="cb2130-3"><a href="generalized-linear-madness.html#cb2130-3"></a><span class="kw">fitted</span>(b16<span class="fl">.6</span>,</span>
<span id="cb2130-4"><a href="generalized-linear-madness.html#cb2130-4"></a>       <span class="dt">summary =</span> F,</span>
<span id="cb2130-5"><a href="generalized-linear-madness.html#cb2130-5"></a>       <span class="dt">nsamples =</span> <span class="dv">21</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2130-6"><a href="generalized-linear-madness.html#cb2130-6"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2130-7"><a href="generalized-linear-madness.html#cb2130-7"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="dv">1900</span><span class="op">:</span><span class="dv">1920</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2130-8"><a href="generalized-linear-madness.html#cb2130-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2130-9"><a href="generalized-linear-madness.html#cb2130-9"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>iter) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2130-10"><a href="generalized-linear-madness.html#cb2130-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Year =</span> <span class="kw">as.integer</span>(name)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2130-11"><a href="generalized-linear-madness.html#cb2130-11"></a><span class="st">  </span></span>
<span id="cb2130-12"><a href="generalized-linear-madness.html#cb2130-12"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Year)) <span class="op">+</span></span>
<span id="cb2130-13"><a href="generalized-linear-madness.html#cb2130-13"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value, <span class="dt">group =</span> iter),</span>
<span id="cb2130-14"><a href="generalized-linear-madness.html#cb2130-14"></a>            <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2130-15"><a href="generalized-linear-madness.html#cb2130-15"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> Lynx_Hare,</span>
<span id="cb2130-16"><a href="generalized-linear-madness.html#cb2130-16"></a>             <span class="kw">aes</span>(<span class="dt">y =</span> Hare),</span>
<span id="cb2130-17"><a href="generalized-linear-madness.html#cb2130-17"></a>             <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">stroke =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, </span>
<span id="cb2130-18"><a href="generalized-linear-madness.html#cb2130-18"></a>             <span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb2130-19"><a href="generalized-linear-madness.html#cb2130-19"></a><span class="st">  </span><span class="kw">annotate</span>(<span class="dt">geom =</span> <span class="st">&quot;text&quot;</span>,</span>
<span id="cb2130-20"><a href="generalized-linear-madness.html#cb2130-20"></a>           <span class="dt">x =</span> <span class="fl">1913.5</span>, <span class="dt">y =</span> <span class="dv">85</span>,</span>
<span id="cb2130-21"><a href="generalized-linear-madness.html#cb2130-21"></a>           <span class="dt">label =</span> <span class="st">&quot;Lepus&quot;</span>, <span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>) <span class="op">+</span></span>
<span id="cb2130-22"><a href="generalized-linear-madness.html#cb2130-22"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;thousands of hare pelts&quot;</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">6</span> <span class="op">*</span><span class="st"> </span><span class="dv">20</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">120</span>))</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-51-1.png" width="624" style="display: block; margin: auto;" /></p>
<p>The model did a pretty good job capturing the non-linear trends in the data. But notice how the fitted lines appear to be one step off from the data. This is actually expected behavior for a simple AR(1) model. For insights on why, check out <a href="https://stats.stackexchange.com/questions/404650/why-is-arima-in-r-one-time-step-off">this thread</a> on Stack Exchange.</p>
<p>So far we’ve been fitting the autoregressive models with the Gaussian likelihood, which is a typical approach. If you look at McElreath’s practice problem 16H3, you’ll see he proposed a bivariate autoregressive model using the Log-Normal likelihood. His approach used hand-made lagged predictors and ignored the missing value problem by dropping the first case. That model followed the form</p>
<p><span class="math display">\[
\begin{align*}
L_t &amp; \sim \operatorname{Log-Normal}(\log \mu_{L, t}, \sigma_L) \\
H_t &amp; \sim \operatorname{Log-Normal}(\log \mu_{H, t}, \sigma_H) \\
\mu_{L, t} &amp; = \alpha_L + \beta_{L1} L_{t - 1} + \beta_{L2} H_{t - 1} \\
\mu_{H, t} &amp; = \alpha_H + \beta_{H1} H_{t - 1} + \beta_{H2} L_{t - 1},
\end{align*}
\]</span></p>
<p>where <span class="math inline">\(\beta_{L1}\)</span> and <span class="math inline">\(\beta_{H1}\)</span> are the autoregressive parameters and <span class="math inline">\(\beta_{L2}\)</span> and <span class="math inline">\(\beta_{H2}\)</span> are what are sometimes called the cross-lag parameters. McElreath left the priors up to us. I propose something like this:</p>
<p><span class="math display">\[
\begin{align*}
\alpha_L &amp; \sim \operatorname{Normal}(\log 10, 1) \\
\alpha_H &amp; \sim \operatorname{Normal}(\log 10, 1) \\
\beta_{L1}, \dots, \beta_{H2} &amp; \sim \operatorname{Normal}(0, 0.5) \\
\sigma_L &amp; \sim \operatorname{Exponential}(1) \\
\sigma_H &amp; \sim \operatorname{Exponential}(1).
\end{align*}
\]</span></p>
<p>Before we fit the model, we’ll need to make a lagged version of <code>Lynx</code>.</p>
<div class="sourceCode" id="cb2131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2131-1"><a href="generalized-linear-madness.html#cb2131-1"></a>Lynx_Hare &lt;-</span>
<span id="cb2131-2"><a href="generalized-linear-madness.html#cb2131-2"></a><span class="st">  </span>Lynx_Hare <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2131-3"><a href="generalized-linear-madness.html#cb2131-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Lynx_1 =</span> <span class="kw">lag</span>(Lynx))</span></code></pre></div>
<p>Because the predictor variables are not centered at zero, we’ll want to use the <code>0 + Intercept...</code> syntax. Now fit the bivariate autoregressive model.</p>
<div class="sourceCode" id="cb2132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2132-1"><a href="generalized-linear-madness.html#cb2132-1"></a>b16<span class="fl">.9</span> &lt;-</span>
<span id="cb2132-2"><a href="generalized-linear-madness.html#cb2132-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> Lynx_Hare,</span>
<span id="cb2132-3"><a href="generalized-linear-madness.html#cb2132-3"></a>      <span class="dt">family =</span> lognormal,</span>
<span id="cb2132-4"><a href="generalized-linear-madness.html#cb2132-4"></a>      <span class="kw">bf</span>(Hare <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>Hare_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Lynx_<span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb2132-5"><a href="generalized-linear-madness.html#cb2132-5"></a><span class="st">        </span><span class="kw">bf</span>(Lynx <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>Lynx_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Hare_<span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb2132-6"><a href="generalized-linear-madness.html#cb2132-6"></a><span class="st">        </span><span class="kw">set_rescor</span>(<span class="ot">FALSE</span>),</span>
<span id="cb2132-7"><a href="generalized-linear-madness.html#cb2132-7"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="kw">log</span>(<span class="dv">10</span>), <span class="dv">1</span>), <span class="dt">class =</span> b, <span class="dt">resp =</span> Hare, <span class="dt">coef =</span> Intercept),</span>
<span id="cb2132-8"><a href="generalized-linear-madness.html#cb2132-8"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="kw">log</span>(<span class="dv">10</span>), <span class="dv">1</span>), <span class="dt">class =</span> b, <span class="dt">resp =</span> Lynx, <span class="dt">coef =</span> Intercept),</span>
<span id="cb2132-9"><a href="generalized-linear-madness.html#cb2132-9"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> b, <span class="dt">resp =</span> Hare),</span>
<span id="cb2132-10"><a href="generalized-linear-madness.html#cb2132-10"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> b, <span class="dt">resp =</span> Lynx),</span>
<span id="cb2132-11"><a href="generalized-linear-madness.html#cb2132-11"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="dv">1</span>), <span class="dt">class =</span> sigma, <span class="dt">resp =</span> Hare),</span>
<span id="cb2132-12"><a href="generalized-linear-madness.html#cb2132-12"></a>                <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="dv">1</span>), <span class="dt">class =</span> sigma, <span class="dt">resp =</span> Lynx)),</span>
<span id="cb2132-13"><a href="generalized-linear-madness.html#cb2132-13"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb2132-14"><a href="generalized-linear-madness.html#cb2132-14"></a>      <span class="dt">seed =</span> <span class="dv">16</span>,</span>
<span id="cb2132-15"><a href="generalized-linear-madness.html#cb2132-15"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b16.09&quot;</span>)</span></code></pre></div>
<p>Check the summary.</p>
<div class="sourceCode" id="cb2133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2133-1"><a href="generalized-linear-madness.html#cb2133-1"></a><span class="kw">print</span>(b16<span class="fl">.9</span>)</span></code></pre></div>
<pre><code>##  Family: MV(lognormal, lognormal) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: Hare ~ 0 + Intercept + Hare_1 + Lynx_1 
##          Lynx ~ 0 + Intercept + Lynx_1 + Hare_1 
##    Data: Lynx_Hare (Number of observations: 20) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Hare_Intercept     3.01      0.17     2.68     3.34 1.00     2253     2480
## Hare_Hare_1        0.02      0.00     0.02     0.03 1.00     3418     2454
## Hare_Lynx_1       -0.02      0.00    -0.03    -0.01 1.00     2884     2557
## Lynx_Intercept     1.44      0.12     1.21     1.69 1.00     2663     2450
## Lynx_Lynx_1        0.03      0.00     0.02     0.04 1.00     4299     2897
## Lynx_Hare_1        0.02      0.00     0.02     0.03 1.00     3921     2789
## 
## Family Specific Parameters: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_Hare     0.33      0.06     0.23     0.47 1.00     3030     3019
## sigma_Lynx     0.23      0.04     0.17     0.34 1.00     3151     2663
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here we’ll use <code>fitted()</code> to make a variant of the posterior predictions from the top portion of Figure 16.9.</p>
<div class="sourceCode" id="cb2135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2135-1"><a href="generalized-linear-madness.html#cb2135-1"></a><span class="kw">rbind</span>(<span class="kw">fitted</span>(b16<span class="fl">.9</span>, <span class="dt">resp =</span> <span class="st">&quot;Hare&quot;</span>),</span>
<span id="cb2135-2"><a href="generalized-linear-madness.html#cb2135-2"></a>      <span class="kw">fitted</span>(b16<span class="fl">.9</span>, <span class="dt">resp =</span> <span class="st">&quot;Lynx&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2135-3"><a href="generalized-linear-madness.html#cb2135-3"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2135-4"><a href="generalized-linear-madness.html#cb2135-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Hare&quot;</span>, <span class="st">&quot;Lynx&quot;</span>), <span class="dt">each =</span> <span class="kw">n</span>() <span class="op">/</span><span class="st"> </span><span class="dv">2</span>),</span>
<span id="cb2135-5"><a href="generalized-linear-madness.html#cb2135-5"></a>         <span class="dt">year =</span> <span class="kw">rep</span>(<span class="dv">1901</span><span class="op">:</span><span class="dv">1920</span>, <span class="dt">times =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2135-6"><a href="generalized-linear-madness.html#cb2135-6"></a><span class="st">  </span></span>
<span id="cb2135-7"><a href="generalized-linear-madness.html#cb2135-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span></span>
<span id="cb2135-8"><a href="generalized-linear-madness.html#cb2135-8"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>, <span class="dt">group =</span> name, <span class="dt">fill =</span> name),</span>
<span id="cb2135-9"><a href="generalized-linear-madness.html#cb2135-9"></a>              <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb2135-10"><a href="generalized-linear-madness.html#cb2135-10"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">group =</span> name, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb2135-11"><a href="generalized-linear-madness.html#cb2135-11"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> Lynx_Hare <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(Lynx<span class="op">:</span>Hare),</span>
<span id="cb2135-12"><a href="generalized-linear-madness.html#cb2135-12"></a>             <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> value, <span class="dt">color =</span> name),</span>
<span id="cb2135-13"><a href="generalized-linear-madness.html#cb2135-13"></a>             <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb2135-14"><a href="generalized-linear-madness.html#cb2135-14"></a><span class="st">  </span><span class="kw">scale_fill_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2135-15"><a href="generalized-linear-madness.html#cb2135-15"></a><span class="st">  </span><span class="kw">scale_color_grey</span>(<span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="fl">.5</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb2135-16"><a href="generalized-linear-madness.html#cb2135-16"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">1900</span>, <span class="dv">1920</span>)) <span class="op">+</span></span>
<span id="cb2135-17"><a href="generalized-linear-madness.html#cb2135-17"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;thousands of pelts&quot;</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">6</span> <span class="op">*</span><span class="st"> </span><span class="dv">20</span>)</span></code></pre></div>
<p><img src="16_files/figure-html/unnamed-chunk-54-1.png" width="624" style="display: block; margin: auto;" /></p>
<p>In the next practice problem (16H4), McElreath suggested we “adapt the autoregressive model to use a <em>two-step</em> lag variable” (p. 551, <em>emphasis</em> added). Using the verbiage from above, we might also refer to that as second-order autoregressive model, AR(2). That would be a straight generalization of the approach we just took. I’ll leave the exercise to the interested reader.</p>
<p>The kinds autoregressive models we fit in this section are special cases of what are called <strong>autoregressive moving average</strong> (ARMA) models. If you’re in the social sciences, Hamaker and Brose have a nice <span class="citation">(<a href="#ref-hamakerIdiographicDataAnalysis2009" role="doc-biblioref">2009</a>)</span> chapter explaining AR, ARMA, and other related models, which you can download from ReserachGate <a href="https://www.researchgate.net/publication/226943668_Idiographic_Data_Analysis_Quantitative_Methods-From_Simple_to_Advanced">here</a>. ARMA models are available in <strong>brms</strong> with help from the <code>arma()</code> function. However, if you want to dive deep into models of this kind, you might want to check out the <a href="https://github.com/asael697/varstan"><strong>varstan</strong> package</a> <span class="citation">(Matamoros &amp; Torres, <a href="#ref-matamorosVarstanPackageBayesian2020" role="doc-biblioref">2020</a>)</span>, which is designed to fit a variety of Bayesian structured time series models.</p>
</div>
</div>
<div id="session-info-15" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode" id="cb2136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2136-1"><a href="generalized-linear-madness.html#cb2136-1"></a><span class="kw">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.3
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] patchwork_1.0.1.9000 rethinking_2.01      dagitty_0.2-2        rstan_2.21.2         StanHeaders_2.21.0-6
##  [6] GGally_2.0.0         brms_2.14.4          Rcpp_1.0.5           tidybayes_2.1.1      ggthemes_4.2.0      
## [11] forcats_0.5.0        stringr_1.4.0        dplyr_1.0.2          purrr_0.3.4          readr_1.3.1         
## [16] tidyr_1.1.1          tibble_3.0.4         ggplot2_3.3.2        tidyverse_1.3.0     
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.0      plyr_1.8.6           igraph_1.2.5         splines_3.6.3       
##   [6] svUnit_1.0.3         crosstalk_1.1.0.1    TH.data_1.0-10       rstantools_2.1.1     inline_0.3.16       
##  [11] digest_0.6.27        htmltools_0.5.0      rsconnect_0.8.16     fansi_0.4.1          magrittr_1.5        
##  [16] modelr_0.1.6         RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1           sandwich_2.5-1      
##  [21] prettyunits_1.1.1    colorspace_1.4-1     rvest_0.3.5          ggdist_2.1.1         haven_2.2.0         
##  [26] xfun_0.19            callr_3.5.1          crayon_1.3.4         jsonlite_1.7.1       lme4_1.1-23         
##  [31] survival_3.1-12      zoo_1.8-8            glue_1.4.2           gtable_0.3.0         emmeans_1.4.5       
##  [36] V8_3.4.0             pkgbuild_1.1.0       shape_1.4.4          abind_1.4-5          scales_1.1.1        
##  [41] mvtnorm_1.1-1        DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4         stats4_3.6.3        
##  [46] DT_0.13              htmlwidgets_1.5.1    httr_1.4.1           threejs_0.3.3        RColorBrewer_1.1-2  
##  [51] arrayhelpers_1.1-0   ellipsis_0.3.1       reshape_0.8.8        pkgconfig_2.0.3      loo_2.3.1           
##  [56] farver_2.0.3         dbplyr_1.4.2         utf8_1.1.4           tidyselect_1.1.0     labeling_0.4.2      
##  [61] rlang_0.4.8          reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    
##  [66] tools_3.6.3          cli_2.1.0            generics_0.1.0       broom_0.5.5          ggridges_0.5.2      
##  [71] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1           processx_3.4.4       knitr_1.30          
##  [76] fs_1.4.1             nlme_3.1-144         mime_0.9             projpred_2.0.2       xml2_1.3.1          
##  [81] compiler_3.6.3       bayesplot_1.7.2      shinythemes_1.1.2    rstudioapi_0.11      gamm4_0.2-6         
##  [86] curl_4.3             reprex_0.3.0         statmod_1.4.34       stringi_1.5.3        ps_1.4.0            
##  [91] Brobdingnag_1.2-6    lattice_0.20-38      Matrix_1.2-18        nloptr_1.2.2.1       markdown_1.1        
##  [96] shinyjs_1.1          vctrs_0.3.4          pillar_1.4.6         lifecycle_0.2.0      bridgesampling_1.0-0
## [101] estimability_1.3     httpuv_1.5.4         R6_2.5.0             bookdown_0.18        promises_1.1.1      
## [106] gridExtra_2.3        codetools_0.2-16     boot_1.3-24          colourpicker_1.0     MASS_7.3-51.5       
## [111] gtools_3.8.2         assertthat_0.2.1     withr_2.3.0          shinystan_2.5.0      multcomp_1.4-13     
## [116] mgcv_1.8-31          hms_0.5.3            grid_3.6.3           coda_0.19-4          minqa_1.2.4         
## [121] rmarkdown_2.5        shiny_1.5.0          lubridate_1.7.8      base64enc_0.1-3      dygraphs_1.1.1.6</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-boeschLearningCurvesTeaching2019">
<p>Boesch, C., Bombjaková, D., Meier, A., &amp; Mundry, R. (2019). Learning curves and teaching when acquiring nut-cracking in humans and chimpanzees. <em>Scientific Reports</em>, <em>9</em>(1), 1515. <a href="https://doi.org/10.1038/s41598-018-38392-8">https://doi.org/10.1038/s41598-018-38392-8</a></p>
</div>
<div id="ref-Bürkner2020Define">
<p>Bürkner, P.-C. (2020e). <em>Define custom response distributions with brms</em>. <a href="https://CRAN.R-project.org/package=brms/vignettes/brms_customfamilies.html">https://CRAN.R-project.org/package=brms/vignettes/brms_customfamilies.html</a></p>
</div>
<div id="ref-gelman2013bayesian">
<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). <em>Bayesian data analysis</em> (Third Edition). CRC press. <a href="https://stat.columbia.edu/~gelman/book/">https://stat.columbia.edu/~gelman/book/</a></p>
</div>
<div id="ref-hamakerIdiographicDataAnalysis2009">
<p>Hamaker, E. L., &amp; Dolan, C. V. (2009). Idiographic data analysis: Quantitative methodsfrom simple to advanced. In J. Valsiner, P. C. M. Molenaar, M. C. D. P. Lyra, &amp; N. Chaudhary (Eds.), <em>Dynamic process methodology in the social and developmental sciences</em> (pp. 191–216). Springer. <a href="https://doi.org/10.1007/978-0-387-95922-1_9">https://doi.org/10.1007/978-0-387-95922-1_9</a></p>
</div>
<div id="ref-hewittTheConservation1921">
<p>Hewitt, C. G. (1921). <em>The conservation of the wild life of Canada</em>. Charles Scribner’s Sons.</p>
</div>
<div id="ref-lotkaPrinciplesOfPhysicalBiology1925">
<p>Lotka, A. J. (1925). <em>Principles of physical biology</em>. Waverly.</p>
</div>
<div id="ref-matamorosVarstanPackageBayesian2020">
<p>Matamoros, I. A. A., &amp; Torres, C. A. C. (2020). varstan: An R package for Bayesian analysis of structured time series models with Stan. <em>arXiv:2005.10361 [Stat]</em>. <a href="http://arxiv.org/abs/2005.10361">http://arxiv.org/abs/2005.10361</a></p>
</div>
<div id="ref-mcelreathStatisticalRethinkingBayesian2020">
<p>McElreath, R. (2020b). <em>Statistical rethinking: A Bayesian course with examples in R and Stan</em> (Second Edition). CRC Press. <a href="https://xcelab.net/rm/statistical-rethinking/">https://xcelab.net/rm/statistical-rethinking/</a></p>
</div>
<div id="ref-standevelopmentteamStanReferenceManual2020">
<p>Stan Development Team. (2020b). <em>Stan reference manual, Version 2.25</em>. <a href="https://mc-stan.org/docs/2_25/reference-manual/">https://mc-stan.org/docs/2_25/reference-manual/</a></p>
</div>
<div id="ref-vanleeuwenDevelopmentHumanSocial2018">
<p>van Leeuwen, E. J. C., Cohen, E., Collier-Baker, E., Rapold, C. J., Schäfer, M., Schütte, S., &amp; Haun, D. B. M. (2018). The development of human social learning across seven societies. <em>Nature Communications</em>, <em>9</em>(1), 2076. <a href="https://doi.org/10.1038/s41467-018-04468-2">https://doi.org/10.1038/s41467-018-04468-2</a></p>
</div>
<div id="ref-volterraFluctuationsAbundanceSpecies1926">
<p>Volterra, V. (1926). Fluctuations in the abundance of a species considered mathematically. <em>Nature</em>, <em>118</em>(2972), 558–560. <a href="https://doi.org/10.1038/118558a0">https://doi.org/10.1038/118558a0</a></p>
</div>
<div id="ref-vonbertalanffyUntersuchungenUeberGesetzlichkeit1934">
<p>von Bertalanffy, L. (1934). Untersuchungen Über die Gesetzlichkeit des Wachstums. <em>Wilhelm Roux’ Archiv Für Entwicklungsmechanik Der Organismen</em>, <em>131</em>(4), 613–652. <a href="https://doi.org/10.1007/BF00650112">https://doi.org/10.1007/BF00650112</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="missing-data-and-other-opportunities.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="horoscopes-insights.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
